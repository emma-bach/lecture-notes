\documentclass{report}
\usepackage[a4paper,margin=1in]{geometry}
\usepackage{fancyhdr}
\usepackage[titles]{tocloft}
\usepackage{tikz}

\usepackage{multicol}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{pdfpages}
%\usepackage{biblatex}
%\addbibresource{bib.bib}

%hyperref should be last apparently
\usepackage{hyperref}

\renewcommand\cftsecdotsep{\cftdot}
\renewcommand\cftsubsecdotsep{\cftdot}

\newcommand{\tbf}{\textbf}

\newcommand*{\newpar}{\par\vspace{\baselineskip}\noindent} %start new unindented paragraph with empty line inbetween

\pagestyle{fancy} %allows headers

\lhead{Emma Bach}
\rhead{\today}

\renewcommand*\contentsname{Table of contents}


\begin{document}
\include{title}
\tableofcontents
\thispagestyle{fancy}
\chapter{Introduction}
\thispagestyle{fancy}
\section{Definition}
There is no fully rigorous 'mathematical' definition that cleanly seperates everything that is an embedded system from everything that isn't. Instead, embedded systems exist on a spectrum. We can say that a system is \textit{more embedded} or \textit{less embedded} depending on how many of the typical properties of an embedded system apply to it. \tbf{Embedded Systems} are \tbf{computer systems} that tend to:
\begin{itemize}
    \item be \tbf{integrated (embedded) into a larger system}, which they may control and/or provide information processing for.
    \item be \tbf{specialized} to provide exactly the functions they need to.
    \item be forced to work with \tbf{constraints} in time, memory, energy consumption, space, etc.
\end{itemize}
The term \tbf{Cyber-Physical System} generally refers to a larger system that combines computational elements with physical elements, with embedded systems generally being smaller components of such a system.
Examples of Cyber-Physical Systems include \tbf{IoT} (Internet of Things) devices, \tbf{Ubiquitous Computing} devices, and \tbf{SCADA} (Supervisory Control and Data Acquisition) systems.
\newpar
An embedded system generally consists of physical components such as sensors and actuators, computational components including memory and processors, and software. Since the computational components tend to work with digital representation of numbers, while the physical components work with analog voltages, additional conversion through A/D and D/A converters is needed.

\begin{figure}[h!]
\centering
\include{structure.tex}
\caption{The structure of a typical embedded system.}
\label{fig:embeddedsystemstructure}
\end{figure}

\newpar
Embedded systems have extremely widespread applications, especially in fields such as automotive and aerospace engineering and in medical technology.

\section{Design}
Embedded systems must be \tbf{dependable}:
\begin{itemize}
    \item The \tbf{Availability} is the probability of the system working at time t.
    \item The \tbf{Reliability} of an embedded system is the probability of the system working correctly provided that it was working at time t=0.
    \item The \tbf{Maintainability} is the probability of the system working correctly at time t+d after encountering an error at time t.
    \item Additional factors are \tbf{Safety} (How much harm could the system potentially cause?) and \tbf{Security} (How resistant to outside interference is the system?)
\end{itemize}
Since embedded systems are often employed in safety-critical roles, such as in the aforementioned aerospace industry, dependability is extremely important. For safety-critical systems, \tbf{redundancy} is generally a desired trait, so that if one component fails there are still other components to cover the same function.
\newpar
Embedded systems also generally need to be efficient enough to meet constraints in:
\begin{multicols}{2}
\begin{itemize}
    \item Energy consumption
    \item Physical Size
    \item Code Size
    \item Required Memory
    \item Runtime
    \item Weight
    \item Cost
    \item[\vspace{\fill}]
\end{itemize}
\end{multicols}
\newpar
Lastly, Embedded systems are typically \tbf{reactive systems}, meaning that they work through interacting with their environment at a pace dictated by that environment. This often also makes them \tbf{real-time systems}, meaning they need to meet real-time constraints - If a right answer arrives too late, it is just as bad as a wrong answer. If failure to meet a deadline results in catastrophe, that constrained is called a \tbf{hard constraint}. This means that worse average runtimes are acceptable, or even necessary, if it leads to a better worst case runtime. 
\chapter{Specification}
\thispagestyle{fancy}
Design by Contract (\tbf{DbC}), also known as contract programming or simply as internal testing, is the idea that software designers should define precise, formal, verifiable specifications for the desired behaviour of their systems. These often extend the ordinary usage of abstract data types with the description of desired preconditions, postconditions and invariants. Testing can prove the presence of errors, but in order to prove the absence of errors, more complicated methods of Program and Hardware Verification are needed, which are not covered in this course.
\newpar
Such specifications generally involve the \tbf{abstraction} of a given system in order to simplify its description, and hierarchical separation of the description, in order to make a description more easily digestible. We distinguish between two kinds of hierarchy:
\begin{itemize}
    \item Behavioral hierarchy, which describes a systems behavior in terms of states, events, and output signals. Examples of concepts of "high level" behavioral hierarchy are interrupts and exceptions.
    \item Structural hierarchy, which describes how a system can be thought of as a collection of seperate components: processors, actuators, sensors, etc.
\end{itemize}
Specifications generally need to describe a systems \tbf{Timing Behavior}, especially in the case of real-time systems. This involves specifying the elapsed time during execution of a given task, the delay between processes, Timeouts (maximum waiting times for a given event), and Deadlines.
\newpar
It is helpful to model a system as a flow of states (\tbf{State-Oriented Behavior}). However, classical automata are often insufficient, since they don't model timing and don't support hierarchical description.
\section{VHDL}
VHDL is a \tbf{Hardware Description Language}, meaning that it describes digital circuits (instead of abstract algorithms).
\newpar
VHDL code is split into \tbf{entities} and \tbf{architectures}. Entities describe ports, such as inputs (\textit{in}), outputs (\textit{out}), bi-directional ports (\textit{inout}), and \textit{buffers} (Output that the entity itself can read). An architecture defines the actual implementation of an entity - internal wiring, connection of signals, and assignment of values. For example, an OR gate could be implemented as:
\begin{verbatim}
entity orGate is
    port(a,b: in bit;
    c: out bit);
end orGate;
architecture arch1 of orGate is
begin
    c <= a or b;
end arch1;
\end{verbatim}
or:
\begin{verbatim}
entity orGate is
    port(a,b: in bit;
    c: out bit);
end orGate;
architecture arch2 of orGate is
begin
    c <= 1 when (a = '1' or b = '1') else 0;
end arch2;
\end{verbatim}
\newpar
There may be several architectures for a single entity. By default, the most recently analyzed architecture is the one that ends up being used.
\subsection{Testbenches}
A testbench is a VHDL Design without inputs or outputs, designed to test another VHDL Design, generally through Port mapping and verifying that the entity produces the correct outputs for given inputs. For example, a test bench for our OR gate could be realized as:
\begin{verbatim}
entity testbench is
 --empty
end testbench;

architecture test of testbench is
 signal d,e,f: bit := '0'

begin
 or1: entity orGate port map (a=>d,b=>e,c=>f);
 d <= not d after 10 ns;
end;
\end{verbatim}
The \tbf{port map} maps the signals $d,e,f$ in the software to the ports $a,b,c$ in the hardware. It is also possible to use positional association instead of explicit association, which means simply writing
\begin{verbatim}
architecture test of testbench is
 signal d,e,f: bit := '0'

begin
 or1: entity orGate port map (d,e,f);
 d <= not d after 10 ns;
end;
\end{verbatim}
after which the compiler will assign the ports based on the order of the signals in the port map. It is however good practice to always use explicit association.
\newpar
There are three concepts used in  testing:
\begin{itemize}
 \item \texttt{report}, for print-like outputs
 \item \texttt{assert}, for specifying conditions
 \item \texttt{severity}, for specifying how the statement should affect the run of a simulation
\end{itemize}
If needed, combinations of the three can be used within a single line:
\begin{verbatim}
report <message_string>
report <message_string> severity <severity_level>;

assert <condition>;
assert <condition> severity <severity_level>;
assert <condition> report <message_string>;
assert <condition> report <message_string> severity <severity_level>;
\end{verbatim}
If all three are used, the following happens: If the assertion is violated, the program sends a message \texttt{"message"}, and the whole thing is treated as an 'incident' with a predefined \texttt{severity\_level}. If an \texttt{assert} doesn't have a \texttt{severity\_level}, then the severity level will be \texttt{error}. If no \texttt{message\_string} is specified, the message will be \texttt{"Assertion Violation"}.
 If a \texttt{report} without an assertion does not have a \texttt{severity\_level}, the severity level is implicitly defined to be \texttt{note}.
 \newpar
 \texttt{report} statements are inherently sequential, meaning they can occur inside processes, but not (by themselves) in architectures. However, \texttt{assert}ions can be either sequential or concurrent.


\subsection{A Full Adder in VHDL}
\begin{verbatim}
entity fullAdder is

 port(a,b,cin: in bit;
      sum,cout: out bit);

end fullAdder;
\end{verbatim}
Dataflow description of the architecture:
\begin{verbatim}
architecture dataflow of fullAdder is

begin
 sum <= (a xor b) xor cin;
 cout <= (a and b) or (a and cin) or (b and cin);
end dataflow;
\end{verbatim}
\newpar
\tbf{Components} are entities used within a \tbf{structural definition} of an architecture, where a new architecture is defined as an interconnected circuit of already known smaller components. They are defined either via component and signal binding or via entity instantiation. For example, a fully structural definition of a full adder would be something like:
\begin{verbatim}
entity FULLADDER is
  port (A,B, CARRY_IN : in bit;
        SUM, CARRY    : out bit);
end FULLADDER;
 
architecture STRUCT of FULLADDER is
  component HALFADDER
    port (A, B       : in  bit;
          SUM, CARRY : out bit);
  end component;
 
  component ORGATE
    port (A, B : in  bit;
          RES  : out bit);
  end component;
  signal W_SUM, W_CARRY1, W_CARRY2 : bit;
 
begin
 
  MODULE1 : HALFADDER
    port map(A, B, W_SUM, W_CARRY1);
 
  MODULE2 : HALFADDER
    port map (W_SUM, CARRY_IN,
              SUM, W_CARRY2);
 
  MODULE3 : ORGATE
    port map (W_CARRY2, W_CARRY1, CARRY);
 
end STRUCT;
\end{verbatim}
\subsection{Data Types in VHDL}
\subsubsection{Standard data types}
The standard data types provided by VHDL are:
\newpar
\begin{tabular}{|c|c|}
    \hline
    bit & 0,1\\\hline
    boolean & true,false\\\hline
    character & most ASCII characters\\\hline
    integer & $-2^{31} - 1, \ldots, 2^{31}-1$\\\hline
    real & $-1.7e38, \ldots, 1.7e48$\\\hline
    time & 1fs, \ldots, 1hr\\\hline
\end{tabular}
\newpar
Users can also define their own datatypes, either as integer types:
\begin{verbatim}
 --64 bits
type small is range 0 to 63;

 --32 bits
type result32 is range 31 downto 0;

 --16 bits
subtype result16 is result32 range 15 downto 0;
\end{verbatim}
or as enumeration types:
\begin{verbatim}
type state is (idle,start,stop);
type hexDigits is (’0’, {…} , ’9’, ’A’, ’B’, ’C’, ’D’, ’E’, ’F’)
\end{verbatim}
\newpar
It is important not to get confused between statements like the following:
\begin{itemize}
 \item \texttt{signal S : integer range 0 to 3;}, meaning a number between 0 and 3
 \item \texttt{signal S : unsigned(3 downto 0);}, meaning an unsigned 3-bit integer (i.e. a number between 0 and 7)
\end{itemize}
Also note that for most datatypes, \texttt{downto} corresponds to little endian (i.e. most significant bit first), while \texttt{to} corresponds to big endian.

\subsubsection{std\_logic}
In realistic circuits, voltages may come in many forms not accurately described as simple boolean variables / bits. To model these, the datatype \texttt{std\_logic} is used, which contains signal types such as:
\newpar
\begin{tabular}{|c|c|}
    \hline
    0,1 & "Ground" and "High" Voltages\\\hline
    U & uninitialized\\\hline
    X & unknown, impossible to determine (generally a short circuit)\\\hline
    Z & high impedance (circuit connected to neither ground nor voltage)\\\hline
    H & weak drive, logic one (i.e. voltage behind resistor)\\\hline
    L & weak drive, logic zero\\\hline
    W & weak drive, undefined logic value\\\hline 
    - & don't care\\\hline
\end{tabular}
\newpar
These values take priority over each other in the following order: $X > (0 \sim 1) > W > (L \sim H) > Z$.
\newpar
\subsubsection{Arrays and Vectors}
\begin{verbatim}
type intArray is array (15 downto 0) of integer;
type bitArray is array (0 to 7) of bit;
type myMatrix is array (1 to 3, 1 to 3) of std_logic;
subtype myVector4 is std_logic_vector(3 downto 0);
\end{verbatim}
\subsection{Operators}
\newpar
\begin{tabular}{|c|c|c|}
\hline
    No. & Type & Examples\\\hline
    7 & Other Operators & \texttt{abs, not \textrm{(Negation of bits)}, ** \textrm{(exponentiation)}}\\\hline
    6 & Multipliying Operators & \texttt{*, /, mod, rem  \textrm{(remainder)}}\\\hline
    5 & Unary Operators & + (identity), - (negation of a numeric type)\\\hline
    4 & Addition Operators & \texttt{+, -, \&} (vector concatenation)\\\hline
    3 & Shift Operators &\texttt{sll, srl, sla, sra, rol, ror}\footnote[1]{}\\\hline
    2 & Relational Operators & \texttt{=, /= \textrm{(not equal)}, <, <=, >, >=}\\\hline
    1 & Logical Operators &\texttt{and, or, nand, nor, xor, xnor}\\\hline
\end{tabular}
\newpar
$^1$ - Shift operators ending in "l" are "logical", meaning vacated bits are filled with 0. Shift operators ending in "a" are "arithmetical", meaning vacated bits are filled with the value of the rightmost/leftmost bit. The operators "rol" and "ror" rotate the bits instead of shifting them.
\newpar
Operators with higher numbers in this table take priority over operators with lower numbers.
\subsection{Constants and Signals}
Constants work as expected in a programming language:
\begin{verbatim}
constant PI: real := 3.1415;
contant PERIOD: time := 100ns;
type vecType is array (0 to 3) of integer;
contant VEC: vecType := (2,4,-1,7)
\end{verbatim}
Signals represent a wire or register. They can be of any data type, can be declared in architectures only.
\begin{verbatim}
signal sum: std_logic;
signal clk: bit;
signal data: std_logic_vector(0 to 7) := "00X0X011";
signal value: integer range 16 to 31 := 17;
\end{verbatim}
Signals assignments are performed \tbf{concurrently}, meaning that they are sequentially collected until the process is stopped, and then collectively performed in parallel after al processes are stopped.
\newpar
Signals can be assigned with either an explicit user-defined time delay ("after 10ns", etc.), or with an implicit small delta delay:
\begin{verbatim}
sum <= (a xor b) after 2 ns; -- explicit delay
data(1) <= 'x'; -- implicit delay
\end{verbatim}
Signal assignments can also include conditionals. This can be done using the when-else condition:
\begin{verbatim}
clk <= '0' after 5ns when clk = '1' else '1' after 7ns when clk = '0';
a <= "1000" when b = "00" 
else "0100" when b = "01" 
else "0010" when b= "10" 
else "0001" when b = "11";
\end{verbatim}
Or using the with-select condition:
\begin{verbatim}
with b select a <=
	"1000" when "00",
	"0100" when "01",
	"0010" when "10",
	"0001" when "11";
\end{verbatim}
Neither of the two conditionals may be used inside a process. Within the finished hardware, conditions like this are realized using a multiplexer. Custom multiplexer code would look something like this:
\begin{verbatim}
entity mux is
port (i3, i2, i1, i0: in bit;
    sel: in bit_vector(1 downto 0);
    otp: out bit);
end;    

architecture wSelect of mux is
begin
    with sel select
    otp <= i0 when "00",
    i1 when "01",
    i2 when "10",
    i3 when others;
end;
\end{verbatim}
\subsection{Variables}
Variables work like variables in other programming languages. They store temporary values and are only usable in processes, procedures and functions. \tbf{Usage of them is not recommended in VHDL for synthesis.} Unlike signal assignments, variables assignments are performed sequentially as they are encountered in the code.
\subsection{Processes}
We've already seen two styles of modelling using VHDL: A Dataflow architecture uses concurrent signal assignment statements, while a structural architecture uses only component instantiation statements. We will now learn a third style: \tbf{Behavioural architecture}, which uses  \tbf{process statements}. A process is simply a set of statements that are executed sequentially-ish:
\begin{verbatim}
signal clk : std_logic := '0';
clk_gen: process ( )
begin
 clk <= ‘0’;
 wait for 10 ns;
 clk <= ‘1’;
 wait for 10 ns;
end process;
\end{verbatim}
VHDL supports four different types of wait statements:
\begin{itemize}
    \item \texttt{wait on} waits until one of the given signals changes (e.g. \texttt{wait on a,b,c;}).
    \item \texttt{wait until} waits until the given condition is met (e.g. \texttt{wait until (clkEvent and clk = '1')}).
    \item \texttt{wait for} waits for a specified amount of time (e.g. \texttt{wait for 25 ns;}).
    \item \texttt{wait} waits indefinitely.
\end{itemize}
Only simple signal assignments are allowed inside a process. When a simulation starts, each process will be executed at least once. Afterwards, they will loop infinitely. If the process has a \textit{sensitivity list}, a new iteration will occur whenever a signal from the sensitivity list changes:
\begin{verbatim}
entity DFF is
port (D, clk: in std_logic;
Q: out std_logic);
end DFF;
architecture rtl of DFF is
begin
 p : process(clk) -- sensitivity list
 begin
 if (clk‘event) and (clk=`1`) then
  Q <= D;
 end if;
 end process p;
end rtl;    
\end{verbatim}
Processes with sensitivity lists are equivalent to processes without a sensitivity loop that have \texttt{wait on} statements instead:
\begin{verbatim}
entity DFF is
port (D, clk: in std_logic;
Q: out std_logic);
end DFF;
architecture rtl of DFF is
begin
 p : process
 begin
  if (clk‘event) and (clk=`1`) then
   Q <= D;
  end if;
  wait on clk; -- equivalent wait statement
 end process p;
end rtl;
\end{verbatim}
Processes are not allowed to have subprocesses. They always loop, and are often used to specify sequential hardware. Everything in VHDL is implicitly part of a "main" process.
\subsection{Statements}
\texttt{if}-Statements and \texttt{case}-Statements are comparable to \texttt{if}-Statements and \texttt{switch}-statements in other languages. Both of them can be nested. Conditions in \texttt{if}-Statements can be any boolean expression.
\begin{multicols}{2}
\begin{verbatim}
if a = b then
…
elsif a > b or a > c then
…
else
…
end if;    
\end{verbatim}
\begin{verbatim}
case a is
when "01" =>
…
when "10" =>
…
when others =>
null
end case;    
\end{verbatim}
\end{multicols}
\newpar
As seen here, a case where nothing happens can be specified using the \texttt{null} Statement.
\newpar
VHDL also supports \texttt{loop}s. Here are two variants of a clock that counts up to 10, incrementing once every 5ns, using a \texttt{while} loop and a \texttt{for} loop:
\begin{multicols}{2}
\begin{verbatim}
constant MAX_SIM_TIME : time := 50 ns;
constant PERIOD : time := 10 ns;
...
clk_gen: process (clk)
begin
 while NOW < MAX_SIM_TIME loop --!
  clk <= not clk ;
  wait for PERIOD/2;
 end loop;
 wait;
end process clk_gen;
\end{verbatim}
\begin{verbatim}
constant MAX_CYCLES : integer := 10;
constant PERIOD : time := 10 ns;
...
clk_gen: process (clk)
variable cnt: integer := 0
begin
 for cnt in 1 to MAX_CYCLES loop --!
  clk <= not clk ;
  wait for PERIOD/2;
 end loop;
 wait;
end process clk_gen;
\end{verbatim}
\end{multicols}
\newpar
And a third variant using the \texttt{exit when}-Statement:
\begin{verbatim}
constant MAX_CYCLES : integer := 10;
...
clk_gen: process (clk)
variable cnt: integer := 0;
begin
 L1: loop
  clk <= not clk;
  cnt := cnt + 1;
  wait for 5ns;
 exit when cnt > 2*MAX_CYCLES; --!
end loop;
wait;
end process clk_gen;
\end{verbatim}
\newpar
During synthesis, all loops have to be unrolled, meaning that loops with a non-static range are non-synthesisable. It is generally good practice to only use loops in testbenches.
\subsection{Functions and procedures}
Apart from entities and architectures, VHDL also supports functions and procedures, similar to traditional programming languages. A \tbf{Function} has a return value and can be used in statements:
\begin{verbatim}
architecture rtl of example is
 signal test : integer := 0;
 ...

begin
 function b2i(b : bit) return integer is
 begin
  if b = '1' then
   return 1;
  else
   return 0;
  end if;
 end b2i;

 test <= b2i(’0’);
end;
\end{verbatim}
Functions can be overloaded, meaning that there can be Functions with the same name but different type signatures. By default, functions have to be \tbf{pure}, meaning they are free of side effects - formally $f(a)$ always returns the same value if $a$ is the same. An impure function can be declared by prepending the function with \texttt{impure}. This will let the function gain access to all variables and signals outside of its scope.
\newpar
A \tbf{Procedure} can be seen as a function without a return value. Instead, it has \texttt{in, out} or \texttt{inout}-signals, similar to an entity:
\begin{verbatim}
architecture behave of ex_procedure_simple is
 signal r_TEST : std_logic_vector(7 downto 0) := X"42";

-- Purpose: Increments a std_logic_vector by 1
 procedure INCREMENT_SLV (
  signal r_IN : in std_logic_vector(7 downto 0);
  signal r_OUT : out std_logic_vector(7 downto 0)
  ) is
  begin
   r_OUT <= std_logic_vector(unsigned(r_IN) + 1);
  end INCREMENT_SLV;
...
 signal test : std_logic_vector(7 downto 0) := (others => '0');
...
 test_p: process
 begin
  INCREMENT_SLV(test, test);
 end test_p;
\end{verbatim}
Because Procedures do not return anything, they can't be used in statements. They can still be used inside of processes, or, if \texttt{out} and \texttt{inout} parameters are signals, as their own processes.
\subsection{Synthesisable vs Non-Synthesisable Code}
Only a subset of VHDL statements is \tbf{synthesisable} (i.e. compilable with the output being hardware). Non-synthesisable statements include time statements, asserts, and dynamic loops.
\newpar
You can work around many of these restrictions. For example, the following code is non-synthesisable, because it uses a \texttt{wait}-Statement:
\begin{verbatim}
architecture behavior of testbench is
begin
 enable <= '0';
 wait for 100 ns; -- !
 enable <= '1'
end behavior;
\end{verbatim}
However, the following code is synthesisable:
\begin{verbatim}
architecture behavior of realCircuit is
signal cnt : unsigned(3 downto 0) := (others => '0');
begin
 process ( clk )
 begin
  if rising_edge( clk ) then
   if cnt < 10 then -- assume clk  period is 10 ns
    cnt <= cnt + 1;
    enable <= '0';
   else
    cnt <= (others => '0');
    enable <= '1';
   end if;
  end if;
 end process;
end behavior;
\end{verbatim}
\newpar
Many statements in VHDL are technically synthesisable, but are best avoided, generally because they quickly lead to significant, often unexpected, increases in hardware complexity. These include:
\begin{itemize}
 \item division or multiplication with numbers that aren't powers of 2
 \item \texttt{if rising\_edge (clk)} with \texttt{else}
 \item latches
\end{itemize}
\newpar
a \tbf{latch} is a memory element that is triggered by a changes immediately whenever the input changes:
\begin{verbatim}
architecture rtl of latch is
…
begin
 process (E, D) begin
  if E = ’1’ then
   Q <= D;
  end if;
 end process;
end;
\end{verbatim}
The big problem with latches is that they leaf to uncertainty in a circuit's timing behavior. You can avoid latches by including a clock and triggering things only on rising edges, and by stating all possibilities in if statements.
\subsection{Simulation}
A simulation works in the following way:
\begin{itemize}
\item Initialization:
\begin{itemize}
 \item Initialize all signals
 \item Set simulation time to 0
 \item Execute all processes once
 \item Start simulaton cycles
\end{itemize}
\item Simulation cycles:
\begin{itemize}
 \item update signals
 \item execute processes
 \item repeat
\end{itemize}
\item Simulation ends when:
\begin{itemize}
 \item No more signal changes are possible
 \item A maximum simlulation time has been reached
 \item An explicit \texttt{wait} is encountered
\end{itemize}
\end{itemize}
\newpar
Values are assigned to signals using a \tbf{transaction list}. The list contains entries of the form $(s,v,t)$, meaning ``signal $s$ is set to value $v$ at time $t$''. Processes are similarly reactivated using a \tbf{process activation list}, with entries of the form $(p,t)$ (``process $p$ resumes at time $t$'').
\subsection{Delay Modeling}
Real components always work on a delay. \tbf{Delay of components} can be modeled in VHDL using the \texttt{inertial} Keyword:
\begin{verbatim}
output <= not input after 10 ns;
-- with inertial delay:
output <= reject 5 ns inertial not input after 10 ns;
\end{verbatim}
If a signal assignment happens for an amount of time shorter than the signals inertial delay, then the signal doesn't change at all.
\newpar
There is also the Keyword \texttt{transport} to model the \tbf{delay of wires}:
\begin{verbatim}
output <= not input after 10 ns;
-- with transport delay:
output <= transport not input after 10 ns;
\end{verbatim}
A signal that uses \texttt{transport} delay always gets changed after the specified time.
%
\chapter{Design Space Evaluation}
Design Space Evaluation is the process of considering different possible ways to realize a given plan and comparing them based on criteria such as:
\begin{multicols}{2}
\begin{itemize}
 \item Cost
 \item Performance
 \item Power consumption
 \item Quality
\end{itemize}
\end{multicols}
\newpar
'Cost' can be further split into factors such as:
\begin{multicols}{2}
 \begin{itemize}
  \item Manufacturing cost
  \item Design cost
  \item Field support
  \item Administration
  \item Design time
  \item[\vspace{\fill}]
 \end{itemize}
\end{multicols}
While 'Performance' comes down to factors like:
\begin{multicols}{2}
\begin{itemize}
 \item Clock Frequency / Operations per Second
 \item Bandwidth
 \item Quality of service
 \item[\vspace{\fill}]
\end{itemize}
\end{multicols}
\newpar
Note that especially in safety-critical systems, it is preferable to accept a worse average runtime if it leads to a better worst case runtime and more predictability. For example, caching is usually avoided because of its inherent unpredictability.
\newpar
Within the context of Embedded Systems, common decision points include choosing between:
\begin{multicols}{3}
\begin{itemize}
 \item ASICs (Application specific integrated circuits)
 \item Field Programmable Gate Arrays (FPGAs)
 \item Microprocessors
 \item Microcontrollers
 \item Different Memory Architectures
 \item Different Interfaces (I$^2$C, SPI, CAN, \ldots)
 \item Different possible Sensors \& Actuators
 \item Different possible AD and DA converters
 \item etc.
\end{itemize}
\end{multicols}
\newpar
Formally, this comes down to a \tbf{multiobjective optimisation problem}.
\section{Power Consumption}
Generally, \tbf{power} is the most important constraint in Embedded Systems, and thus minimizing power consumption is one of the primary concerns during the design process. Modern processors have a power density of up to $100 \frac{W}{cm^2}$!
\newpar
Minimizing the power consumption leads to less pressure for the power supply and for voltage regulators and a much lower risk of overheating (also meaning less effort needed to introduce cooling). Naturally it also means lower costs.
\newpar
Low power design techniques include the usage of different components such as \tbf{low-power transistors}, which tend to come with drawbacks in speed. It may also involve dynamic power management, i.e. sleep modes (temporarily switching off components that aren't needed). Switching off the clock of a flip-flop specifically is known as \tbf{clock gating}. Dynamic power management naturally brings with it the cost of requiring additional logic. One can also use \tbf{dynamic voltage and frequency scaling}, where the power supply voltage is lowered when needed and the clock frequency is lowered accordingly.
\newpar
The power consumption $P$ of a CMOS circuit is
\begin{equation*}
P = \alpha C_L V_{DD}^2f
\end{equation*}
Where:
\begin{itemize}
 \item $\alpha$ is the \textit{switching activity} or \textit{activity factor}, defined as the probablity that a circuit node changes from logic 0 to logic 1 in any given clock cycle,
 \item $C_L$ is the \textit{load capacitance}, i.e. the capacitance between the output of a circuit and ground,
 \item $V_{DD}$ is the supply voltage,
 \item and $f$ is the clock frequency.
\end{itemize}
\newpar
For a more detailed breakdown of this equation, I found \href{https://cdn.intechopen.com/pdfs/82415.pdf}{\textit{Power Consumption in CMOS
Circuits} by Len Luet Ng et al.} to be helpful.
\newpar
The delay of a CMOS circuit is
\begin{equation*}
\tau = k \cdot C_L \frac{V_{DD}}{(V_{DD}-V_t)^2}
\end{equation*}
Where $k$ is a contant that depends on the circuit and $V_t$ is the threshold voltage, i.e. the voltage defined as the cutoff between a logical ``1'' and a logical ``0''.
\newpar
The important takeaway from these equations is that
\begin{equation*}
P \propto V_{DD}^2, \text{ while } \tau \propto \frac{1}{V_{DD} + \frac{1}{V_{DD}}}.
\end{equation*}
This means that, by decreasing the supply voltage of a circuit, the circuit's power consumption can be decreased quadratically, while the circuit's delay increases roughly linearly (by a pretty generous definition of ``roughly'').
%
\section{Quality Testing}
All manufacturing processes are inherently prone to defects. Naturally, defective parts should not be delivered to customers. Therefore, a need arises for \tbf{test processes} to distinguish good components from faulty ones. Testing can incur significant costs (the slides state an unsourced figure of ``up to 60\%''). Naturally, these still cannot identify 100\% of defective parts. There are many different approaches of testing for different types of components and the systems they make up. Parts are also susceptible to aging, which leads to parts which were previously defect-free to become defective over time. Lastly, parts may be susceptible to external effects like changing temperatures, noise or radiation.
\newpar
The fraction of defective delivered parts over total delivered parts is known as the \tbf{Defect Level (DL)} or as the number of \tbf{test escapes}. Naturally, a high defect level can lead to a loss of reputation and eventually to legal penalties. The fraction of defective-free part over all parts is known as the \tbf{Yield}. A higher lead naturally leads to lower testing costs and fewer test escapes. Finally, as already defined in the introduction, \tbf{Reliability} measures the probability that a part will work correctly over a given time, and is incredibly important especially for safety-critical systems. Ideally, a system should be able to undergo \tbf{graceful degradation}, meaning that as the system degrades, performance merely decreases gradually instead of suddenly catastrophically failing.
\newpar
Generally, a specification will include required bounds on quality parameters. For example, the IEC 61508 standard defines four safety integrity levels (SIL 1 through SIL 4). By this definition, an SIL 1 system must have a failure probability per hour lower than $\frac{1}{10^5}$, while an SIL 4 system needs to meet a much stricter requirement of at most $\frac{1}{10^8}$ failures per hour.
%
\section{Pareto Frontier}
A solution of the multiobjective optimisation problem posed by design space exploration is given by a vector $V = (v_1, \hdots, v_n)$ of parameters describing the performance, costs etc. associated with a possible realisation of a specification. We define these parameters in such a way that higher values are always better, which means that, for parameters describing a cost, we need to either take the negative or the inverse of the cost value. Naturally, these parameters are generally only estimates, since determining the exact values would have to involve production of every single possible solution at a non-trivial scale.
\newpar
A natural way of discarding inferior solutions is given by \tbf{pareto superiority}. We say that a solution $A$ is pareto-superior to a solution $B$ iff we have both $\forall j(a_j \geq b_j)$ ($A$ is at least as good as $B$ in every aspect) and $\exists i(a_i > a_j)$ (There is at least one aspect of $A$ that is better than $B$). It should be intuitively obvious that if $A$ is superior to $B$ in every single criterium considered, then $A$ is preferable over $B$. The set of all solutions not dominated by any other solution is known as the \tbf{Pareto Frontier}.
%
\chapter{Hardware}
\thispagestyle{fancy}
\section{Microprocessors vs Microcontrollers}
A Microprocessor consists of \tbf{only a computing unit}, which then needs to be complemented by memory, I/O interfaces etc. Microprocessors are fast, but often  expensive.
\newpar
Meanwhile, a Microcontroller is a \tbf{System-on-chip (SOC)}. It already contains memory, timers, voltage converters, and at least one I/O interface (generally even multiple). They are slower than microprocessors, but are cheap and energy efficient.
%
\section{Memory}
Technological improvements to computer memory size and access times are currently made at a much slower pace than improvements to processor cycle times. This \tbf{Memory Wall} is a key challenge in the development of new AI models and, more generally, in most high performance computing applications.
\begin{figure}[h!]
 \centering
 \includegraphics[scale=0.3]{figures/memorywall.png}
 \caption{The memory wall in action (Source: \href{https://ayarlabs.com/wp-content/uploads/2024/05/Memory_Wall_Chart.svg}{ayarlabs})}
\end{figure}
\newpar
The \tbf{Principle of Locality} is the Observation that programs tend to use data with addresses near those they have already used recently. It can be further split into \tbf{Temporal Locality}, which means that recently referenced items are likely to be referenced again soon, and \tbf{Spatial Locality}, meaning that items with nearby addresses are often referenced around the same time. Modern memory architectures exploit these properties through \tbf{caching}, where several types of memory exist within a system, and items  are placed in faster memory or slower memory depending on how likely it is that they will be needed in the near future.
\newpar
The most basic types of memory, ordered by speed, are:
\begin{enumerate}
 \item Registers
 \item Cache, Scratchpad Memory (SPM)
 \item Main Memory (RAM)
 \item Secondary Storage (SSD, HDD)
\end{enumerate}
On its own, a processor tends to only include registers and cache or SPM. The registers of a processor could technically be considered a particularly fast type of cache. Fast caches have to be placed near the processing unit - the increases in signal travel time and especially in ambient noise that come with longer wires are actually relevant factors in determining memory speed.
%
\subsection{Cache Design}
Some key questions of cache design are:
\begin{itemize}
 \item Which memory blocks do we place into which cache blocks?
 \item How do we detect if and where a block is in the cache?
 \item Which cache block is replaced after a \tbf{cache miss}, i.e. when an item is needed that isn't in the cache yet?
 \item What happens if we write new things into memory?
 \item How do we deal with multi-core architectures?
\end{itemize}
A \tbf{direct mapping cache} is a cache where the adress of any item in cache is simply the item's adress in main memory modulo the number of cache blocks. A cache where any item can occupy any block is known as an \tbf{associative cache}. To use an associative cache, one needs to specify what happens when the cache is full - a predefined \tbf{cache replacement strategy} is needed. Common cache replacement strategies include:
\begin{itemize}
 \item FIFO (first in, first out)
 \item LRU (least recently used)
 \item random selection
\end{itemize}
Interestingly, random selection is provably optimal in cases where the order that items are needed in is provided by an \textit{oblivious adversary} (See lecture ``Algorithm Theory'' for more details). However, for real-time embedded systems, predictability is key, which means that non-deterministic cache algorithms are used. For a worst case execution time analysis, one has to assume that almost every access to the cache leads to a cache miss.
%
\clearpage
\subsection{Scratch Pad Memory}
A scratch pad memory architecture maps small physical memories directly into the CPU's address space. Frequently used variables and instructions can thus be allocated to the scratch pad memory \tbf{at compile time}. This leads to \tbf{fast and predictable behavior and lower energy consumption}, especially compared to associative cache architectures. Some architectures contain both caches and SPM, leading to a hierachical memory structure:
\begin{figure}[h!]
\centering
\include{memoryhierarchy}
\caption{A memory architecture that combines caching with SPM}
\label{fig:memoryhierarchy}
\end{figure}
%
\subsection{I/O Access}
The two most basic ways of handling I/O are \tbf{memory-mapped I/O}, where components get mapped directly into controller address space, and \tbf{port-mapped I/O}, also known as \tbf{programmed I/O}, where the CPU transfers bytes using a special instruction. However, both of those have the major disadvantage of keeping the CPU busy, with updates requiring polling.
\newpar
Most microprocessors and -controllers include a component that allows \tbf{DMA (Direct Memory Access)}. These are dedicated components that allow the CPU to do other work or sleep during a data transfer. However, the CPU still needs to initiate the transfer on its own. Typically, the CPU then receives an interrupt from the DMA once the transfer is done.
\newpar
Usage of DMAs brings with it the problem of \tbf{cache coherency}. Imagine the following scenario:
\begin{itemize}
 \item The CPU accesses location X in memory and stores the current value of X in cache
 \item Subsequent operations on X update the cached copy of X, not the external memory version of X (since updating the external version would mean dealing with slow memory speeds, defeating the whole purpose of a cache.)
 \item Whenever an outside device now tries to access X, that device will \tbf{recieve the old value of X.} Similary, if a device updates X in main memory, then \tbf{the CPU will be working with an outdated version of X.}
\end{itemize}
A simple cache consistency protocol consists of having both the CPU and outside devices broadcast an ``invalidate'' flag on every write to memory, signaling to each other that a value has become outdated. Alternatives include having a \tbf{write-through} or \tbf{write-around} cache instead of a write-back cache, meaning that everything that is written to cache is copied to main memory immediately. This sacrifices speed on writes (but still leaves the benefits caches have for reads).
\subsection{Interrupts}
Interrupts allow the CPU to be notified about important events. An interrupt generally gets processed as follows:
\begin{enumerate}
 \item an interrupt request is triggered
 \item the CPU stops its current exectution flow and saves its current state to memory
 \item the CPU executes the interrupt service routine associated with the specific interrupt request
 \item the CPU reloads its state and continues normal operation
\end{enumerate}
Modern CPUs feature at least one programmable interrupt controller (PIC) that manages interrups along several lines (to allow several devices to send interrupts) by assigning priorities and delaying or outright ignoring low-important interrupts.
%
\section{Communication}
In order to communicate with each other, digital devices need to send \tbf{modulated signals}.
\chapter{Software}
\thispagestyle{fancy}
A big software chapter was teased all throughout the lecture but besides a non-exam-relevant chapter on the very very basic basics of embedded AI it was basically skipped :\textsuperscript{$\wedge$})
%
\appendix
\chapter{Sources}
\thispagestyle{fancy}
The content of these notes primarily comes from the slides provided by Prof. Amft and Lars Häusler.
\newpar
Additional sources include \href{http://www.en.wikipedia.org}{Wikipedia} for theoretical topics and \href{http://www.vhdlwhiz.com}{vhdlwhiz.com}, \href{http://www.vhdl-online.de}{vhdl-online.de} and \href{https://www.sigasi.com/tech/}{sigasi.com} for VHDL.
\newpar
A tool of dubious quality that was nevertheless used frequently throughout the lecture for playing around with VHDL was \href{https://www.edaplayground.com}{edaplayground.com}.
\end{document}
