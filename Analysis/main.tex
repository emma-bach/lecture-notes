\documentclass{report}

% custom margins
\usepackage[a4paper,margin=1.5in]{geometry}
\renewcommand{\baselinestretch}{1.2}

% emma's long list of custom macros and universally used packages
\include{../macros-and-packages.tex}

% colored box behind proofs
\tcolorboxenvironment{proof}{
	colback=white,
	boxrule=0pt,
	leftrule=0.5mm,
	before skip=0.75cm,
	after skip=0.75cm,
	sharp corners,
	breakable,
	enhanced,
}

\renewcommand*\contentsname{Inhalt}
\renewcommand*\proofname{Beweis}

% use roman numerals in enumerate
\renewcommand{\labelenumi}{(\roman{enumi})}

\pagestyle{fancy} %allows headers

\lhead{Emma Bach}
\rhead{\today}

\begin{document}
	
\include{title}
\tableofcontents
\thispagestyle{fancy}

\chapter{Grundlagen der Mengenlehre}
\section{Die de-Morganschen Regeln}
\begin{theorem}
	Es gilt:
	\begin{enumerate}
		\item $X \setminus \bigcap_{i \in I} A_i = \bigcup_{i \in I} X \setminus A_i$
		\item $X \setminus \bigcup_{i \in I} A_i = \bigcap_{i \in I} X \setminus A_i$
	\end{enumerate}
\end{theorem}
\begin{proof}
	\phantom{}
	\begin{enumerate}
		\item 
		\iffalse
		Wir zeigen zuerst $X \setminus \bigcap_{i \in I} A_i \subseteq \bigcup_{i \in I} X \setminus A_i$:
		\begin{align*}
			x \in X \setminus \bigcap_{i \in I} A_i &\Leftrightarrow x \in X \wedge \left(\bigwedge_{i \in I} x \notin A_i\right)\\
			&\Rightarrow x \in X \wedge  \exists j \in I : x \notin A_j\\
			&\Rightarrow x \in X \setminus A_j\\
			&\Rightarrow x \in \bigcup_{i \in I} X \setminus A_i
		\end{align*}
		Es fehlt nun nur noch $\bigcup_{i \in I} X \setminus A_i \subseteq X \setminus \bigcap_{i \in I} A_i$:\fi
		\begin{align*}
			x \in \bigcup_{i \in I} X \setminus A_i &\Leftrightarrow \bigvee_{i \in I} x \in X \wedge x \notin A_i\\
			&\Leftrightarrow \exists j \in I : x \in X \wedge x \notin A_j\\
			&\Leftrightarrow \exists j \in I : x \in X \setminus A_j\\
			&\Leftrightarrow x \in X \setminus \bigcap_{i \in I} A_i
		\end{align*}
		\item \phantom{}
		TODO
	\end{enumerate}
\end{proof}
\chapter{Zahlen}
\section{Die natürlichen Zahlen}
\section{Die rationalen Zahlen}
\section{Algebraische Grundbegriffe}
\section{Reelle Zahlen axiomatisch}
Die Konstruktion der reellen Zahlen ist deutlich komplizierter als die Konstruktion der natürlichen Zahlen und der rationalen Zahlen. Insbesondere ist für die meiner Meinung nach anschaulichste Konstruktion der Begriff einer Cauchyfolge nötig, für welchen wiederum topologische Grundbegriffe gebraucht werden.
\newpar
Die reellen Zahlen können aber auch ohne eine explizite Konstruktion bereits axiomatisch definiert werden: Wir sagen "Falls die reellen Zahlen existieren, sollen sie diese Gesetze erfüllen".
\begin{definition}
	Die reellen Zahlen sind der angeordnete Körper $\bR$, in dem für jede beschränkte Menge $M$ auch eine kleinste obere Schranke in $\bR$ existiert. Man sagt dann, der Körper ist \tit{Dedekind-vollständig}.
\end{definition}
\noindent Diese Definition erlaubt es uns a priori noch nicht von "den" reellen Zahlen zu sprechen - es könnte schließlich viele Dedekind-vollständige Körper geben, die eventuell nichts mit den reellen Zahlen zu tun haben. Es stellt sich jedoch heraus, dass dies nicht der Fall ist.
\begin{theorem}
	Alle angeordneten Körper mit dieser Eigenschaft sind isomorph.
\end{theorem}
\noindent Wir können also getrost von "den reellen Zahlen" reden. Der Beweis dieses Satzes wird allerdings einiges an Vorarbeit benötigen.
\subsection{$\bR$ enthält $\bN$, $\bZ$ und $\bQ$}
Im folgenden Abschnitt definieren wir $\bR$ als beliebiges Modell der reellen Zahlen, ohne von Eindeutigkeit auszugehen.
\begin{definition}
	Sei $K$ ein Körper und $S \subset K$ eine Teilmenge dieses Körpers. Wir nennen $S$ eine \tbf{induktive Teilmenge} von $K$, falls:
	\begin{enumerate}
		\item $0 \in S$
		\item $\forall a \in S : a + 1 \in S$
	\end{enumerate}
\end{definition}
\begin{lemma}
	Es sei die Menge $N$ der Schnitt aller induktiver Teilmengen von $\bR$. Dann gilt:
	\begin{enumerate}
		\item Die Menge $N$ ist induktiv.
		\item Ist $A \subseteq \bR$ induktiv, so ist $N \subseteq A$.
		\item Ist $n \in N$, so ist $n \geq 0$. 
	\end{enumerate}
\end{lemma}
\begin{proof}
	\begin{enumerate}
		\item Sei $\cI$ die Menge aller induktiven Teilmengen von $\bR$. Wir wissen $1 \in I$ für alle $I \in \cI$, also auch $\displaystyle 1 \in \bigcap_{I \in \cI} I = N$.
		Analog gilt für $\displaystyle a \in N = \bigcap_{I \in \cI} I$ auch $a \in I$ für alle $I$, also $a+1 \in I$ für alle $I$, also $\displaystyle a + 1 \in \bigcap_{I \in \cI} I = N$.
		\item $N$ ist per Definition der Schnitt aller induktiver Teilmengen von $\bR$. Ein Schnitt von Mengen ist immer Teilmenge aller ursprünglichen Mengen.
		\item Die Menge $\{x \in \bR : x \geq 0\}$ ist induktiv. Somit muss $N$ eine Teilmenge dieser Menge sein, also kann $N$ keine Elemente $n < 0$ enthalten.
	\end{enumerate}
\end{proof}
\begin{theorem}
	Die Menge $N$ mit Nachfolgerfunktion $s : n \to n + 1$ ist ein Modell der natürlichen Zahlen.
\end{theorem}
\begin{proof}
	Zu zeigen ist, dass $N$ die Peanoaxiome erfüllt.
	\begin{enumerate}
		\item \ul{$\neg(\exists n \in N : s(n) = 0)$:}\\
		Angenommen, $n + 1 = 0$. Dann muss $n$ das additive Inverse von $1$ sein, also $n = -1$. Dann ist aber $n < 0$, also wissen wir aus dem vorherigen Lemma, dass $n \notin N$.
		\item \ul{$s$ ist injektiv:} Angenommen, $s(n) = s(m)$. Dann gilt $m + 1 = n + 1$, also $m = n$. Somit ist $s$ injektiv.
		\item \ul{Induktionsaxiom:} Das Induktionsaxiom sagt uns, dass jede induktive Menge $G$, welche $0$ enthält und unter der Nachfolgerfunktion abgeschlossen ist, eine Obermenge der Natürlichen Zahlen ist. Dies folgt aus Bedingung (ii) aus unserem Lemma.
	\end{enumerate}
\end{proof}
\noindent Wir schreiben dementsprechend von nun an $\bN \subseteq \bR$ statt $N \subseteq \bR$.
\begin{theorem}
	\theoremname{Wohlordnungsprinzip:} Jede nichtleere Teilmenge $G \subseteq \bN$ enthält ein minimales Element $m \in G$, also ein Element $m$, welches $\forall g \in G : m \leq g$ erfüllt.
\end{theorem}
\begin{corollary}
	Die Reellen Zahlen enthalten ein Modell der ganzen Zahlen $\bZ$ und der rationalen Zahlen $\bQ$ als Teilmengen.
\end{corollary}
\begin{proof}
	Die Ganzen Zahlen sind per Definition gegeben durch $\bN \cup \{n' \in \bR : \exists n \in \bN : n' + n = 0\}$, also als die Menge der natürlichen Zahlen vereinigt mit der Mengen ihrer additiven Inversen. Analog sind die rationalen Zahlen der Abschluss der natürlichen Zahlen und ihrer multiplikativen Inversen.
\end{proof}
\chapter{Topologie}
In den meisten Anfängervorlesungen über Analysis ist der einzige relevante Topologische / Metrische Raum der Raum $(\bR, \abs{-})$ der Reellen Zahlen mit der Absolutbetragsmetrik $d(x,y) = \abs{x-y}$. Falls kein zusätzliches Interesse besteht, tiefer in die Theorie einzutauchen und die betrachteten Konzepte in voller Allgemeinheit aufzunehmen, kannst dieses Kapitel dementsprechend auch fürs Erste übersprungen werden und in jedem Satz in den darauffolgenden Kapiteln die Wörter "Topologischer Raum" und "Metrischer Raum" durch "$\bR$" und die Funktion "$d(x,y)$" durch "$\abs{x - y}$" ersetzt werden.
\newpar
Spätestens ab dem Kapitel über den Euklidischen Raum $\bR^n$ entsprechen die Notizen eher einer Vorlesung "Analysis II" - ab diesem Punkt werden auch andere Metrische Räume als $\bR$ relevant, und es lohnt es sich, die Grundlagen nachzuholen.
\section{Metrische und Topologische Räume}
\begin{definition}
	Eine \tbf{Metrik} auf einer Menge $M$ ist eine Abbildung $d : M \times M \to \bR$, welche für alle $x,y,z \in M$ folgende Eigenschaften erfüllt sind:
	\begin{enumerate}
		\item $d(x,y) = 0$ genau dann, wenn $x = y$
		\item \ul{\tbf{Symmetrie:}} $d(x,y) = d(y,x)$
		\item \ul{\tbf{Dreiecksungleichung:}} $d(x,y) \leq d(x,z) + d(z,y)$
	\end{enumerate}
	Ist $d$ eine Metrik auf einer Menge $M$, so nennen wir das Paar $(M,d)$ einen \tbf{Metrischen Raum}.
\end{definition}
\noindent Ein Metrischer Raum ist eine Menge, auf der \tbf{Abstände} zwischen den Elementen definiert werden können. Der Abstand von $x \in M$ und $y \in M$ ist dann genau $d(x,y)$.
\begin{theorem}
	Sei $(M,d)$ ein Metrischer Raum und $x,y \in M$. So gilt \ul{\tbf{Positivität:}} $d(x,y) \geq 0$
\end{theorem}
\begin{proof}
	\begin{align*}
		0 = d(x,x) \leq d(x,y) + d(y,x) = d(x,y) + d(x,y) = 2d(x,y)
	\end{align*}
	Also auch $d(x,y) \geq 0$.
\end{proof}
\begin{definition}
	Sei $(M,d)$ ein Metrischer Raum. Wir nennen eine Teilmenge $\Omega \subseteq M$ \tbf{offen}, falls für jedes $x \in \Omega$ ein $\epsilon \in \bR_{> 0}$ existiert, sodass auch alle $y \in M$ mit $d(x,y) \leq \epsilon$ in $\Omega$ enthalten sind.
\end{definition}
\begin{definition}
	Gegeben einen Punkt $x \in M$ und eine positive reelle Zahl $\epsilon \in \bR_{> 0}$ nennen wir eine solche Menge $\{y \mid d(x,y) < \epsilon\}$ auch den \tbf{$\epsilon$-Ball um $y$} und schreiben sie $B_\epsilon(p)$. Die Zahl $\epsilon$ gibt uns also den "Radius" des Balls.
\end{definition}
\begin{definition}
	Sei $T$ eine beliebige Menge und $\tau \in \cP(M)$. Wir nennen $\tau$ eine \tbf{Topologie} und das Paar $(T,\tau)$ einen \tbf{Topologischen Raum}, falls folgende Eigenschaften erfüllt sind:
	\begin{enumerate}
		\item $\emptyset \in \tau$
		\item $M \in \tau$ 
		\item Der Durchschnitt endlich vieler Mengen aus $\tau$ ist ebenfalls in $\tau$.
		\item Die Vereinigung endlich vieler Mengen aus $\tau$ ist ebenfalls in $\tau$.
	\end{enumerate}
\end{definition}
\begin{theorem}
	Jeder Metrische Raum bildet zusammen mit den System seiner offenen Teilmengen einen Topologischen Raum.
\end{theorem}
\noindent Ein Topologischer Raum ist ein Raum, in dem definiert ist, welche Elemente "nah aneinander liegen". Somit macht es intuitiv hoffentlich Sinn, dass Metrische Räume Topologische Räume sind.
\newpar
Allerdings gibt es auch Topologische Räume, auf denen keine Metriken existieren. In solchen Räumen kann man zwar erkennen, dass manche Punkte näher aneinanderliegen als andere, kann aber den Punkten keine exakten Abstände zuordnen.
\begin{definition}
	Ist $(T, \tau)$ ein Topologischer Raum, so nennen wir die Elemente der Topologie allgemein immer \tbf{offene Teilmengen}, selbst wenn der Topologische Raum kein Metrischer Raum ist. Ist $U$ eine offene Menge und $x \in U$, nennen wir $U$ auch eine \tbf{Umgebung von $x$}.
\end{definition}
\begin{definition}
	Sei $(T, \tau)$ ein Topologischer Raum. Wir nennen $T$ \tbf{Hausdorff}, falls es für jedes Paar $x, y \in T$ mit $x \neq y$ disjunkte Umgebungen gibt, also $\exists U \ni x, V \ni y : U \cap V = \emptyset$
\end{definition}
\begin{theorem}
	\label{theorem:metricspaceishausdorff}
	Jeder Metrische Raum ist Hausdorff.
\end{theorem}
\begin{proof}
	Da für $x \neq y$ per Definition $d(x,y) \neq 0$ gilt, reicht es, Bälle um $x$ und $y$ zu wählen, deren Radius kleiner als $d(x,y)$ ist. $y$ liegt nicht in $U = \{p \mid d(x,p) < \frac{1}{2}d(x,y)\}$ und umgekehrt.
\end{proof}
%
%
%
%
%
%
%
%
%
%
\section{Normierte Vektorräume}
Viele wichtige Metrische Räume sind Vektorräume, auf denen eine Norm definiert ist, also eine Funktion, welche den Vektoren Längen zuordnet. Ich werde hier in aller Kürze die Definitionen und einige relevante Eigenschaften wiederholen. Die allgemeine Theorie der Vektorräume ist enorm wichtig und wird in der Linearen Algebra genauer behandelt.
\newpar
Intuitiv ist ein Vektorraum ein Raum, dessen Elemente sich unter Addition und Skalierung wie Vektoren im $\bR^n$ verhalten. Diese Intuition wird durch folgende Definition formalisiert:
\begin{definition}
	Ein Vektorraum $V$ über einem Körper $K$ ist ein Tupel $(V, K, +, \cdot)$, sodass $(V, +)$ eine abelsche Gruppe bildet und sodass $\cdot$ eine Abbildung $K \times V \to V$ ist, welche für $a,b \in K$ und $\vv,\vw \in V$ die folgenden Axiome erfüllt:
	\begin{enumerate}
		\item $a(\vv + \vw) = a\vv + a\vw$
		\item $(a+b)\vv = a\vv + b\vv$
		\item $(ab) \cdot \vv = a (b \cdot \vv)$
		\item $1_K \vv = \vv$			
	\end{enumerate}
\end{definition}
\noindent Die vier zusätzlich gegebenen Axiome entsprechen der Vorraussetzung, dass $\cdot$ ein Ringhomomorphismus $K \to \text{End}(V)$ ist. Falls dies mehr Verwirrung als Klarheit schafft, kann man sich aber natürlich auch einfach die Axiome merken.
\begin{definition}
	Sei $V$ ein Vektorraum über einem Körper $K$. Eine \tbf{Norm} auf $V$ ist eine Funktion $\norm{-} : V \to \bR$, welche für $\lambda \in K$ und $\vv, \vw \in V$ folgenden Eigenschaften hat:
	\begin{enumerate}
		\item \ul{\tbf{Positivität:}} $\norm{\vv} \geq 0$
		\item \ul{\tbf{Halblinearität:}} $\norm{\lambda\vv} = \lambda \norm{\vv}$
		\item \ul{\tbf{Dreiecksungleichung:}} $\norm{\vv + \vw} \leq \norm{\vv} + \norm{\vw}$
	\end{enumerate}
\end{definition}
\begin{theorem}
	Gegeben eine Norm $\norm{-} : V \to \bR$ bildet $d(\vv,\vw) = \norm{\vv - \vw}$ eine Metrik auf $V$.
\end{theorem}
%
%
%
%
%
%
%
%
%
%
\section{Folgen}
\begin{definition}
	Eine Folge ist eine Abbildung $\bN \to T$ in einen Topologischen Raum $(T, \tau)$. Für eine Folge $a$ schreibt man in der Regel "$a_n$" statt "$a(n)$".
\end{definition}
\begin{definition}
	Sei $\an$ eine Folge in einem Topologischen Raum $(T, \tau)$. Wir nennen ein Element $a \in T$ den \textbf{Grenzwert} von $\an$, falls man für jede beliebige offene Umgebung $U$ von $a$ ein Folgenglied $a_{n_0}$ mit $n_0 \in \bN$ finden kann, sodass alle darauf folgenden Folgenglieder in $U$ enthalten sind. Als Formel:
	\begin{align*}
		\exists N \in \bN : n \geq N \Rightarrow a_n \in U
	\end{align*}
	Eine Folge, die einen Grenzwert hat, heißt \textbf{konvergent}.
\end{definition}
\begin{theorem}
	Sei $(a_n)_{n \in \bN}$ eine Folge in einem Metrischen Raum $(M, d)$. $a \in M$ ist genau dann ein Grenzwert von $(a_n)_{n \in \bN}$, falls
	\begin{align*}
		\forall \epsilon \in \bR_{> 0} : \exists n_0 \in \bN : \forall n \geq n_0 : d(a_n, a) \leq \epsilon
	\end{align*}
\end{theorem}
\begin{theorem}
	Der Grenzwert einer Folge in einem Metrischen Raum ist eindeutig.
\end{theorem}
\begin{proof}
	Angenommen, eine Folge $a_n$ hat zwei Grenzwerte $a \neq b$. So gilt für $\epsilon = \frac{1}{2}(a-b)$, dass $n_1, n_2 \in \bN$ existieren, sodass für alle $n \geq n_1$ (bzw. $n > n_2$)
	\begin{align*}
		d(a_n - a) < \epsilon
	\end{align*}
	und
	\begin{align*}
		d(a_n - b) < \epsilon
	\end{align*}
	Wählen wir nun $n_3 = \max(n_1, n_2)$, So gilt für alle $n \geq n_3$:
	\begin{align*}
		d(a-b) &= d(a - a_n - (b - a_n))\\
		&\leq d(a - a_n) + d(b - a_n)\\
		&< 2\epsilon\\
		&= d(a-b)
	\end{align*}
	Also $d(a-b) < d(a-b)$, was ein Widerspruch ist.
\end{proof}
\begin{theorem}
	Der Grenzwert einer Folge in einem Hausdorff-Raum $T$ ist eindeutig.
\end{theorem}
\begin{proof}
	Angenommen, die Folge $a_n$ konvergiert gegen $a \in T$. Sei $b \in T$ beliebig, sodass $a \neq b$. So existiert eine Umgebung $U \ni a$ und eine Umgebung $V \ni b$ mit $U \cap V = \emptyset$. Nach der Definition von Konvergenz nach $a$ muss ein $n_0 \in \bN$ existieren, sodass alle $a_n$ ab $a_{n_0}$ in $U$ enthalten sind. Für konvergenz gegen $V$ müssten nun ab einem Gewissen Punkt alle Folgenglieder außerdem in $V$ enthalten sein. Aber $U \cap V = \emptyset$, also kann es kein Folgenglied geben, welches in beiden Umgebungen enthalten ist. Also konvergiert die Folge nicht gegen $b$.
\end{proof}
\noindent Die Version für Metrische Räume folgt natürlich gemäß Satz \ref{theorem:metricspaceishausdorff} aus der Version für Hausdorff-Räume. Ich persönlich finde den allgemeineren Beweis deutlich übersichtlicher, und hoffe, dieses Beispiel dient als gute Rechtfertigung dafür, warum ich in diesen Notizen gerne Sätze in voller Metrischer / Topologischer Allgemeinheit formuliere und beweise.
\begin{definition}
	Eine Folge $\an$ in einem Metrischen Raum $M$ heißt \tbf{beschränkt}, falls sie in einem $\epsilon$-Ball in $M$ enthalten ist, also wenn:
	\begin{align*}
		\exists m \in M : \exists \epsilon \in \bR_{> 0} : \forall n \in \bN : a_n \in B_\epsilon(m)
	\end{align*}
\end{definition}
\begin{definition}
	Der \tbf{Durchmesser} einer Folge $\an$ ist die Reelle Zahl $D = \sup(d(a_n,a_m) \mid n,m \in \bN)$.
\end{definition}
\begin{theorem}
	Eine Folge ist genau dann beschränkt, wenn ihr Durchmesser endlich ist.
\end{theorem}
\begin{proof}
	Sei $a_k$ ein beliebiges Folgenglied. So ist die gesamte Folge im Ball $B_D(a_k)$ enthalten.
\end{proof}
\begin{theorem}
	Jede konvergente Folge in einem Metrischen Raum ist beschränkt.
\end{theorem}
\begin{proof}
	Sei $a_n$ eine Folge, welche gegen den Grenzwert $a$ konvergiert. So gilt per Definition von Konvergenz für ein beliebiges $\epsilon \in \bR_{> 0}$:
	\begin{align*}
		\exists n_0 \in \bN : \forall n \geq n_0 : d(a_n - a) \leq \epsilon
	\end{align*}
	Es folgt:
	\begin{itemize}
		\item Alle $a_n$ mit $n \geq n_0$ sind im Ball $B_\epsilon(a)$ enthalten.
		\item Die Menge $\{a_n \mid n < n_0\}$ ist endlich, also existiert ein maximaler Abstand zu $a$:
		\begin{align*}
			\forall n < n_0 : a_n \in B_{\max(d(a,a_1), \hdots, d(a,a_{n_0})}(a)
		\end{align*}
	\end{itemize} 
	Nehmen wir nun das Maximum der beiden Radien, so ist die gesamte Folge im entstehenenden Ball enthalten, also begrenzt.
\end{proof}
\begin{theorem}
	\label{theorem:increasingandboundedsequence}
	Jede begrenzte, monoton steigende Folge in einem geordneten Körper $K$ ist konvergent.
\end{theorem}
\begin{theorem}
	\label{theorem:rechenregelnfürfolgen}
	Seien $\an$ und $\bn$ konvergente Folgen in eine Körper $K$ und $a$ und $b$ die dazugehörigen Grenzwerte. So gilt:
	\begin{itemize}
		\item $(a_n + b_n)_{n \in \bN}$ ist konvergent mit Grenzwert $a + b$
		\item $(a_n b_n)_{n \in \bN}$ ist konvergent mit Grenzwert $ab$
		\item Für $\lambda \in \bR$ ist $(\lambda a_n)_{n \in \bN}$ konvergent mit Grenzwert $\lambda a$.
		\item Falls $a \neq 0$ ist $(\frac{1}{a_n})_{n \in \bN}$ konvergent mit Grenzwert $\frac{1}{a}$.
	\end{itemize}
\end{theorem}
\begin{proof}
	\phantom{}
	\begin{enumerate}
		\item
		\item $(a_n b_n)_{n \in \bN}$ ist konvergent mit Grenzwert $ab$:
		\begin{align*}
			\abs{a_n b_n - ab} = \abs{a_n b_n - a_n b + a_n b - a b} \leq \abs{a_n}\abs{b_n - b} + \abs{b}\abs{a_n - a}
		\end{align*}
		Da die Folgen $a_n$ und $b_n$ konvergieren sind sie Beschränkt mit Schranke $C$:
		\begin{align*}
			\abs{a_n}\abs{b_n - b} + \abs{b}\abs{a_n - a} \leq C(\abs{b_n - b} + \abs{a_n - a})
		\end{align*}
		Durch die Konvergenz von $b_n$ und $a_n$ finden wir nun $\delta$, sodass 
		\begin{align*}
			C(\abs{b_n - b} + \abs{a_n - a}) \leq C\left(\frac{\epsilon}{2C} + \frac{\epsilon}{2C}\right) = \epsilon
		\end{align*}
		\item
		\item
	\end{enumerate}	
\end{proof}
\begin{theorem}
	Seien $\an$ und $\bn$ konvergent mit Grenzwerten $a$ und $b$. Sei außerdem $\forall n \in \bN : a_n \leq b_n$. So ist auch $a \leq b$.
\end{theorem}
\begin{theorem}
	Seien $\an$ und $\bn$ konvergent mit Grenzwerten $a$ und $b$. Sei außerdem $\forall n \in \bN : a_n < b_n$. So ist immer noch $a \leq b$.
\end{theorem}
\begin{definition}
	Eine Folge $\an$ heißt \textbf{bestimmt divergent gegen $\infty$}, geschrieben
	\begin{align*}
		\lim_{n \to \infty} a_n = \infty
	\end{align*}
	Falls
	\begin{align*}
		\forall c \in \bR : \exists n_0 \in \bN : \forall n \geq n_0 : a_n > c
	\end{align*}
\end{definition}
\begin{definition}
	Eine Zahl heißt \textbf{Häufungspunkt} oder \textbf{Häufungswert} einer Folge, wenn sie der Grenzwert einer Teilfolge ist.
\end{definition}
\begin{theorem}
	\emph{\textbf{Bolzano-Weierstraß:}} Jede beschränkte Folge in $\bR$ besitzt eine konvergente Teilfolge.
\end{theorem}
\begin{proofsketch}
	Beweis durch Intervallhalbierung: Wähle Intervall $[s,S]$, sodass $s$ das Infimum und $S$ das Supremum ist. Wähle bei Halbierung das Intervall, welches unendlich viele Folgenglieder enthält.
\end{proofsketch}
\begin{theorem}
	Hat eine beschränkte Folge genau einen Häufungswert, so konvergiert sie gegen diesen Häufungswert.
\end{theorem}
\begin{definition}
	Eine Folge heißt \textbf{Cauchy-Folge}, falls 
	\begin{align*}
		\forall \epsilon \in \bR : \exists n_0 \in \bN : \forall m, n \geq n_0 : \abs{a_m - a_n} < \epsilon
	\end{align*}
\end{definition}
\begin{theorem}
	Jede Cauchyfolge in $\bR$ ist konvergent.
\end{theorem}
\noindent
Dieser Satz ist je nach verwendeter Konstruktion der reellen Zahlen entweder ein Axiom oder folgt aus den Axiomen.
\begin{theorem}
	Jede konvergente Folge in $\bR$ ist Cauchy.
\end{theorem}
\begin{proof}
	Angenommen, eine Folge $a_n : \bN \to \bR$ konvergiert. So gilt:
	\begin{align*}
		\lim_{n \to \infty} a_n = a \Leftrightarrow \forall \epsilon \in \bR^+ : \exists n_0 \in \bN : \forall n \geq n_0 : \abs{a_n - a} < \epsilon
	\end{align*}
	Sei nun $n_0 \in \bN$ und $m , n > n_0$ mit $\abs{a_m - a} < \frac{\epsilon}{2}$ und $\abs{a_n - a} < \frac{\epsilon}{2}$. Nun gilt 
	\begin{align*}
		\abs{a_m - a_n} \leq \abs{a_m - a} + \abs{a_n - a} < \epsilon,
	\end{align*}
	also ist $a_n$ Cauchy.
\end{proof}
\begin{corollary}
	Jede monoton wachsende, beschränkte Folge ist Cauchy.
\end{corollary}
\begin{proof}
	Jede monoton wachsende beschränkte Folge ist konvergent, also Cauchy.
\end{proof}
\begin{definition}
	Gegeben eine beschränkte Folge $\an$ nennen wir den Grenzwert der oberen Schranken der Folge den \textbf{Limes superior}:
	\begin{align*}
		\limsup_{n \to \infty} a_n = \lim_{n \to \infty} \left(\sup_{m \geq n} a_m\right)
	\end{align*}
	Analog definieren wir für untere Schranken den \textbf{Limes inferior}:
	\begin{align*}
		\liminf_{n \to \infty} a_n = \lim_{n \to \infty} \left(\inf_{m \geq n} a_m\right)
	\end{align*}
\end{definition}
\begin{theorem}
	Es gilt $\limsup_{n \to \infty} a_n \leq a$ gdw. für alle $\epsilon \in \bR$ die Menge $\{k \in \bN \mid a_k \geq a + \epsilon\}$ endlich ist.
\end{theorem}
\begin{theorem}
	Es gilt $\limsup_{n \to \infty} a_n \geq a$ gdw. für alle $\epsilon \in \bR$ die Menge $\{k \in \bN \mid a_k \geq a - \epsilon\}$ unendlich ist.
\end{theorem}
\begin{theorem}
	Sei $\an$ eine beschränkte Folge. So ist $\limsup a_n$ der größte und $\liminf a_n$ der kleinste Häufungswert der Folge.
\end{theorem}
\begin{corollary}
	Die Folge $\an$ konvergiert genau dann, wenn sie beschränkt ist mit $\limsup a_n = \liminf a_n$.
\end{corollary}
\begin{definition}
	Sei $M \subset \bR$. Eine Zahl $a \in \bR \cup \{-\infty\}$ heißt \tbf{größte untere Schranke} oder \tbf{Infimum} der Menge $M$, wenn:
	\begin{enumerate}
		\item $\forall x \in M : a \leq x$
		\item $\forall a < a' : \exists x \in M : x < a'$
	\end{enumerate}
\end{definition}
\noindent Der folgende Trick wird später in der Integrations- und Maßtheorie oft nützlich:
\begin{proposition}
	Sei $M \subset \bR$. Sei $\inf M \neq -\infty$. Dann gilt:
	\begin{align*}
		\forall \epsilon \in \bR_{> 0} : \exists m \in M : m < \inf M + \epsilon
	\end{align*}
\end{proposition}

\begin{definition}
	Sei $M \subset \bR$. Eine Zahl $a \in \bR \cup \{\infty\}$ heißt \tbf{kleinste obere Schranke} oder \tbf{Supremum} der Menge $M$, wenn:
	\begin{enumerate}
		\item $\forall x \in M : x \leq a$
		\item $\forall a' < a : \exists x \in M : a' < x$
	\end{enumerate}
\end{definition}
\begin{theorem}
	Sei $M$ nichtleer. So gibt es Folgen $x_n, y_n \in M$, sodass
	\begin{align*}
		\lim_{n \to \infty} x_n = \inf M
	\end{align*}
	und 
	\begin{align*}
		\lim_{n \to \infty} y_n = \sup M
	\end{align*}
\end{theorem}
\begin{proof}
	Im Fall einer nach oben unbeschränkten Menge lässt sich trivial eine Folge finden, welche gegen $\sup M = \infty$ konvergiert, eben so für das Infimum im Fall einer nach unten unbeschränkten Menge.
	\newpar
	Sei nun $a_1 \in M$ und $b_1 \geq M$. Wir konstruieren nun durch sukzessives Halbieren des Intervalls $[a_1, b_1]$ eine Intervallschachtelung, welche gegen das Supremum konvergiert:
	\begin{align*}
		I_{n+1} = [a_{n+1}, b_{n+1}] = 
		\begin{cases}
			[(a_n + b_n)/2, b_n] & [(a_n + b_n)/2, b_n] \cap M \neq \emptyset\\
			[a_n, (a_n + b_n)/2] &\\
		\end{cases}
	\end{align*}
\end{proof}
\begin{corollary}
	Jede Menge $M \subset \bR$ hat genau ein Supremum und genau ein Infimum.
\end{corollary}
\begin{proof}
	In der vorherigen Intervallschachtelung ist jedes Intervall Obermenge eines Intervalls in $M$. Da also das Supremum und das Infimum in der Intervallschachtelung enthalten sind, sind die auch in $M$ enthalten.
\end{proof}
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
\section{Stetigkeit}
\begin{definition}
	\ul{\textbf{Stetigkeit in Topologischen Räumen:}} Seien $X, Y$ Topologische Räume. Eine Funktion $f : X \to Y$ heißt \textbf{stetig}, wenn das Urbild jeder offener Menge offen ist.
\end{definition}
\begin{theorem}
	\ul{\textbf{$\epsilon$-$\delta$-Kriterium:}} Seien $M, N$ Metrische Räume mit Metriken $d_M$ und $d_N$. Eine Funktion $f : M \to N$ heißt \textbf{stetig} an einem Punkt $p \in M$, wenn:
	\begin{align*}
		\forall \epsilon \in \bR^+ : \exists \delta \in \bR^+ : d_M(x,p) < \delta \implies d_N(f(x), f(p)) < \epsilon
	\end{align*}
	Die Funktion ist genau dann stetig im Topologischen Sinne, wenn das $\epsilon-\delta$-Kriterium an allen Punkten erfüllt ist.
\end{theorem}
\begin{anmerkung}
	Im Fall einer Funktion $\bR \to \bR$ also:
	\begin{align*}
		\forall \epsilon \in \bR^+ : \exists \delta \in \bR^+ : \abs{x - p} < \delta \implies \abs{f(x), - f(p)} < \epsilon
	\end{align*}
\end{anmerkung}
\begin{proofsketch}
	Left as an exercise to the reader :) (I'll get back to it)
\end{proofsketch}
\begin{definition}
	\ul{\textbf{Folgenstetigkeit:}} Eine Folge $x_k$ heißt \tbf{folgenstetig}, wenn:
	\begin{align*}
		\lim_{k \to \infty} x_k = x_0 \implies \lim_{k \to \infty} f(x_k) = f(x_0)
	\end{align*}
\end{definition}
\begin{theorem}
	Jede stetige Funktion ist folgenstetig.
\end{theorem}
\begin{proof}
	Sei $\lim_{k \to \infty} x_k = x_0$. \newpar
	Wähle zu $\epsilon \in \bR^+$ ein $\delta \in \bR^+$, sodass $\forall x \in D$ mit $\abs{x - x_0} < \delta$:
	\begin{align*}
		\abs{f(x) - f(x_0)} < \epsilon
	\end{align*}
	Da die Aussage $\forall x \in D$ mit $\abs{x - x_0} < \delta$ gilt, gilt sie insbesondere für $x_k$ mit groß genugem $k$.
\end{proof}
\begin{theorem}
	Jede folgenstetige Funktion in $\bR$ ist stetig.
\end{theorem}
\begin{proof}
	Angenommen, $f$ sei folgenstetig, aber nicht stetig. \newpar
	Dann gibt es ein $\epsilon > 0$, sodass für kein $\abs{x_k - x_0} < \delta \in \bR^+$ die Bedingung
	\begin{align*}
		\abs{f(x) - f(x_0)} < \epsilon
	\end{align*}
	erfüllt ist.\newpar
	Wählen wir nun $\delta_k = \frac{1}{k}$ mit $k \in \bN$, so gibt es jeweils ein $x_k \in D$ mit $\abs{x_k - x_0} < \frac{1}{k}$, aber $\abs{f(x_k) - f(x_0)} \geq \epsilon$. Dies ist ein Widerspruch zur Folgenstetigkeit.
\end{proof}
\begin{theorem}
	Die Verkettung stetiger Funktionen ist stetig.
\end{theorem}
\begin{proof}
	Durch Folgenstetigkeit. 
	\begin{align*}
		\lim_{x \to x_0} g(f(x)) = g\left(\lim_{x \to x_0} f(x)\right) = g(f(x_0))
	\end{align*}
\end{proof}
\begin{theorem}
	Das Produkt stetiger Funktionen ist stetig.
\end{theorem}
\begin{proof}
	\begin{align*}
		\lim_{x \to x_0} f(x)g(x) = \lim_{x \to x_0} f(x) \lim_{x \to x_0} g(x) = f(x_0)g(x_0)
	\end{align*}
\end{proof}
\begin{theorem}
	Das Inverse einer stetigen Funktion ist stetig.
\end{theorem}
\begin{proofsketch}
	Monotone Surjektionen auf kompakte Mengen sind stetig.
\end{proofsketch}
\begin{theorem}
	Eine Funktion $f = (f_1, \hdots, f_n)$ ist genau dann an einem Punkt $p$ stetig, wenn dort alle Komponentenfunktionen $f_i$ stetig sind.
\end{theorem}
\begin{theorem}
	\emph{\textbf{Zwischenwertsatz:}} Gegeben $a < b$ in $\bR$ nimmt eine stetige Funktion $f : [a,b] \to \bR$ jeden Wert zwischen $f(a)$ und $f(b)$ an.
\end{theorem}
\begin{proof}
	Sei $z \in [f(a), f(b)]$ und
	\begin{align*}
		p = \sup \{x \in [a,b] : f(p) \leq z\}.
	\end{align*}
	Zu zeigen ist $f(p) = z$. Angenommen, $f(p) < z$. Da $z \leq f(b)$ folgt $p < b$. Sei nun $\epsilon = z - f(p)$. Aufgrund der Stetigkeit von $f$ existiert ein $\delta$, sodass für $q := p + \delta$ sowohl $p < q$ als auch $f(p) \leq z$ gelten. Somit war $p$ kein Supremum, was ein Widerspruch ist.
\end{proof}
\begin{corollary}
	Das Bild eines Intervalles unter einer Stetigen Funktion ist ebenfalls ein Intervall.
\end{corollary}
\begin{theorem}
	Ist das Bild einer monotonen Abbildung $f$ : $\bR \subset D \to \bR$ ein Intervall in $\bR$, so ist $f$ stetig.
\end{theorem}
\begin{corollary}
	Ist eine Funktion $f : [a,b] \to \bR$ streng monoton und stetig, so ist auch die Umkehrfunktion streng monoton und stetig.
\end{corollary}
\begin{proof}
	Die Umkehrfunktion ist klar monoton (sonst könnte man sie nicht erneut invertieren, um die ursprüngliche Funktion zu erhalten). Außerdem ist ihr Bild das Intervall $[a,b]$. Somit ist die Umkehrfunktion stetig.
\end{proof}
\begin{theorem}
	\emph{\textbf{Existenz von Extremalstellen auf Kompakta:}} Jede stetige Funktion auf einem nichtleeren Kompaktum hat ein Maximum und ein Minimum.\\
	\textbf{Alternativ:} Jede stetige Funktion auf einem nichtleeren Kompaktum nimmt das Supremum und Infimum ihrer Funktionswerte als Funktionswert an.\\
	\textbf{Also:}
	\begin{align*}
		\forall f : D \to \bR : \exists x_0, x_1 \in D : f(x_0) = \inf_{x \in D} f(x), \quad f(x_1) = \sup_{x \in D} f(x)
	\end{align*}
\end{theorem}
\begin{proof}
	Wir zeigen die Aussage über das Infimum, das Supremum folgt dann analog. Setze 
	\begin{align*}
		\alpha = \inf_{x \in D} f(x) \in [-\infty,\infty)
	\end{align*}
	Nach Definition des Infimums gibt es eine Folge $x_k \in D$ mit $f(x_k) \to a$. Da $D$ beschränkt ist, ist die Folge beschränkt. Nach Satz von Bolzano-Weierstraß gibt es eine Teilfolge $x_{k_j}$, welche gegen einen Wert $x_0 \in D$ konvergiert.
	\newpar
	Wir wissen, dass $f(x_{k_j})$ gegen $f(x_0)$ konvergiert (dies ist genau die Folgenstetigkeit von $f$). Aus der Eindeutigkeit des Grenzwerts folgt nun $f(x_0) = \alpha$.
\end{proof}
%
%
%
%
%
%
%
%
%
%
\chapter{Formale Konstruktion der Reellen Zahlen}
%
%
%
%
%
%
%
%
%
\chapter{Reihen}
\begin{definition}
	Sei $\an$ eine Folge. Wir nennen die Zahl
	\begin{align*}
		s_n := \sum_{k = 1}^n a_k
	\end{align*}
	Die \textbf{$n$-te Partialsumme} der Folge. Wir nennen Folgen der Form $\sn$ unendliche Reihen und schreiben solche auch als
	\begin{align*}
		\sum_{k = 1}^\infty a_k.
	\end{align*}
	Ist die Folge $\sn$ konvergent, bezeichnet dieser Ausdruck außerdem den Grenzwert der Folge. Per Definition ist
	\begin{align*}
		\sum_{k = 1}^\infty a_k = s \Leftrightarrow \lim_{n \to \infty} \sum_{k = 1}^n a_k = s
	\end{align*}
\end{definition}
\newpar
Gemäß Satz \ref{theorem:rechenregelnfürfolgen} können \textbf{konvergente} Reihen wie intuitiv erwartet addiert, skalarmultipliziert etc. werden.
\section{Konvergenzkriterien}
\begin{theorem} 
	\textbf{\emph{Nullfolgentest:}} Ist eine Reihe $\displaystyle \sum_{k = 1}^\infty a_k$ 		konvergent, so folgt $\displaystyle \lim_{k \to \infty} a_k = 0$.
\end{theorem}
\begin{theorem} 
	\textbf{\emph{Konvergenzkriterium von Cauchy:}} Eine Reihe $\displaystyle \sum_{n = 1}^\infty a_k$ ist genau dann konvergent, wenn 
	\begin{align*}
		\forall \epsilon \in \bR^+ : \exists n_0 \in \bN : \forall n,m > n_0 : \abs{\sum^m_{k = n} a_k} < \epsilon
	\end{align*}	
\end{theorem}
\begin{proof}
	Dies ist genau die Bedingung, dass die Reihe eine Cauchyfolge ist.
\end{proof}
\begin{theorem} 
	\textbf{\emph{Reihen mit positiven Gliedern:}} Falls $\forall k \in \bN : a_k > 0$, so konvergiert die Reihe $\sum_{k = 1}^\infty a_k$ genau dann, wenn die Folge ihrer Partialsummen nach oben beschränkt ist.
\end{theorem}
\begin{proof}
	Die Folge der Partialsummen ist dann monoton steigend und beschränkt, also konvergent nach \ref{theorem:increasingandboundedsequence}
\end{proof}
\begin{theorem} \textbf{\emph{Leibnizkriterium:}}
	Sei $a_k$ eine reelle, monoton fallende Nullfolge. So ist die Reihe 
	$\sum_{k = 1}^\infty (-1)^k a_k$ konvergent. Es gilt außerdem:
	\begin{align*}
		0 \leq (-1)^n \sum_{k = n}^\infty (-1)^k a_k \leq a_n
	\end{align*}
\end{theorem}
\begin{proof}
	Sei $S_n$ die $n$-te Partialsumme.
	\begin{itemize}
		\item Es gilt $S_{n+2} - S_n = a_{2n+2} - a_{2n+1} \leq 0$, also ist die Folge der Partialsummen mit geradem Index streng monoton fallend.
		\item Es gilt $S_{n+1} - S_{n-1} = -a_{2n+1} + a_{2n} \geq 0$, also ist die Teilfolge der Partialsummen mit ungeradem Index streng monoton steigend.
		\item Es gilt außerdem $S_1 \leq S_{2n+1} \leq S_{2n} \leq S_0$, also ist die gerade Partialsummen nach unten beschränkt und die ungeraden Partialsummen sind nach oben beschränkt.
		\item Zuletzt gilt auch noch $S_{n+1} - S_n \to 0$, da beides Nullfolgen sind, also konvergieren beide Teilfolgen gegen den gleichen Grenzwert, also konvergiert die gesamte Reihe gegen diesen Grenzwert.
	\end{itemize}
\end{proof}
\begin{theorem}
	\emph{\textbf{Majorantenkriterium:}} Gilt $\abs{a_k} \leq c_k \in [0, \infty)$ und $\sum_{k=0}^\infty c_k < \infty$, so konvergiert die Reihe $\sum_{k=0}^\infty a_k$ absolut.
\end{theorem}
\begin{theorem}
	\emph{\textbf{Quotientenkriterium:}} Gibt es ein $\theta \in [0,1)$ und ein $n \in \bN$ sodass 
	\begin{align*}
		\forall k \geq n : \frac{\abs{a_{k+1}}}{\abs{a_k}} \leq \theta,
	\end{align*}
	so konvergiert die Reihe $\sum_{k=0}^\infty a_k$ absolut.
\end{theorem}
\begin{theorem}
	Eine äquivalente Bedingung ist $\limsup \abs{\frac{a_{n+1}}{a_n}} < 1$.
\end{theorem}
\begin{proof}
	Per Induktion gilt 
	\begin{align*}
		\forall k \geq n : \abs{a_k} \leq \theta^{k-n} \abs{a_n}.
	\end{align*}
	\newpar
	Es folgt 
	\begin{align*}
		\sum_{k = n}^\infty \abs{a_k} &\leq \sum_{k = n}^\infty \theta^{k-n} \abs{a_n}\\
		&= \abs{a_n} \sum_{k = n}^\infty \theta^{k-n}\\
		&= \abs{a_n} \cdot \frac{1}{1-\theta}
	\end{align*}
\end{proof}
\begin{example}
	Wir betrachten die Reihe
	\begin{align*}
		\sum_{k=1}^\infty a_k := \sum_{k=1}^\infty \frac{k}{e^k}
	\end{align*}
	Der Quotiententest liefert für $k \geq 10$:
	\begin{align*}
		\abs{\frac{a_{k+1}}{a_k}} = \abs{\frac{(k + 1)e^k}{ke^{k+1}}} = \abs{\frac{k + 1}{ke}} < \frac{1}{2}
	\end{align*}
	Also konvergiert die Reihe absolut. (Die Abschätzung ist hier natürlich sehr grob.)
\end{example}
\begin{theorem}
	\emph{\textbf{Wurzelkriterium:}} Gibt es ein $\theta \in [0,1)$ und ein $n \in \bN$ sodass 
	\begin{align*}
		\forall k \geq n : \sqrt[k]{\abs{a_k}} \leq \theta,
	\end{align*}
	so konvergiert die Reihe $\sum_{k=0}^\infty a_k$ absolut.
\end{theorem}
\begin{anmerkung}
	Existiert ein $n \in \bN$, sodass
	\begin{align*}
		\forall k \geq n : \frac{\abs{a_{k+1}}}{\abs{a_k}} \geq 1
	\end{align*}
	oder
	\begin{align*}
		\forall k \geq n : \sqrt[k]{\abs{a_k}} \geq 1,
	\end{align*}
	so ist die Reihe offensichtlich nicht Cauchy, divergiert also.
\end{anmerkung}
\begin{theorem}
	Eine absolut konvergente Reihe kann beliebig umgeordnet werden, ohne den Grenzwert zu verändern.
\end{theorem}


\chapter{Eindimensionale Ableitungen}
\section{Differenzierbarkeitsbegriffe im Mehrdimensionalen}
\subsection{Totale Differenzierbarkeit}
\begin{definition}
	Eine Abbildung $f : \bR^n \supset \Omega \to \bR^m$ heißt \tbf{total differenzierbar} oder einfach \tbf{differenzierbar} am Punkt $p \in \Omega$, falls eine lineare Abbildung $Df(p) : \bR^n \to \bR^n$ gibt, sodass
	\begin{align*}
		\lim_{h \to 0} \frac{f(p + h) - f(p) - Df(p)(h)}{\abs{h}} = 0											
	\end{align*}
	Existiert ein solches $Df(p)$, nennen wir es das \tbf{Differential} von $f$ am Punkt $p$. Existiert eine solche Abbildung für alle Punkte $p \in \Omega$, so nennen wir die Abbildung $Df : \bR^n \supset \Omega \to L(\bR^n, \bR^m)$ \tbf{*das* Differential} von $f$.
\end{definition}

\subsection{Partielle Differenzierbarkeit}
\begin{definition}
	Die \tbf{partielle Ableitung} einer Funktion $f : \bR^n \supset \omega \to \bR^m$ ist die eindimensionale Ableitung entlang einer der Koordinatenachsen:
	\begin{align*}
		\partial_j f(x) &= \left(\frac{d}{dh} f(x + he_j)\right)(0)\\
		&= \lim_{h \to 0} \frac{f(x + he_j) - f(x)}{h}
	\end{align*}
\end{definition}
\section{Ableitungsregeln}
\subsection{Kettenregel}
\begin{theorem}
	Es gilt
	\begin{align*}
		D(g \circ f)(x_0) = Dg(f(x_0))Df(x_0)
	\end{align*}
\end{theorem}
\subsection{Produktregel}
\subsection{Quotientenregel}
\subsection{Ableitung von Umkehrfunktionen}
\begin{theorem}
	Sei $I \in \bR$ ein mehrpunktiges Intervall und $f : I \to \bR$ streng monoton, stetig auf $I$ und differenzierbar bei $p$. So ist die Umkehrfunktion $f^{-1} : f(I) \to \bR$ differenzierbar bei $q = f(p)$ mit:
	\begin{align*}
		(f^{-1})'(q) = \frac{1}{f'(f^{-1}(q))}
	\end{align*}
\end{theorem}
\begin{proof}
	Kettenregel:
	\begin{align*}
		f(f^{-1}(q)) &= q\\
		\implies (f(f^{-1}(q)))' &= 1\\
		\implies (f^{-1})'(q) \cdot f'(f^{-1}(q)) &= 1\\
		\implies (f^{-1})'(q) &= \frac{1}{f'(f^{-1}(q))}
	\end{align*}
\end{proof}
\section{Der Mittelwertsatz}
\begin{theorem}
	Nimmt eine Funktion $f : (a,b) \to \bR$ an einem Punkt $p$ ein Maximum oder Minimum an, so gilt $f'(p) = 0$.
\end{theorem}
\begin{theorem}
	\emph{\textbf{Satz von Rolle:}} Sei $f : [a,b] \to \bR$ stetig auf dem kompakten Intervall $[a,b]$ und differenzierbar auf dem offenen Intervall $(a,b)$. Gilt dann $f(a) = f(b)$, so gibt es $p \in (a,b)$ mit $f'(p) = 0$.
\end{theorem}
\begin{proof}
	Im Abschnitt über Stetigkeit haben wir bewiesen, dass es Punkte $p,q \in [a,b]$ gibt, an denen $f$ sein Maximum und Minimum annimmt. Ist einer dieser Punkte in $(a,b)$ folgt der Satz trivial. Liegen die Punkte $p$ und $q$ hingegen am Rand, so folgt aus $f(a) = f(b)$, dass $p = q$ ist, und die Funktion somit konstant.
\end{proof}
\begin{theorem}
	\emph{\textbf{Mittelwertsatz:}} Sei $f : [a,b] \to \bR$ stetig auf dem kompakten Intervall $[a,b]$ und differenzierbar auf dem offenen Intervall $(a,b)$. So existiert ein $p \in (a,b)$, sodass
	\begin{align*}
		f'(p) = \frac{f(b) - f(a)}{b - a}
	\end{align*}
\end{theorem}
\begin{proof}
	Man wende den Satz von Rolle auf die Funktion
	\begin{align*}
		g : [a,b] &\to \bR\\
		x &\mapsto f(x) - f(a) - (x - a)\frac{f(b) - f(a)}{b - a}
	\end{align*}
	an.
\end{proof}
%
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
\chapter{Riemannintegration über reelle Intervalle}
\section{Treppen- und Regelfunktionen}
\begin{definition}
	Eine Funktion $f \in B([a,b])$ (eine beschränkte Funktion mit Definitionsbereich $[a,b]$) heißt \textbf{Treppenfunktion}, falls es Punkte $a = x_0 < x_1 < \hdots < x_n = b$ gibt, sodass $f$ auf jedem offenen Teilintervall $(x_k, x_{k+1})$ konstant ist. Wir nennen dann $(x_0, \hdots, x_n)$ eine \tbf{zu $f$ gehörige Unterteilung von $[a,b]$}. Die Menge aller Treppenfunktionen auf dem Intervall $[a,b]$ schreiben wir $T([a,b])$.
\end{definition}
\begin{definition}
	Eine Funktion $f : [a,b] \to \bR$ heißt \textbf{Regelfunktion}, falls es eine Folge $f_n$ von Treppenfunktionen gibt, welche Gleichmäßig gegen $f$ konvergiert. Die Menge aller Treppenfunktionen auf dem Intervall $[a,b]$ schreiben wir $R([a,b])$. 
\end{definition}
\begin{theorem}
	Sei $f_n$ eine Funktionenfolge, welche gleichmäßig gegen eine Funktion $f$ konvergiert. Hat jedes $f_n$ überall einseitige Grenzwerte, so auch $f$.
\end{theorem}
\begin{theorem}
	Eine Funktion $f : [a,b] \to \bR$ ist genau dann eine Regelfunktion, wenn für alle $c \in [a,b]$ die einseitigen Grenzwerte
	\begin{align*}
		\liminf_{x \to c} f(x) \text{ und } \limsup_{x \to c} f(x)
	\end{align*}
	existieren.
\end{theorem}
\begin{corollary}
	\label{corollary:stetig->regel}
	Jede stetige Funktion ist eine Regelfunktion.
\end{corollary}
\section{Integration von Treppenfunktionen}
\begin{definition}
	Sei $f$ eine Regelfunktion. Sei eine Unterteilung $x_0 < \hdots < x_n$ gegeben, sodass $f$ auf dem offenen Intervall $(x_i, x_{i+1})$ den Wert $c_i$ annimmt. Wir nennen die Zahl
	\begin{align*}
		I(f) := \sum_{i=0}^n c_i(x_{i+1} - x_i)
	\end{align*}
	Das \textbf{Integral} von $f$ über $[a,b]$ und schreiben auch $I(f) = \int_a^b f(x) dx = \int_a^b f$
\end{definition}
\begin{lemma}
	Der Wert von $I(f)$ ist unabhängig von der Wahl der Unterteilung.
\end{lemma}
\noindent Betrachte hierfür die gemeinsame Verfeinerung, bei der alle Zwischenpunkte aus zwei verschiedenen Unterteilungen vorkommen.
\clearpage
\begin{theorem} Die Abbildung $I(f)$ ist ein \textbf{lineares Funktional}, es gilt also:
	\label{theorem:treppenintegrallinearesfunktional}
	\begin{enumerate}
		\item $\displaystyle \forall f,g \in T([a,b]) : \int_a^b f + g = \int_a^b f + \int_a^b g$
		\item $\displaystyle \forall f \in T([a,b]) : \forall \lambda \in \bR : \int_a^b (\lambda f) = \lambda \int_a^b f$
	\end{enumerate}
	Die Abbildung ist außerdem Monoton, es gilt also:
	\begin{enumerate}
		\item[3.] $\displaystyle \forall f,g \in T([a,b]) : \left(\forall x : f(x) \leq g(x) \implies \int_a^b f \leq \int_a^b g\right)$
	\end{enumerate}
	Ferner gelten folgende obere Schranken für den Betrag der Abbildung:
	\begin{enumerate}
		\item[4.] $\displaystyle \forall f,g \in T([a,b]) : \abs{\int_a^b f} \leq \int_a^b \abs{f} \leq (b-a)\norm{f}$
	\end{enumerate}
\end{theorem}
\section{Integration von Regelfunktionen}
\begin{definition}
	Sei $f$ eine Regelfunktion auf $[a,b]$ und sei $(t_n)_{n \in \bN}$ eine Folge von Treppenfunktionen, welche gleichmäßig gegen $f$ konvergiert. Wir definieren das Integral von $f$ als:
	\begin{align*}
		\int_a^b f(x) dx = \lim_{n \to \infty} \int_a^b t_n(x) dx
	\end{align*}
\end{definition}
\begin{theorem}
	Der gesuchte Grenzwert existiert für jede Regelfunktion.
\end{theorem}
\begin{proof}
	Sei $\epsilon \in \bR^+$. Per Definition konvergiert die Folge $(t_n)_{n \in \bN}$ gleichmäßig gegen $f$, also existiert ein $n_0 \in \bN$, sodass
	\begin{align*}
		\forall n \geq n_0 : \norm{t_n - f} < \frac{\epsilon}{2(b-a)}
	\end{align*}
	Für $m, n \geq n_0$ gilt nun unter Anwendung der Dreiecksungleichung:
	\begin{align*}
		\norm{t_m - t_n} \leq \norm{t_m - f} + \norm{t_n - f} < \frac{\epsilon}{2(b-a)} + \frac{\epsilon}{2(b-a)} = \frac{\epsilon}{(b-a)}
	\end{align*}
	Gemäß \ref{theorem:treppenintegrallinearesfunktional} folgt:
	\begin{align*}
		\abs{\int_a^b t_m - \int_a^b t_n} 
		&= \abs{\int_a^b (t_m - t_n)} 
		& (\ref{theorem:treppenintegrallinearesfunktional}.1)\\
		&\leq (b-a)\norm{t_m - t_n} 
		& (\ref{theorem:treppenintegrallinearesfunktional}.4)\\ 
		&< (b-a)\frac{\epsilon}{(b-a)}\\
		&= \epsilon
	\end{align*} 
	Also ist 
	\begin{align*}
		I_t := \left(\int_a^b t_n(x) dx\right)_{n \in \bN}
	\end{align*}
	eine Cauchyfolge reeller Zahlen, also konvergent.
\end{proof}
\begin{theorem}
	Das Integral ist unabhängig von der Wahl der Folge $(t_n)_{n \in \bN}$ der Treppenfunktionen.
\end{theorem}
\begin{proof}
	Sei $(u_n)_{n \in \bN}$ eine weitere Folge in $T([a,b])$, welche gleichmäßig gegen $f$ konvergiert. Sei $\epsilon \in \bR^+$. Durch die gleichmäßige Konvergenz gegen $f$ existieren $n_1, n_2 \in \bN$, sodass:
	\begin{align*}
		\forall n \geq n_1 : \norm{f - t_n} < \frac{\epsilon}{2(a-b)}
	\end{align*}
	und 
	\begin{align*}
		\forall n \geq n_2 : \norm{f - u_n} < \frac{\epsilon}{2(a-b)}
	\end{align*}
	Für $n_0 = \max{n_1, n_2}$ gilt also
	\begin{align*}
		\forall n \geq n_0 : \norm{t_n - u_n} \leq \norm{t_n - f} + \norm{u_n - f} < \frac{\epsilon}{b-a}
	\end{align*}
	Analog zum vorherigen Beweis folgt durch \ref{theorem:treppenintegrallinearesfunktional}
	\begin{align*}
		\abs{\int_a^b t_n - \int_a^b u_n} \leq (a,b)\norm{t_n - u_n} < \epsilon
	\end{align*}
	Also konvergiert die Folge $\displaystyle \left(\int_a^b t_n - \int_a^b u_n \right)_{n \in \bN}$ gegen Null, also ist
	\begin{align*}
		\lim_{n \to \infty} \int_a^b t_n = \lim_{n \to \infty}\int_a^b u_n
	\end{align*}
\end{proof}
\begin{theorem}
	Genau wie im Fall der Treppenfunktionen ist das Integral einer Regelfunktion ebenfalls ein beschränktes monotones lineares Funktional.
\end{theorem}
\begin{anmerkung}
	Es gilt desweiteren:
	\begin{enumerate}
		\item $\displaystyle \int_a^b 1 = b - a$
		\item $\displaystyle \forall f \in T([a,b]) : \forall z \in [a,b] : \int_a^b f = \int_a^z f + \int_z^b f$
	\end{enumerate}
	Gemeinsam mit Linearität und Monotonizität, welche im Vorherigen Satz bewiesen wurden, definieren diese Vorschriften die Integralabbildung bereits eindeutig.
\end{anmerkung}
\begin{theorem}
	Sei $(f_n)_{n \in \bN}$ eine Folge von Regelfunktionen, welche gleichmäßig gegen eine Funktion $f$ konvergieren. Dann ist $f$ eine Regelfunktion und es gilt
	\begin{align*}
		\int_a^b f = \lim_{n \to \infty} \int_a^b f_n
	\end{align*}
\end{theorem}
\begin{theorem}
	\emph{\textbf{Mittelwertsatz der Integralrechnung:}} Seien $f,g \in R([a,b])$, sei $f$ stetig und $g(x) \geq 0$. Dann existiert ein $c \in [a,b]$, sodass:
	\begin{align*}
		\int_a^b fg = f(c) \int_a^b g
	\end{align*}
\end{theorem}
\begin{proof}
	Nach dem Satz von Weierstrass (Extremwertsatz) nimmt die stetige Funktion $f$ auf dem Intervall $[a,b]$ ein Minimum $m$ und ein Maximum $M$ an. Aus $m \leq f(x) \leq M$ und $g(x) \geq 0$ folgt $mg(x) \leq f(x)g(x) \leq Mg(x)$, also auch:
	\begin{align*}
		m \int_a^b g(x) dx \leq \int_a^b f(x)g(x) dx \leq M \int_a^b g(x) dx
	\end{align*}
	Also ist $\displaystyle \int_a^b f(x)g(x) dx = \alpha \int_a^b g(x) dx$ für eine Zahl $\alpha \in [m,M]$. Da $\alpha$ also zwischen den Extremwerten von $f$ liegt gibt es gemäß Zwischenwertsatz eine Zahl $c \in [a,b]$ mit $f(c) = \alpha$.
\end{proof}
\begin{corollary}
	Sei $f \in R([a,b])$ und sei $f$ stetig Dann existiert ein $c \in [a,b]$, sodass:
	\begin{align*}
		\int_a^b f = f(c) (a-b)
	\end{align*}
\end{corollary}
\begin{proof}
	Dies ist der vorherige Satz im Fall $g(x) = 1$.
\end{proof}
\section{Hauptsatz der Integralrechnung}
\begin{definition}
	Sei $f : [a,b] \to \bR$. Eine Funktion $F : [a,b] \to \bR$ heißt \textbf{Stammfunktion} von $f$, falls \begin{align*}
		\frac{d}{dx} F(x) = f(x)
	\end{align*}
\end{definition}
\begin{lemma}
	Seien $F$ und $G$ Stammfunktionen einer Funktion $f$. So gilt $\exists c \in \bR : G(x) = F(x) + c$.
\end{lemma}
\begin{proof}
	Es gilt $F' = G' = f$, also
	\begin{align*}
		(F - G)' = F' - G' = 0.
	\end{align*}
	Somit ist die Funktion $F - G$ konstant.
\end{proof}
\begin{theorem}
	\emph{\textbf{Hauptsatz der Integralrechnung:}} Sei $f : [a,b] \to \bR$ eine stetige Funktion, also insbesondere eine Regelfunktion. Definiere die Funktion
	\begin{align*}
		F(x) := \int_a^x f(t) dt
	\end{align*}
	So ist $F$ eine Stammfunktion von $f$.
	(Achtung: $a$ ist keine beliebige Konstante, sondern der kleinste Punkt im Definitionsbereich!)
\end{theorem}
\begin{proof}
	\textbf{Beweis nach Růžička:} Sei $x \in [a,b]$. Sei $h \in \bR$ mit $x + h \in [a,b]$. Dann gilt:
	\begin{align*}
		\abs{F(x+h) - F(x) - f(x)h} &= \abs{\int_a^{x+h}f(t)dt - \int_a^{x}f(t)dt - f(x)h}\\
		&= \abs{\int_x^{x+h}f(t)dt - f(x)h}\\
		&= \abs{\int_x^{x+h}f(t)dt - \int_x^{x+h} f(x) dt}\\
		&= \abs{\int_x^{x+h}(f(t) - f(x)) dt}\\
		&\leq \int_x^{x+h}\abs{f(t) - f(x)} dt &\ref{theorem:treppenintegrallinearesfunktional}\\
	\end{align*}
	Sei nun $\epsilon \in \bR^+$. Da $f$ stetig und auf dem Kompaktum $[a,b]$ definiert ist, ist $f$ gleichmäßig stetig. Also existiert ein $\delta \in \bR^+$, sodass
	\begin{align*}
		\forall x,t \in [a,b] : \abs{t - x} < \delta \implies \abs{f(t) - f(x)} < \epsilon.
	\end{align*}
	Ist nun $\abs{t-x} \leq \delta$, also $\abs{h} \leq \delta$, folgt
	\begin{align*}
		\int_x^{x+h}\abs{f(t) - f(x)} dt \leq \int_x^{x+h}\epsilon dt = \abs{h}\epsilon
	\end{align*}
	Also:
	\begin{align*}
		&\abs{F(x+h) - F(x) - f(x)h} \leq \abs{h}\epsilon\\
		\implies &\lim_{h \to 0} \abs{F(x+h) - F(x) - f(x)h} = 0\\
		\implies &\lim_{h \to 0} F(x+h) - F(x) - f(x)h = 0\\
		\implies &\lim_{h \to 0} \frac{F(x+h) - F(x)}{h} - f(x) = 0\\
		\implies &\lim_{h \to 0} \frac{F(x+h) - F(x)}{h} = f(x) \\
	\end{align*}
	Also ist $f$ die Ableitung von $F$.
\end{proof}
\begin{proof}
	\textbf{Beweis per Mittelwertsatz:} (Dieser Beweis ist übersichtlicher, aber nur, weil die ganze Arbeit an den Mittelwertsatz und den Satz von Rolle abgegeben wurden. Vermutlich also für die mündliche Prüfung also weniger gut geeignet.)
	Wir betrachten die Ableitung von $F$. Es gilt:
	\begin{align*}
		\frac{F(x+h) - F(x)}{h} &= \frac{1}{h} \left(\int_a^{x+h} f(t) dt - \int_a^{x} f(t) dt\right)\\
		&= \frac{1}{h} \int_x^{x+h} f(t) dt\\ 
	\end{align*}
	Nach dem Mittelwertsatz der Integralrechnung existiert nun ein $c_h \in [x,x+h]$, sodass 
	\begin{align*}
		\int_x^{x+h} f(t) dt = (x + h - x) f(c) \implies \frac{1}{h} \int_x^{x+h} f(t) dt = f(c)
	\end{align*}
	Da $c \in [x,x+h]$ folgt $\displaystyle \lim_{h \to 0} c_h = x$, da $f$ stetig ist folgt $\displaystyle \lim_{h \to 0} f(c_h) = f(x)$. Also gilt:
	\begin{align*}
		\lim_{h \to 0} \frac{F(x+h) - F(x)}{h} = \lim_{h \to 0} f(c_h) = f(x)
	\end{align*}
\end{proof}
\subsection{Partielle Integration}
\begin{theorem}
	Es gilt
	\begin{align*}
		\int_a^b f'(x) g(x) dx = \left[f(x) g(x)\right]_a^b - \int_a^b f(x) g'(x) dx
	\end{align*}
\end{theorem}
\begin{proof}
	Folgt direkt aus dem Hauptsatz der Integralrechnung und der Produktregel:
	\begin{align*}
		(f(x)g(x))' &= f'(x)g(x) + f(x)g'(x)\\
		\implies \int_a^b (f(x)g(x))' dx &= \int_a^b \left(f'(x)g(x) + f(x)g'(x)\right) dx\\
		\implies [f(x)g(x)]_a^b &= \int_a^b f'(x)g(x) dx + \int_a^b f(x)g'(x) dx\\
		\implies \int_a^b f'(x)g(x) dx &=  [f(x)g(x)]_a^b - \int_a^b f(x)g'(x) dx\\
	\end{align*}
\end{proof}
\begin{anmerkung}
	Ich persönlich finde folgende äquivalente Schreibweise einfacher anzuwenden:
	\begin{align*}
		\int_a^b f(x) g(x) dx = \left[F(x) g(x)\right]_a^b - \int_a^b F(x) g'(x) dx
	\end{align*}
\end{anmerkung}
\begin{example}
	Ein sehr häufig anwendbarer Trick ist die partielle Integration einer Funktion durch Multiplikation mit der konstanten Einsfunktion, z.B:
	\begin{align*}
		\int \ln(x) dx &= \int 1 \cdot \ln(x) dx\\
		&= x \ln(x) - \int x \cdot \frac{1}{x} dx\\ 
		&= x \ln(x) - \int 1 dx\\
		&= x \ln(x) - x\\ 
	\end{align*}
\end{example}
\begin{example}
	Im Fall $f = g$ erhält man durch partielle Integration das gleiche Integral ein zweites Mal und kann daraufhin die Gleichung durch Umstellen lösen:
	\begin{align*}
		\int f'(x) f(x) dx &= f(x)f(x) - \int f(x) f'(x) dx\\
		\implies 2 \int f'(x) f(x) dx &= f(x)^2\\
		\implies \int f'(x) f(x) dx &= \frac{1}{2} f(x)^2
	\end{align*}
	Diese Formel hat zahlreiche direkte Anwendungen:
	\begin{itemize}
		\item $\displaystyle \int \frac{\ln x}{x} dx = \frac{1}{2} \ln(x)^2$
		\item $\displaystyle \int \sin(x)\cos(x) dx = \frac{1}{2} \sin(x)^2 = -\frac{1}{2} \cos(x)^2$
	\end{itemize}
\end{example}
\subsection{Integration durch Substitution}
\chapter{Potenzreihen}
\begin{definition}
	Eine \tbf{Potenzreihe} ist eine Reihe der Form 
	\begin{align*}
		\sum_{k=0}^\infty a_k x^k,
	\end{align*}
	wobei $a_k$ eine Folge ist.
\end{definition}
\begin{theorem}
	Der \tbf{Konvergenzradius} einer Potenzreihe ist das Supremum der Beträge von $x$, für die die Potenzreihe konvergiert.
\end{theorem}
\begin{theorem}
	Jede Potenzreihe ist auf jedem Kompaktum innerhalb des Konvergenzradius absolut konvergent.
\end{theorem}
\begin{theorem}
	Potenzreihen sind innerhalb des Potenzradius unendlich oft differenzierbar.
\end{theorem}
\section{Taylorreihen}
\begin{theorem}
	Ist $f : I \to \bR$ auf dem Intervall $I$ $(n+1)$-mal differenzierbar, so gibt es für alle $x \in I$ ein $\xi \in [p,x]$ mit:
	\begin{align*}
		f(x) = \sum_{v = 0}^n \frac{f^{v}(p)}{v!}(x - p)^v + \frac{f^{(n+1)}(\xi)}{(n + 1)!}(x-p)^{n+1}
	\end{align*}
\end{theorem}
Diese Darstellung ist bekannt als die \textit{Lagrange-Darstellung des Restglieds}.
\begin{proofsketch}
	Durch den verallgemeinerten Mittelwertsatz.
\end{proofsketch}
\begin{theorem}
	Ist $f^{(n+1)}$ zusätzlich auf $I$ stetig, so gilt die direkte Formel:
	\begin{align*}
		f(x) = \sum_{v = 0}^n \frac{f^{v}(p)}{v!}(x - p)^v + \frac{1}{n!}\int_p^x(x-t)^nf^{(n+1)}(t)dt
	\end{align*}
\end{theorem}
Diese Darstellung ist bekannt als die \textit{Integraldarstellung des Restglieds}.
\begin{proof}
	Wiederholtes partielles Integrieren der Lagrange-Darstellung.
\end{proof}
\section{Die Exponentialfunktion}
\begin{definition}
	Wir definieren die Exponentialfunktion $\exp : \bR \to \bR$ als die Potenzreihe:
	\begin{align*}
		\exp(x) = \sum_{k=1}^\infty \frac{1}{k!}x^k
	\end{align*}
\end{definition}
\begin{theorem}
	Der Konvergenzradius der Exponentialfunktion ist unendlich.
\end{theorem}
\begin{proof}
	Das Quotientenkriterium gibt uns:
	\begin{align*}
		\lim_{k \to \infty} \frac{x^{k+1}k!}{x^k(k+1)!} = \lim_{k \to \infty} \frac{x}{k} = 0,
	\end{align*}
	also ist das Quotientenkriterium unabhängig von $x$ immer erfüllt, also ist der Konvergenzradius unendlich.
\end{proof}
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%



%
%
%
%
%
%
%
%
%
%
%
%

\chapter{Der Euklidische Raum}

\begin{lemma}
 Sei $(V, \scalar{\_}{\_})$ ein euklidischer Vektorraum. Dann wird durch
 \begin{align*}
  \norm{u} = \sqrt{\scalar{u}{u}}
 \end{align*}
auf $V$ eine Norm erklärt. Diese bezeichnet man als die durch das Skalarprodukt induzierte Norm.
\end{lemma}
\begin{definition}
 Seu $(V, \scalar{\_}{\_})$ ein euklidischer Vektorraum, Die Vektoren $u, v \in V$ heißen \tbf{orthogonal}, wenn \begin{align*}
   \scalar{u}{v} = 0                                                                                                                 
 \end{align*}
 ist. Für $u, v \in V \setminus \{0\}$ Wird die reelle Zahl
 \begin{align*}
  \phi = \arccos \frac{\scalar{u}{v}}{\norm{u}\ \norm{v}}
 \end{align*}
 als der Winkel zwischen $u$ und $v$ bezeichnet.
\end{definition}
\begin{anmerkung}
 Es gilt
 \begin{align*}
  \frac{\abs{\scalar{u}{v}}}{\norm{u}\ \norm{v}} \leq 1
 \end{align*}
\end{anmerkung}
\begin{lemma}
\label{lemma:normequiv}
 Für $X = (x_1, \hdots, x_n) \in \bR^n$ sei
 \begin{align*}
  \norm{X}_{\max} := \max\{\abs{x_1}, \hdots, \abs{x_n}\}
 \end{align*}
 Dann ist $||\_||_{\max}$ eine Norm auf $\bR^n$ und es gilt
 \begin{align*}
  \norm{X}_{\max} \leq \norm{X} \leq \sqrt{n}\norm{X}_{\max}
 \end{align*}
\end{lemma}
\begin{theorem}
Die Menge $\bQ^n$ der Punkte mit rational Koordinaten ist dicht in $\bR^n$.
\end{theorem}
\begin{proof}
Sei $X \in \bR^n$ und $\epsilon \in \bR^+$. Da $\bQ$ dicht in $\bR$ ist gilt
\begin{align*}
 \forall i \in \{1, \hdots, n\} : \exists y_i \in \bQ : \abs{x_i - y_i} \leq \frac{\epsilon}{\sqrt{n}}
\end{align*}
Durch Lemma \ref{lemma:normequiv} folgt:
\begin{align*}
 \norm{x-y} \leq \sqrt{n}\norm{X - Y} < \epsilon
\end{align*}
\end{proof}
\begin{theorem}
\label{theorem:componentcauchy}
 Sei $(X_k)_{k \in \bN}$ eine Folge aus $\bR^n$. Sei $X_k = (x_1^{(k)}, \hdots, x_n^{(k)})$. Dann gilt:
 \begin{align*}
  \lim_{k \to \infty} X_k = X \Leftrightarrow \forall i : \lim_{k \to \infty} x_i^{(k)} = x_i
 \end{align*}
 Insbesondere ist $X_k$ eine Cauchyfolge, wenn die Komponenten Cauchyfolgen sind.
\end{theorem}
\begin{proof}
 $X_k \to X$, $i \in \{1, \hdots, n\}$, $\epsilon \in \bR^+$. Dann gilt
 \begin{align*}
  \exists k_0 \in \bN : \forall k \geq k_0 : \norm{X_k - X} \leq \epsilon \implies \forall i : \abs{x_i^{(k)} - x_i} < \epsilon \implies \lim_{k \to \infty} x_i^{(k)} = x_i
 \end{align*}
 Und umgekehrt:
 \begin{align*}
  \forall i : x_i^{(k)} \to x_i, \epsilon \in \bR^+ \implies \exists k_0^i \in \bN : \forall k \geq k_0^i \abs{x_i^{(k)} - x_i} \leq \frac{\epsilon}{\sqrt{n}}
 \end{align*}
 \begin{align*}
  k_0 := \max\{k_0^n, \hdots, k_0^n\} &\implies \forall k \geq k_0 : \abs{x_i^{(k)} - x_i} < \frac{\epsilon}{\sqrt{n}}\\
  &\implies \norm{X_k - X} \leq \sqrt{n}\norm{X_k - X} < \epsilon
 \end{align*}
\end{proof}
\begin{theorem}
 Für konvergente Folgen $(X_k),(Y_k) \in \bR^n$, $(\lambda_k) \in \bR$ gilt:
\begin{align}
 \lim_{k \to \infty} (X_k + Y_k) = \lim_{k \to \infty} X_k + \lim_{k \to \infty} Y_k\\
 \lim_{k \to \infty} \lambda_k X_k = \left(\lim_{k \to \infty} \lambda_k\right)\left(\lim_{k \to \infty}
 X_k\right)\\
 \lim_{k \to \infty} \scalar{X_k}{Y_k} = \scalar{\lim_{k \to \infty} X_k}{\lim_{k \to \infty} Y_k}
\end{align}
\end{theorem}
\begin{theorem}
 $\bR^n$ ist vollständig.
\end{theorem}
\begin{proof}
Ist $X_k$ eine Cauchyfolge in $\bR^n$, so sind nach Satz \ref{theorem:componentcauchy} alle Teilfolgen Cauchy in $\bR$. Also:
\begin{align*}
 \exists x_i \in \bR : x_i^{(k)} \to x_i \implies \exists X \in \bR^n : X_k \to X
\end{align*}
\end{proof}
\begin{theorem}
\emph{\textbf{(Bolzano-Weierstrass:)}} Jede beschränkte Folge in $\bR^n$ besitzt eine konvergente Teilfolge.
\end{theorem}
\begin{proof}
 Sei $(X_k)$ eine beschränkte Folge in $\bR^n$. Nach \ref{lemma:normequiv} müssen die Komponentenfolgen ebenfalls beschränkt sein. Nach dem eindimensionalen Fall des Satzes von Bolzano-Weierstrass existieren also konvergente Teilfolgen der Koordinatenfolgen. Angenommen, die konvergente Teilfolge der ersten Komponente ist gegeben durch $x_1^{(k_n)} \to x_1$. So ist $x_2^{(k_n)}$ ebenfalls eine beschränkte Teilfolge, also existiert eine Teilfolge $x_2^{(k_n)_m}$ welche in den ersten beiden Komponenten konvergiert. Führt man dieses Verfahren induktiv fort, erhält man eine konvergente Teilfolge von $(X_k)$.
\end{proof}
\begin{theorem}
 Sei $(A_i)_{i \in \bN}$ eine Folge abgeschlossener beschränkter nichtleerer Teilmengen des $\bR^n$, sodass $A_1 \supseteq A_2 \supseteq \hdots$ Dann ist $\bigcap_{i \in \bN} \neq \emptyset$
\end{theorem}
\begin{proof}
 $A_i \neq \emptyset \implies \exists X_i \in A$ sd. $(X_i)_{i \in \bN}$ eine Folge ist. Da $A_i$ beschränkt ist ist $(X_i)_{i \in \bN}$ beschränkt, also hat $X_i$ eine konvergente Teilfolge $X_{i_k}$ mit Limes $X$. Es gilt $X_{i_k} \in A_{i_k} \subseteq A_i$, also ist $X$ ein Berührpunkt von $A_i$, also $X \in A_i$.
\end{proof}
\begin{theorem}
 Jede abgeschlossene beschränkte Teilmenge des $\bR^n$ ist kompakt.
\end{theorem}
\begin{proof}
 Analog zur eindimensionalen Version, wobei statt Intervallen $[a_i,b_i]$ Hyperwürfel $[a_i^{(1)}, b_i^{(1)}] \times \hdots \times [a_i^{(n)}, b_i^{(n)}]$ genutzt werden müssen.
\end{proof}
\begin{theorem}
\label{theorem:allnormsequiv}
 Seien $\norm{\_}_1$ und $\norm{\_}_2$ Normen auf $\bR^n$. So existieren $k, K \in \bR^+$ mit
 \begin{align*}
  \forall X \in \bR^n : k\norm{X}_1 \leq \norm{X}_2 \leq K\norm{X}_1
 \end{align*}
\end{theorem}
\begin{proof}
Diese Normenäquivalenz bildet eine Äquivalenzrelation. Es reicht also, zu zeigen, dass jede Norm $||\_||_2$ äquivalent zu einer spezifischen Norm $\norm{\_}_1$ ist. Wir wählen $\norm{\_}_{\max}$.\\
Sei $(E_i)$ die Standardbasis des $\bR^n$. Wir definieren:
\begin{align*}
 K := \norm{E_1}_2 + \hdots + \norm{E_n}_2
\end{align*}
Dann gilt:
\begin{align*}
 \norm{X}_2 &= \norm{x_1 E_1 + \hdots + x_n E_n}\\
         &\leq \abs{x_1}\norm{E_1}_2 + \hdots + \abs{x_n} \norm{E_n}_2\\
         &\leq \norm{X}_{\max} K \quad ^\text{[citation needed]}
\end{align*}
Es bleibt die Rückrichtung zu zeigen. 
\begin{lemma}
 $f(X) := \norm{X}_2$ ist stetig.
\end{lemma}
\begin{proof}
\begin{align*}
 \abs{\norm{X}_2 - \norm{Y}_2} \leq \norm{X - Y}_2 \leq K\norm{X - Y}_{\max} \leq K \norm{X - Y}
\end{align*}
Also ist $\norm{\_}_2$ stetig bezüglich der euklidischen Norm $\norm{\_}$.
\end{proof}
Wir definieren nun:
\begin{align*}
 A := \{X \in \bR^n \mid ||X||_{\max} = 1\}
\end{align*}
Diese Menge ist beschränkt. Wir wollen Zeigen, dass sie außerdem abgeschlossen ist. Sei $X_i \to X$, $X_i \in A$. Es gilt:
\begin{align*}
  \abs{\norm{X_i}_{\max} - \norm{X}_{\max}} \leq \norm{X_i - X}_{\max} \leq \norm{X_i - X}
\end{align*}
Also konvergiert jede Menge, also ist $A$ kompakt, also auch abgeschlossen. Dementsprechend muss $f$ auf $A$ ein Minimum $k$ annehmen. Wir wissen $f \geq 0$, also ist$k \geq 0$. Es gilt sogar $k > 0$, da keiner der Vektoren in $A$ der Nullvektor ist. Nun gilt also $\forall X \in A : ||X||_2 \geq k$. Wir definieren:
\begin{align*}
 \lambda := \frac{1}{\norm{X}_{\max}}
\end{align*}
\begin{align*}
 \norm{\lambda X}_{\max} = \abs{\lambda} \norm{X}_{\max} = 1 
\end{align*}
\begin{align*}
 |\lambda| \norm{X}_2 = \norm{\lambda X}_2 \geq k \implies \norm{X_2} \geq k \norm{X}_{\max}
\end{align*}
\end{proof}
\begin{anmerkung}
 Im unendlichdimensionalen Fall gilt Satz \ref{theorem:allnormsequiv} nicht.
\end{anmerkung}
%
%
%
%
%
%
%
%

%
%
%
%
\section{Abbildungen und Koordinatenfunktionen auf $\bR^n$}
In diesem Abschnitt betrachten wir Funktionen $F: \bR^n \to \bR^k$. Betrachten wir zuerst den Spezialfall Linearer Funktionen, also $\forall X,Y \in \bR^n : \forall \lambda, \mu \in \bR : F(\lambda X + \mu Y) = \lambda F(X) + \mu F(Y)$.
\newpar
Sei $(E_i)$ die Standardbasis des $\bR^n$ und sei $(E_i')$ die Standardbasis des $\bR^k$. Nun gilt:
\begin{align*}
 F(E_j) = \sum_{i=1}^k a_{ij} E_i'
\end{align*}
Daraus erhalten wir Koeffizienten $a_{ij}$, welche eine Matrix bilden. Umgekehrt können wir aus den Koeffizienten die Abbildung $F$ rekonstruieren, indem wir definieren:
\begin{align*}
 F(X) &= F\left(\sum_{j=1}^n x_j E_j\right) \\
 &= \sum x_j F(E_j) \\
 &= \sum_{j=1}^n x_j \sum_{i=1}^k a_{ij} E_i'\\
 &= \sum_{i=1}^k \left(\sum_{j=1}^n a_{ij} x_j\right) E_i'
\end{align*}
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
\newpage
[missing stuff here]
\newpage
\begin{definition}
 Wir bezeichnen als $p_i : M \to k$ die Projektion eines Vektors auf die $i$-te Komponente.
\end{definition}
\begin{theorem}
\label{theorem:componentwisecontinuous}
 Sei $M$ ein metrischer Raum, $F : M \to \bR^n$ eine Abbildung und $x \in M$. Dann ist $F$ stetig in $x$ genau dann, wenn $p_i \circ F$ stetig für alle $i$ ist.
\end{theorem}
\begin{proof}
\begin{enumerate}
 \item $p_i$ ist stetig. Ist also $F$ stetig folgt direkt, dass auch $p_i \circ F$ stetig ist.
 \item Angenommen, $p_i \circ F$ ist stetig $\forall i$, $\epsilon \in \bR^+$. Da $p_i \circ F$ stetig ist existiert eine Umgebung $U_i$ von $x$, sodass $|f_i(x) - f_i(y)| < \frac{\epsilon}{\sqrt{n}} \forall y \in U_i$. Ebenso für die anderen Komponenten. Nun gilt:
 \begin{align*}
  \norm{F(y) - F(x)} \leq \sqrt{n} \norm{F(x) - F(y)}_{\max} \leq \epsilon
 \end{align*}
\end{enumerate} 
\end{proof}
Analog gilt das Selbe für Stetigkeit auf $M$, gleichmäßige Stetigkeit, etc.
\begin{definition}
 Sei $M \subseteq \bR^n$, $F : M \to \bR^k$ eine Abbildung, $x_0$ ein Häufungspunkt, $y \in \bR^k$. Dann definieren wir:
 \begin{align*}
  \lim_{x \to x_0} F(x) = y \Leftrightarrow \forall \epsilon \in \bR^+ : \exists \delta \in \bR^+ : \forall x \in M \setminus \{x_0\} : \norm{x - x_0} \leq \delta \implies \norm{F(x) - y} < \epsilon
 \end{align*}
 $F$ ist stetig in $x_0$ genau dann, wenn $\lim_{x \to x_0} F(x) = F(x_0)$.
\end{definition}
\begin{theorem}
 Sei $M \subseteq \bR^n$, $F : M \to \bR^k$ eine Abbildung, $X_0 \in M$ ein Häufungspunkt, $Y \in \bR^k$ und $f_i = p_i \circ F$. Dann gilt:
 \begin{align*}
  \lim_{X \to X_0} F(X) = Y \Leftrightarrow \forall i : \lim_{X \to X_0} f_i(X) = y_i
 \end{align*}
\end{theorem}
\begin{proof}
 Analog zu Beweis \ref{theorem:componentwisecontinuous}.
\end{proof}
\begin{corollary}
 \begin{align*}
  F(X) \to Y, G(X) \to Z \implies F(X) + G(X) \to Y + Z
 \end{align*}
\end{corollary}
\section{Mehrdimensionale Ableitungen}
	\begin{example}
	 Sei $f : M \to \bR$ definiert auf einer offenen Menge $M \subseteq \bR^n$.
	 \begin{align*}
	  f(X) = f(x_1, \hdots, x_n) \text{ bzgl. der Standardbasis }
	 \end{align*}
	 Wir können aber auch $X = \sum x_i' E_i'$ bezüglich einer beliebigen anderen Basis darstellen. Also:
	 \begin{align*}
	  f(X) = f(x_1, \hdots, x_n) = g(x_1', \hdots, x_n')
	 \end{align*}
	 Da $f$ in der Regel nicht linear ist, ist ein solcher Basiswechsel sehr viel komplizierter als in der Linearen Algebra! Wo möglich ist es also besser, über $f(X)$ zu reden.
	\end{example}
	\begin{definition}
	 Sei $f : \bR^n \to \bR$, $\overline{X} \in M$. Betrachte die Abbildung \[t \to f(\overline{x}_1, \hdots \overline{x}_{i-1}, t, \overline{x}_{i+1}, \hdots, \overline{x}_n),\] welche eine Mehrdimensionale Funktion $f(x_1, \hdots x_n)$ auf eine eindimensionale Funktion $f(t)$ abbildet. \ul{Achtung:} Wir nehmen hier implizit eine Darstellung bezüglich der Standardbasis an!
	\end{definition}
	\begin{example}
	 Betrachte folgende Funktion:
	 \begin{align*}
	  f(x,y) = \begin{cases}
	            \frac{xy}{x^2 + y^2} & (x,y) \neq (0,0)\\
	            0 & (x,y) = (0,0)\\
	           \end{cases}
	 \end{align*}
	 $f$ ist an $(0,0)$ partiellen differenzierbar, die Partiellen Ableitungen sind $0$. Allerdings gilt \begin{align*}
	  \forall x : f(x,x) = \frac{1}{2}
	 \end{align*}
	 Also ist $f$ an $0$ nicht stetig! Es existieren also Funktionen, die an einem Punkt partiell Differenzierbar sind, an dem sie nicht stetig sind.
	\end{example}
	\ul{Idee:} Fordere partielle Differenzierbarkeit bezüglich jeder möglichen Basis, also partielle Differenzierbarkeit in jedem Vektor.
	\begin{example}
	 \begin{align*}
	  f(x,y) = \begin{cases}
	            \frac{x^2y}{x^4 + y^2} & (x,y) \neq (0,0)\\
	            0 & (x,y) = (0,0)\\
	           \end{cases}
	 \end{align*}
	 Wir betrachten die ``Linearisierung'' $t \to f(t, \alpha t)$. Einsetzen liefert:
	 \begin{align*}
	  f(t, \alpha t) = \frac{\alpha t}{t^2 + a^2}
	 \end{align*}
	 Diese Funktion ist differenzierbar, also ist $f$ differenzierbar bezüglich beliebiger Basen. Das reicht jedoch immer noch nicht:
	 \begin{align*}
	  f(a, a^2) = \frac{a^2a^2}{a^4+a^4} = \frac{1}{2}
	 \end{align*}
	 Also ist $f$ immer noch nicht stetig - es ist stetig für Folgen, welche den Nullpunkt durch Geraden erreichen, aber nicht, wenn wir durch kompliziertere Pfade gegen den Nullpunkt gehen.
	\end{example}
	\newpar
	Wir wollen die Begriffe aus der Analysis I über Stetigkeit und Ableitbarkeit retten, also brauchen wir einen komplizierteren Ableitungsbegriff.
	\section{Differenzierbarkeit}
	Sei $f$ eine beliebige Funktion $\bR \to \bR$. Die Ableitung gibt uns die Tangente der Funktion an einem beliebigen Punkt, also die beste affine Approximation der Funktion an diesem Punkt.
	\begin{definition}
	 Eine Funktion $F : \bR^n \to \bR^k$ heißt \tbf{affin}, wenn es eine Lineare Funktion $L : \bR^n \to \bR^k$ und eine Konstante $Z \in \bR^k$ gibt, sodass:
	 \begin{align*}
	  F(X) = L(X) + Z
	 \end{align*}
	\end{definition}
	\newpar
	Sei $g : \bR \to \bR$ affin, also $g(x) = cx + t$ für $c,t \in \bR$. Sei $f : \bR \to \bR$. Wir wollen eine beliebige Funktion $f$ an der Stelle $x_0$ approximieren. Für eine gute Approximation wollen wir $f(x_0) = g(x_0)$, also erhalten wir:
	\begin{align*}
	 g(x) = c(x - x_0) + f(x_0).
	\end{align*}
	Schreibe $x = x_0 + h$ und lasse $h$ gegen $0$ gehen.
	\begin{align*}
	 h \to f(x_0 + h) - g(x_0 + h) = f(x_0 + h) - f(x_0) - ch
	\end{align*}
	Wir sagen, die Approximation ist gut, wenn $f(x_0 + h) - f(x_0) - ch$ schneller gegen $0$ geht als $h$ selbst, also:
	\begin{align}
	\label{eq:goodapprox}
	 \lim_{h \to 0} \frac{f(x_0 + h) - f(x_0) - ch}{h} = 0
	\end{align}
	Was äquivalent ist zu:
	\begin{align*}
	 c = \lim_{h \to 0} \frac{f(x_0 + h) - f(x_0)}{h}\\
	\end{align*}
	Wir sagen also, $f$ ist in $x_0$ differenzierbar, genau dann, wenn eine lineare Abbildung $L$ existiert, sodass:
	\begin{align*}
	 \lim_{h \to 0} \frac{f(x_0 + h) - f(x_0) - L(h)}{h} = 0
	\end{align*}
	Diese geometrische Intuition, nach der die Ableitung die beste affine Approximation der Funktion an einem gegebenen Punkt ist, können wir auf den $\bR^n$ übertragen. Analog zu der Interpretation affiner Funktionen als Geraden in $\bR$, also der Ableitung als das Finden einer Tangentengeraden auf dem Funktionengraph, sucht man beim Ableiten einer Mehrdimensionalen Funktion eine Tangenten(hyper-)ebene auf dem Funktionengraph.
	\begin{definition}
	 Sei $M \subset \bR^n$ offen, $F : M \to \bR^k$ eine Abbildung, sei $X_0 \in M$. Die Abbildung $F$ heißt \tbf{differenzierbar} am Punkt $X_0$, wenn es eine Lineare Abbildung $L : \bR^n \to \bR^k$ gibt, sodass:
	 \begin{align*}
	  \lim_{H \to 0} \frac{F(X_0 + H) - F(X_0) - L(H)}{\norm{H}} = 0.
	 \end{align*}
	 Wir nennen sie das \tbf{Differenzial von $F$ im Punkt $X_0$} und notieren sie als $DF_{X_0}$. $F$ heißt differenzierbar, wenn sie differenzierbar an jedem Punkt $X \in M$ ist.
	\end{definition}
	\begin{anmerkung}
		Im Fall $n = m = 1$ (also bei eindimensionaler Urbild- und Bildmenge) sind lineare Abbildungen $\bR \to \bR$ genau durch Multiplikation mit einer Konstanten $c \in \bR$ gegeben. In diesem Fall vereinfacht sich die Bedingung zu:
		\begin{align*}
			\exists c \in \bR : \lim_{h \to 0} \frac{f(p + h) - f(p) - ch}{\abs{h}} &= 0\\
			\implies \exists c \in \bR : \lim_{h \to 0} \frac{f(p + h) - f(p)}{\abs{h}} &= \lim_{h \to 0}-\frac{ch}{\abs{h}}\\
			\implies \exists c \in \bR : \lim_{h \to 0} \frac{f(p + h) - f(p)}{\abs{h}} &= c\\								
		\end{align*}
		Was genau die Definition von Differenzierbarkeit im Eindimensionalen ist.
	\end{anmerkung}
	\begin{anmerkung}
		Ist die Funktion $F$ linear, so ist sie durch Matrixmultiplikation $f : x \to Ax$ gegeben und es gilt trivial für alle $x$ $DF_x = A$.
	\end{anmerkung}	
	\begin{anmerkung}
	 Differenzierbarkeit kann analog über die Eigenschaften des Restglieds $R(X, X_0)$ definiert werden: Sei
	 \begin{align*}
	  f(X) = f(X_0) + D f_{X_0}(X - X_0) + R(X, X_0).
	 \end{align*}
	 Dann ist $f$ genau dann differenzierbar, wenn:
	 \begin{align*}
	  \lim_{X \to X_0} \frac{R(X, X_0)}{\norm{X - X_0}} = 0
	 \end{align*}
	
	\end{anmerkung}

	\begin{theorem}
	 	Gibt es ein Differential, ist es eindeutig bestimmt.
	\end{theorem}
	\begin{proof}
		 Seien $L_1, L_2$ Differentiale. Es folgt:
		 \begin{align*}
		  \lim_{H \to 0} \frac{L_1(H) - L_2(H)}{\norm{H}} = 0
		 \end{align*}
		 Sei $X \in \bR^n \setminus \{0\}$. Dann gilt:
		 \begin{align*}
		  \lim_{t \to 0} \frac{L_1(tX) - L_2(tX)}{\norm{tX}} = 0
		 \end{align*}
		 %also:
		 \begin{align*}
		  \implies \frac{L_1(X) - L_2(X)}{\norm{X}} = 0
		 \end{align*}
		 %also:
		 \begin{align*}
		  \implies L_1(X) - L_2(X) = 0
		 \end{align*}
		 also sind die beiden Differentiale identisch.
	\end{proof}
	\begin{anmerkung}
	 	Unserer Differenzierbarkeitsbegriff wird insbesonders in der älteren Literatur oft als \tbf{totale Differenzierbarkeit} bezeichnet.
	\end{anmerkung}
	\begin{theorem}
	 	Ist $F: M \to \bR^k$ an einem Punkt $X_0$ differenzierbar, so ist $F$ an diesem Punkt stetig.
	\end{theorem}
	\begin{proof}
 		Sei $F$ differenzierbar. Da die Differenzierbarkeit über den Limes des Differentialquotienten definiert ist folgt direkt:
		 \begin{align*}
		  \forall \epsilon \in \bR^+ : \exists \delta_1 \in \bR^+ : \forall H \in M : (X_0 + H \in M) \wedge (0 \leq \norm{H} \leq \delta_1)\\ 
		  \implies \frac{\norm{F(X_0 + M) - F(X_0) - DF_{X_0}(H)}}{\norm{H}} \leq \frac{\epsilon}{2}\\
		  \implies \norm{F(X_0 + M) - F(X_0) - DF_{X_0}(H)} \leq \frac{\epsilon}{2}\norm{H}\\
		 \end{align*}
 		Da $DF_{X_0}$ eine lineare Abbildung ist ist $DF_{X_0}$ gleichmäßig stetig, also gilt:
	 \begin{align*}
	  \exists \delta_2 \in \bR^+ : \norm{H} < \delta_2 \implies \norm{DF_{X_0}(H)} \leq \frac{\epsilon}{2} 
	 \end{align*}
	 Also gilt für $\norm{H} \leq \delta := \min\{\delta_1, \delta_2, 1\}$
	 \begin{align*}
	  &\norm{F(X_0 + H) - F(X_0)}\\
	  = &\norm{F(X_0 + H) - F(X_0) - DF_{X_0}(H) + DF_{X_0}(H)}\\
	  \leq &\norm{F(X_0 + H) - F(X_0) - DF_{X_0}(H)} + \norm{DF_{X_0}(H)}\\
	  \leq &\frac{\epsilon}{2}\norm{H} + \frac{\epsilon}{2}\\
	  \leq &\epsilon
	 \end{align*}
	
	\end{proof}

	\begin{theorem}
		 Sind $F$ und $G$ differenzierbar, so auch $F + G$, und es gilt
		 \begin{align*}
		  D(F + G)_{X_0} = DF_{X_0} + DG_{X_0}
		 \end{align*}
	\end{theorem}
	\begin{proof}
		\begin{align*}
		 &\lim_{H \to 0} \frac{(F+G)(X_0 + H) - (F + G)(X_0) - (DF_{X_0} + DG_{X_0})}{\norm{H}}\\
		 = &\lim_{H \to 0} \frac{F(X_0 + H) - F(X_0) - DF_{X_0}}{\norm{H}} + \lim_{H \to 0} \frac{G(X_0 + H) - G(X_0) - DG_{X_0}}{\norm{H}}\\
		 = &0\\
		\end{align*}
	\end{proof}

	\begin{theorem}
	\ul{\tbf{Kettenregel:}} Seien $M \subseteq \bR^n$, $N \subseteq \bR^n$ offen, seien $F: M \to N$, $G : N \to \bR^m$ Abbildungen, sei $X_0$
	\end{theorem}
	\begin{proof}
	 Sei $F(X_0) = Y_0, F(X_0 + H) - F(X_0) = Z$, $H \in \bR^n \setminus \{0\}$, $X_0 + H \in M$.
	 \begin{align*}
	    &\frac{1}{\norm{H}} ((G \circ F)(X_0 + H) - (G \circ F)(X_0) - DG_{F(X_0)} \circ DF_{X_0}(H))\\
	    =&\frac{1}{\norm{H}}(G(Y_0 + Z_H) - G(Y_0) - DG_{Y_0}(Z_H))\\
	    =&\frac{1}{\norm{H}}(DG_{Y_0}(F(X_0 + H) - F(X_0)) - DG_{Y_0}(DF_{X_0}(H)))\\
	    =&\frac{1}{\norm{H}}DG_{Y_0}((F(X_0 + H) - F(X_0)) - DF_{X_0}(H))\\
	 \end{align*}
	 \begin{align*}
	  \lim_{H \to 0}\frac{1}{\norm{H}}DG_{Y_0}((F(X_0 + H) - F(X_0)) - DF_{X_0}(H)) = DG_{Y_0}(0) = 0\\
	 \end{align*}
	 \begin{align*}
	  \frac{1}{\norm{H}}(G(Y_0 + Z_H) - G(Y_0) - DG_{Y_0}(Z_H)) = 
	  \begin{cases}
	    0 & Z_H = 0\\
	    \frac{1}{\norm{H}}(G(Y_0 + Z_H) - G(Y_0) - DG_{Y_0}(Z_H)) & Z_H \neq 0 
	  \end{cases}
	 \end{align*}
	 Der Term zweite Term in $Z_H \neq 0$ geht gegen $0$ für $H \to 0 \implies Z_H = F(X_0 + H) - F(X_0) \to 0$
	 \begin{align*}
	  \frac{\norm{Z_H}}{\norm{H}} &= \frac{\norm{F(X_0 + H) - F(X_0)}}{\norm{H}} \\
	  &= \frac{\norm{DF_{X_0}(H) - R(X_0, H)}}{\norm{H}}\\ 
	  &\leq \frac{\norm{DF_{X_0}(H)}}{\norm{H}} + \frac{\norm{R(X_0, H)}}{\norm{H}}\\
	  &\leq \frac{\norm{DF_{X_0}(H)}}{\norm{H}} + \frac{\norm{R(X_0, H)}}{\norm{H}}\\
	  &\overset{???}{\leq} \frac{\norm{DF_{X_0}}\norm{H}}{\norm{H}} + \frac{\norm{R(X_0, H)}}{\norm{H}}\\
	  &= \norm{DF_{X_0}} + \frac{\norm{R(X_0, H)}}{\norm{H}}\\
	  &\leq c\\
	 \end{align*}
	\end{proof}
	\begin{theorem}
	 Seien $I \subseteq \bR$, $N \subseteq \bR^k$ offen, seien $F : I \to N$, $G : N \to \bR^n$ Abbildungen.
	 \newpar
	 Ist $F$ differenzierbar in $t_0 \in I$ und $G$ differenzierbar in $F(t_0)$, so gilt:
	 \begin{align*}
	  (G \circ F)'(t_0) = DG_{F(t_0)} (F'(t_0))
	 \end{align*}
	\end{theorem}
	\begin{proof}
	 Gemät Kettenregel gilt $D(G \circ F) = DG_{F(t_0)} \circ DF_{t_0}$. Nun gilt:
	 \begin{align*}
	  h(G \circ F)'(t_0) &= h D(G \circ F)_{t_0} (1)\\ &= D(G \circ F)_{t_0}(h)\\ &= DG_{F(t_0)}(DF_{t_0}(h))\\
	  &= h DG_{F(t_0)}(F'(t_0))
	 \end{align*}
	\end{proof}
	\newpar
	Mittelwertsatz: $f : [x,y] \to \bR$, dann $\exists y : f(y) - f(x) = f'(z)(y-x)$. Im Allgemeinen ist dieser im Mehrdimensionalen Fall leider falsch.
	\newpar
	Betrachte allerdings die folgende Ungleichung, welche die Wichtigste Konsequenz des Mittelwertsatzes ist: $\abs{f(y) - f(x)} \leq \abs{f'(z)}\abs{y-x} \leq c \abs{y-x}$. Diese kann im Allgemeinen erhalten werden.
	\newpar
	$F : M \subset \bR^n \to \bR^k$ $X,Y \in M$. Sei $[X,Y] = \{(1- \lambda)X + \lambda Y\}$ die Verbindungslinie zwischen den beiden Vektoren.
	\begin{theorem}
	 Sei $M \subseteq \bR^n$ offen, $X,Y \in M$ mit $[X,Y] \subseteq M$. Die Abbildung $F : M \to \bR^k$ sei stetig in $M$ und differenzierbar in den Punkten $(1-\lambda)X + \lambda Y$ mit $\lambda \in (0,1)$. Gilt
	 \begin{align*}
	  \forall \lambda \in (0,1) : \forall (1-\lambda)X + \lambda Y : \norm{DF_Z} \leq c 
	 \end{align*}
	 so gilt auch
	 \begin{align*}
	  \norm{F(Y) - F(X)} \leq c\norm{Y - X}
	 \end{align*}
	 \begin{proof}
	  Angenommen $G : [0,1] \to \bR^k$ ist stetig auf $[0,1]$ und differenzierbar auf $(0,1)$. So gilt 
	  \begin{align*}
	  \forall t \in (0,1) : \norm{G'(t)} \leq c
	  \end{align*}
	 \newpar
	 Sei $\epsilon \in \bR^+$ und 
	 \begin{align*}
	  A := \{t \in [0,1] \mid \norm{G(t) - G(0)} \leq (c + \epsilon) t + \epsilon\}
	 \end{align*}
	 Da $G$ stetig in $0$ ist gilt $[0, \tau] \subseteq A$.
	 \newpar
	 Sei $s = \sup A$. Es gilt $0 < s \leq 1$, also ist $G$ stetig in $s$.
	 \newpar
	 Da $t \in A \implies t \leq s$ 
	 \begin{align*}
	  \norm{G(t) - G(0)} \leq (c + \epsilon) t + \epsilon \to s
	  \implies \norm{G(s) - G(0)} \leq (c + \epsilon) s + \epsilon
	 \end{align*}
	 also $s \in A$. Angenommen, $s < 1$. Dann gilt $\exists h > 0 : s + h < 1$.
	 \begin{align*}
	  \norm{\frac{G(s + h) - G(s)}{h} - G'(s)} \leq \epsilon
	 \end{align*}
	 \begin{align*}
	  \implies \norm{\frac{G(s + h) - G(s)}{h}} \leq \epsilon +  G'(s) \leq c + \epsilon
	 \end{align*}
	 \begin{align*}
	  \norm{G(s + h) - G(0)} &\leq \norm{G(s + h) - G(s)} + \norm{G(s) - G(0)}\\
	                         &\leq (c + \epsilon) h + (c + \epsilon) s + \epsilon\\
	                         &\leq (c + \epsilon)(s + h) + \epsilon\\
	 \end{align*}
	 Daraus folgt $s + h \in A$. Da $s$ das Supremum ist ist dies ein Widerspruch. Also gilt $h = 1$.
	 \begin{align*}
	  \forall \epsilon \in \bR^+ : \norm{G(1) - G(0)} \leq &c + \epsilon + \epsilon = c + 2 \epsilon\\
	  \implies &\norm{G(1) - G(0)} \leq c
	 \end{align*}
	 Sei $F$ wie im Satz. Sei $K : [0,1] \to \bR^n : t \to (1-t)X + tY$. Diese Abbildung ist affin, also differenzierbar. Es gilt $K'(t) = Y - X$. $F \circ K$ ist diffbar in $(0,1)$
	 \begin{align*}
	  D(F \circ K)_t = DF_{K(t)} \circ DK_t
	 \end{align*}
	 \begin{align*}
	  (F \circ K)'(t) = DF_{K(t)}(K'(t)) = DF_{K(t)}(Y-X)
	 \end{align*}
	 \begin{align*}
	  \norm{(F \circ K)'(t)} = \norm{DF_{K(t)}(Y - X)} \leq \norm{DF_{K(t)}}\norm{Y - X} \leq c \norm{Y - X}
	 \end{align*}
	 Mit $G := F \circ K$ und $c := c\norm{Y - X}$
	 \begin{align*}
	  \norm{F(Y) - F(X)} \leq c\norm{Y - X}
	 \end{align*}
	
	 \end{proof}
	\end{theorem}
	[missing stuff - gradients]
	\begin{definition}
	 Eine Funktion $f$ heißt \tbf{partiell differenzierbar}, wenn für jede Koordinatenachse $i$ die Partielle Ableitung $\forall i \in \{0, \hdots, n\} : \partial_i f : M \subseteq \bR \to \bR : X \to \delta_i f(X)$ existiert.
	\end{definition}
	\begin{theorem}
	 Ist $f: M \to \bR$ in einer Umgebung von $X_0$ partiell differenzierbar und sind die partiellen Ableitungen in $X_0$ stetig, so ist $f$ in $X_0$ differenzierbar.
	\end{theorem}
\begin{proof}
 Sei $U$ ein offener Ball um $X_0$, welcher vollständig in $M$ enthalten ist. Sei $H \in \bR^n$, sodass $X_0 + H \in U$. Nun gilt:
 \begin{align*}
  f(X_0 + H) - f(X_0) &= \sum_{i=1}^n (f(x_1, \hdots, x_{i-1}, \hdots, x_i + h_i, x_{i+1} + h_{i+1} , \hdots, x_n + h_n))\\
  &- \sum_{i=1}^n (f(x_1, \hdots, x_{i-1}, \hdots, x_i, x_{i+1} + h_{i+1} , \hdots, x_n + h_n))\\
 \end{align*}
 Die Summenglieder sind partielle Ableitung. Nach Mittelwertsatz erhalten wir:
 \begin{align*}
  \sum_{i=1}^n h_1 \partial_i f(x_1, \hdots x_{i-1}, x_i + c_ih_i, x_{i+1}, \hdots, x_n)\ c_i \in (0,1)\\
 \end{align*}
 Nun gilt:
 \begin{align*}
  &\frac{1}{\norm{H}} \abs{f(X_0 + H) - f(X_0) - \scalar{\grad f(X_0)}{H}}\\
  =&\frac{1}{\norm{H}} \abs{\sum_{i=1}^n h_1 \partial_i f(x_1, \hdots x_{i-1}, x_i + c_ih_i, x_{i+1} + h_{i+1}, \hdots, x_n + h_n) - \partial_i(f(x_0, \hdots, x_n))} \\
  \leq&\abs{\sum_{i=1}^n \partial_i f(x_1, \hdots x_{i-1}, x_i + c_ih_i, x_{i+1} + h_{i+1}, \hdots, x_n + h_n) - \partial_i(f(x_0, \hdots, x_n))} \to 0\\
 \end{align*}
\end{proof}
 Sei $M \subseteq \bR^n$ offen, $X_0 \in M$, $F: M \to \bR^k$. Seien $\forall i \in \{1, \hdots, n\} f: M \to \bR^n \to \bR$ Koordinatenfunktionen.
 \begin{align*}
  F(X) = (f_1(X), \hdots, f_k(X)) = \sum_{i=1}^k f_i(X)E_i'
 \end{align*}
 \begin{align}
  Y = F(X) \Leftrightarrow \forall i : y_i = f_i(x_1, \hdots, x_n)
 \end{align}
\begin{theorem}
Die Abbildung $F$ ist genau dann differenzierbar in $X_0$, wenn alle Koordinatenfunktionen $f_i$ in $X_0$ differenzierbar sind. Ist das der Fall, gilt:
\begin{align*}
 DF_{X_0}(H) = \sum_{i=1}^k (Df_i)_{X_0}(H)E_i' \forall H \in \bR^n 
\end{align*}
\end{theorem}
\begin{proof}
 $L : \bR^n \to \bR^n$ linear. Dann
 \begin{align*}
  \lim_{H \to 0} \frac{F(X_0 + H) - F(X_0) - L(H)}{\norm{H}} = 0 \Leftrightarrow \lim_{H \to 0} \frac{f_i(X_0 + H) - f_i(X_0) - (D_i \circ L)(H)}{\norm{H}} = 0
 \end{align*}
 \end{proof}
 Wir wollen nun das Differential bezüglich der Standardbasis übersichtlich darstellen. Es gilt:
 \begin{align*}
  L(E_j) = \sum_{i=1}^k a_{ij} E_i'\\
  DF_{X_0} = \sum_{i=1}^k \partial_j f_i(X_0) E_j'
 \end{align*}
 Die Koeffizienten der Darstellenden Matrix sind also identisch mit den Partiellen Ableitungen.
\begin{theorem}
 Sei $F : M \to \bR^k$ differenzierbar in $X_0 \in M$. Dann wir das Differential $DF_{X_0}$ bezüglich der Standardbasis in $\bR^n$ und $\bR^k$ beschrieben als die $k \times n$-Matrix
 \begin{align*}
  JF(X_0) = (\delta_j f_i(X_0))_{1 \leq i \leq n, 1 \leq j \leq k}
 \end{align*}
 Sie heißt die Funktionalmatrix oder Jacobimatrix von $F$ in $X_0$. Falls $k = n$ wird die Determinante dieser Matrix als Funktionaldeterminante oder Jacobideterminante von $F$ in $X_0$ bezeichnet.
\end{theorem}
\newpar
[missing stuff]
\newpar
\begin{theorem}
 Ist $r \geq 2$ und $f \in C^r(M)$, so sind die partiellen Ableitungen von $f$ bis zur Ordnung $r$ unabhängig von der Reihenfolgen es gilt also:
 \begin{align*}
  \partial_1 \hdots \partial_r f = \partial_{\sigma(1)} \hdots \delta_\sigma(r) f
 \end{align*}
\end{theorem}
\begin{theorem}
 \emph{\tbf{Taylor-Formel}}: Sei $g: [-\epsilon, h] \to \bR$ $\epsilon, h > 0$.
 Sei $g$ $(k+1)$- mal differenzierbar. Dann gilt:
 \begin{align*}
  \exists c \in (0,h) : g(h) = \sum_{j = 0}^k \frac{1}{j!} g^{(j)} (0) h^j + \frac{1}{(k+1)!} g^{(k+1)}(c) h^{k+1}
 \end{align*}
 Sei $f : M \to \bR$ $M \subseteq \bR^n$ offen, $x_0 \in M$. Sei $k \in \bN$, $f \in C^k(M)$ mit partielle differenzierbaren partiellen Ableitungen $k$-ter Ordnung, $H \in \bR^n : [x_0, x_0+H] \subseteq M$. Sei $g(t) := f(x_0 + tH)$. Dann gilt für $r \in \{1, \hdots, k+1\}$:
 \begin{align*}
  g^{(r)}(t) = \sum_{i_1, \hdots i_r}^n \delta{i_1} \hdots \delta{i_r} f(X_0 + tH) h_{i_1} \hdots h_{i_r}
 \end{align*}
 \begin{align*}
  g(1) = \sum_{r=0}^k \frac{1}{r!} g^{(r)}(0) + \frac{1}{(k+1)!} g^{(k+1)}(c)
 \end{align*}
\end{theorem}
\begin{theorem}
 \emph{\tbf{Mehrdimensionale Taylorformel:}} Sei $M \subseteq \bR^n$ offen, $X_0 \in M$, $H \in \bR^n$ mit $[X_0, X_0 + h] \subseteq M$, $k \in \bN$, $f \in C^k(M)$, sodass die partiellen Ableitungen der Ordnung $k$ in $M$ differenzierbar sind. Dann $\exists c \in (0,1)$, sodass:
 \begin{align*}
  f(X_0 + h) = f(X_0) + \sum_{r=1}^k \frac{1}{r!} \sum_{i_1, \hdots i_r = 1}^n \delta{i_1} \hdots \delta{i_r} f(X_0 + tH) h_{i_1} \hdots h_{i_r} + \frac{1}{(k+1)!}  \sum_{i_1, \hdots i_r = 1}^n \delta{i_1} \hdots \delta{i_r} f(X_0 + cH) h_{i_1} \hdots h_{i_r}
 \end{align*}
 Kompakter für $k = 2$:
 \begin{align*}
  f(X_0 + H) = f(X_0) + \scalar{\grad f(X_0)}{H} + \frac{1}{2} \sum_{i,j=1}^n \partial_i \partial_j f(X_0) h_i h_h + R(X_0, h)
 \end{align*}
 \begin{align*}
  R(X_0, H) = \frac{1}{6}\sum_{i,j,k=1}^n \delta_i \delta_j \delta_k f(Y) h_i h_j h_k \quad Y \in [X_0, X_0 + H]
 \end{align*}
 Falls die dritten Ableitungen auf der Verbindungslinie beschränkt sind gilt:
 \begin{align*}
  \lim_{H \to 0} \frac{R(X_0; H)}{\norm{H}^2} = 0
 \end{align*}
\end{theorem}
\begin{theorem}
 Sei $f : M \to \bR$ zweimal partiell differenzierbar in $X_0$. Dann heißt die durch
 \begin{align*}
  Q(f,X_0;H) := \sum_{i,j=1}^n \delta_i \delta_j f(X_0) h_i h_j
 \end{align*}
 definierte Funktion $Q(f,X_0;H$ die \tbf{Hesse-Form} von $f$ im Punkt $X_0$ und die dadurch definierte Matrix
 \begin{align*}
  \Hess{f, X_0}_{ij} = (\partial_i \partial_j f(X_0))
 \end{align*}
 heißt die \tbf{Hesse-Matrix} von $f$ in $X_0$.
\end{theorem}
\clearpage
[...]
\clearpage
\begin{lemma}
 Sei $M \subseteq \bR^n$ offen, $F : M \to \bR^n$ eine $C^1$-Abbildung, sei $L : \bR^n \to \bR^n$ eine lineare Abbildung, sei $X, Y \in M$ mit $[X, Y] \subseteq M$. Dann gilt:
 \begin{align*}
  \norm{F(X) - F(Y) - L(X-Y)} \leq \norm{X - Y} \cdot \max_{Z \in [X,Y]} \norm{DF_Z - L}
 \end{align*}
\end{lemma}
\begin{proof}
 \begin{align*}
  G(X) := F(X) - L(X) \quad X \in M
 \end{align*}
 \begin{align*}
  DG_Z = DF_Z - L
 \end{align*}
 Dann muss für $F \in C^1$ folgende Funktion stetig sein:
 \begin{align*}
  Z \to \norm{DF_Z - L}
 \end{align*}
 Zusätzlich ist $[X,Y]$ kompakt, also existiert das Maximum
 \begin{align*}
  \max_{Z \in [X,Y]} \norm{DF_Z - L} := c
 \end{align*}
 Gemäß Mittelwertsatz ist nun
 \begin{align*}
  \norm{F(X) - F(Y) - L(X-Y)} \leq c \norm{X - Y}
 \end{align*}
\end{proof}
\begin{theorem}
 Sei $M \subseteq R^n$ offen. Sei $\vx_0 \in M$. Sei $F : M \to \bR^n$ eine $C^r$-Abbildung ($r \in \bN_1$). Sei das Differential $DF_{\vx_0}$ regulär, also $\det JF(\vx_0) \neq 0$. Dann existiert eine offene Umgebung $U \subseteq M$ von $ \vx_0$, sodass folgendes gilt:
 \begin{enumerate}
  \item die Einschränkung $F|_U$ ist injektiv
  \item die Bildmenge $F(U) := V$ ist offen
  \item die Umkehrabbildung $(F|_U)^{-1} : V \to U$ ist $C^r$. 
 \end{enumerate}
\end{theorem}
\begin{proof}
 Sei $I$ die Identitätsabbildung des $\bR^n$. Sei $U(0, \alpha) := \{\vx \in \bR^n \mid \vx < \alpha\}$.
 \newpar
 \ul{Annahmen}: $\vx_0 = 0$, $F(0) = 0$ (Erfüllbar durch Verschieben), $DF_0 = I$ (Erfüllbar durch invertierbare Lineare Abbildung der Funktion?)
 \newpar
 $\vx \to \norm{DF_{\vx} - I}$ ist stetig mit $\norm{DF_0 - I} = 0$. Also gilt
 \begin{align*}
  \forall \epsilon > 0 : \exists \alpha > 0 : \forall \vx \in U_\alpha : \norm{DF_{\vx} - I} \leq \epsilon
 \end{align*}
 Nach 4.3 folgt:
 \begin{align*}
  \forall \vx, \vy \in U_\alpha : \norm{F(\vx) - F(\vy) - (\vx-\vy)} \leq \epsilon \norm{\vx - \vy}
 \end{align*}
 \begin{align*}
  \norm{\vx - \vy} &\leq \norm{\vx - \vy - (F(\vx) - F(\vy))} + \norm{F(\vx) - F(\vy)}\\
  &\leq \epsilon \norm{\vx - \vy} + \norm{F(\vx) - F(\vy)}\\
 \end{align*}
 also:
 \begin{align*}
  (1- \epsilon)\norm{\vx - \vy} \leq \norm{F(\vx) - F(\vy)}
 \end{align*}
 Also ist $\norm{F(\vx) - F(\vy)} = 0$ gdw. $\vx = \vy$, also folgt Injektivität.
 \newpar
 \begin{lemma}
  $U_{(1-\epsilon)\alpha} \subseteq F(U_\alpha)$
 \end{lemma}
 \begin{proof}
  Sei $\vy \in U_{(1-\epsilon)\alpha}$. Wir suchen $\vx \in U_\alpha : \vy = F(\vx)$. Wir wollen den Banchschen Fixpunktsatz anwenden. Dafür definieren wir $\phi : \overline{U_\alpha} \to \bR^n$ als:
  \begin{align*}
   \phi(\vx) := \vy - F(\vx) + \vx
  \end{align*}
  Sei nun $X \in \overline{U_\alpha}$. Dann gilt:
  \begin{align*}
   \norm{\phi(\vx)} &\leq \norm{\vy} + \norm{F(\vx) - \vx}\\
                    &\leq \norm{\vy} + \epsilon \norm{\vx}\\
                    &< (1-\epsilon)\alpha + \epsilon \alpha\\
                    &= \alpha\\
  \end{align*}
  Sei $X,Z \in \overline{U_\alpha}$. Nun gilt:
  \begin{align*}
   \norm{\phi(\vx) - \phi(\vz)} &= \norm{F(\vx) - \vx - (F(\vz) - \vz)}\\
                                &\leq \epsilon \norm{\vx - \vz}
  \end{align*}
  Gemäß Banachschem Fixpunktsatz existert also genau ein $X \in \overline{U_\alpha}$, sodass $\phi(\vx) = \vx$, also $F(\vx) = \vy$. Da $\phi(\vx) < \alpha$ gilt auch $\vx \in U_\alpha$.
 \end{proof}
 Sei nun $V : U_{(1 - \epsilon) \alpha}$ und $U := F^{-1}(V)$. Gemäß Lemma ist $U$ eine Obermenge von $V$, also ist $U$ eine offene Umgebung von $0$. Wir wissen bereits, dass $F|_U$ injektiv ist. Sei also nun $G : V \to U$ die Umkehrabbildung von $F|_U$.
 \begin{lemma}
  $G$ ist in $0$ differenzierbar.
 \end{lemma}
 \begin{proof}
 Sei $\epsilon' \in \bR^+$. So existiert ein $\alpha' \in \bR^+$, sodass $U_{\alpha'} \in M$ und
 \begin{align*}
  \norm{F(\vx) - \vx} \leq \frac{\epsilon'}{1 + \epsilon'} \norm{\vx} \quad \forall \vx \in U_{\alpha'}
 \end{align*}
 \begin{align*}
  \norm{\vx} &\leq \norm{\vx - F(\vx)} + \norm{F(\vx)}\\
             &\leq \frac{\epsilon'}{1 + \epsilon'} \norm{\vx} + \norm{F(\vx)}
 \end{align*}
 also:
 \begin{align*}
  \norm{\vx} \leq (1 + \epsilon') \norm{F(\vx)} \quad \forall \vx \in U_{\alpha'}
 \end{align*}
 Sei nun $\vh \in V$ mit $\norm{\vh} < \alpha'(1 - \epsilon)$. Sei $\vx := G(\vh)$. Gemäß Lemma ist $V \subseteq F(U_\alpha)$, also $G(V) \subseteq G(F(U_\alpha))$, also $U \subseteq U_\alpha$, also $\vx \in U$ (?)
 \newpar
 Gemäß vorheriger Überlegungen haben wir
 \begin{align*}
  \norm{X} \leq \frac{1}{1 - \epsilon} \norm{F(\vx)} = \frac{1}{1 - \epsilon} \norm{\vh} < \alpha' 
 \end{align*}
 Wir betrachten nun endlich den Differentialquotienten:
 \begin{align*}
  \norm{G(\vh) - \vh} &= \norm{\vx - F(\vx)}\\
                      &\overset{(*)}{\leq} \frac{\epsilon*}{1 + \epsilon'}\norm{\vx}\\
                      &\leq \epsilon'\norm{F(\vx)}\\
                      &\leq \epsilon' \norm{\vh}
 \end{align*}
 also:
 \begin{align*}
  \frac{\norm{G(\vh) - \vh}}{\norm{\vh}} \leq \epsilon'
 \end{align*}
 für alle $0 < \norm{\vh} < \min \{\alpha(1 - \epsilon), \alpha' (1 - \epsilon)\}$, also ist $G$ in $0$ differenzierbar mit $DG_0 = I$.
 \end{proof}
 Was ist nun, wenn die Vorraussetzungen $\vx = 0$, $F(0) = 0$, $DF_0 = I$ nicht gelten?
 \newpar
 Wir definieren lineare Translationsabbildungen $T_{\vz} : \bR^n \to \bR^n$ $\vx \to \vx + \vz$. Sei nun:
 \begin{itemize}
  \item $L : DF_{\vx_0}$,
  \item $M' := (L \circ T_{-\vx_0})(M)$,
  \item $F'(\vx) := T_{-F(\vx_0} \circ F \circ T_{\vx_0} \circ L^{-1}(\vx)$
 \end{itemize}
 Die Differentiale sind $DL = L$ und $DT_Z = I$. Nun gilt:
 \begin{align*}
  DF'_{0} = I \circ DF_{\vx_0} \circ I \circ (DF_{\vx_0})^{-1} = I
 \end{align*}
 Also $F'(0) = 0$, $0 \in M'$. $F'$ ist also umkehrbar und die Umkehrabbildung ist differenzierbar in $0$. Für die Ursprüungliche Abbildung gilt $F = T_{T_{\vx_0}} \circ F' \circ L \circ T_{-\vx_0}$.
\end{proof}
\begin{definition}
 Sei $F : M \subseteq \bR^n \to \bR^n$ eine $C^r$-Funktion mit regulären Differentialen. Eine solche Abbildung nennt man einen $C^r$-Diffeomorphismus.
\end{definition}
\clearpage
[...]
\clearpage
\begin{theorem}
 \emph{\tbf{(Implizite Funktion):}}  Sei $k < n$, $M \subseteq \bR^n$ offen, $F \in C^r : M \to \bR^k$, sei $N = \{\vx \in M \mid F(\vx) = 0\}$. Sei $\vx_0 \in N$ und $DF_{\vx_0}$ vom Rang $k$. 
 
 \noindent Dann gibt es nach passender Identifizierung von $\bR^n$ mit $\bR^{n-k} \times \bR^k$ eine offene Umgebung $U \subseteq M$ von $\vx_0$, eine offene Menge $V \subseteq \bR^{n-k}$ und eine Abbildung $G \in C^r : V \to \bR^k$, sodass $N \cap U$ der Graph von $G$ ist.
\end{theorem}
\begin{proof}
 $DF_{\vx_0}$ hat Rang $k$. Es gilt also $k$ linear unabhängige Spalten. OBDA seien dies die letzten $k$ Spalten. Die ersten $(n-k)$ Basisvektoren bilden eine Basis des $\bR^{n-k}$, ebenso bilden die letzten $k$ Vektoren eine Basis des $\bR^k$. Wir haben somit eine Identifikation $\bR^n \simeq \bR^{n-k} \times \bR^k$ erhalten, sodass wir $\vx \in \bR^n$ abbilden auf $\vx = (\vx',\vx'')$. Wir definieren folgende Funktion:
 \begin{align*}
  \phi : M \times \bR^k &\to \bR^{n-k} \times \bR^k\\
  (\vx', \vx'') &\to (\vx', F(\vx', \vx''))
 \end{align*}
 Da $F, \times \in C^r$ ist $\phi$ ebenfalls in $C^r$. Für die Jakobimatrix gilt:
 \begin{align*}
  J \phi = 
  \begin{pmatrix}
    1 & \hdots & 0 & 0 & \hdots & 0\\
    \vdots & \ddots & \vdots\\
  \end{pmatrix}
 \end{align*}
 
 [WIP]
 
 Nach dem Satz der Inversen Funktion existiert eine Umgebung $U_0$ von $\vx_0$, sodass auf dieser Umgebung eine Umkehrabbildung $\psi$ existiert. Und so weiter :)
\end{proof}
\begin{anmerkung}
 Seien $A$, $B$ Mengen. Es existieren folgende Funktionen: 
 \begin{itemize}
  \item Das Produkt $A \times B$
  \item Die Projektion $\pi_1 : A \times B \to A$ auf die erste Komponente
  \item Die Projektion $\pi_2 : A \times B \to B$ auf die zweite Komponente
  \item Die kanonische Injektion $i : A \to A \times B : a \to (a,0)$
 \end{itemize}
\end{anmerkung}
\begin{theorem}
 \emph{\tbf{Über lokal surjektive Abbildungen:}} Sei $k < n$. Sei $M \subseteq \bR^n$ offen, $F : M \to \bR^k$ eine Abbildung der Klasse $C^r$, $r \in \bN_1$. Sei $X_0 \in M$ und $F$ in $X_0$ vom Rang $k$, also $DF_{X_0}$ surjektiv. Dann gibt es eine offene Umgebung $U$ von $X_0$ in $M$, eine offene Menge $V$ in $\bR^{n-k}$, und einen $C^r$-Diffeomorphismus $h : U \to V \times F(u)$, sodass das folgende Diagramm kommutiert:
 \begin{figure}[h!]
 \centering
    \begin{tikzcd}[row sep = huge, column sep = huge]
    U
    \arrow[r, "h"]
    \arrow[dr, "F"]
    & V \times F(u)
    \arrow[d, "\pi_2"] \\
    &  F(u)
    \end{tikzcd}
\end{figure}
\end{theorem}
	\begin{proof}
		Nach Vorraussetzung hat $JF(X_0)$ $k$ unabhängige Spalten. Seien dies OBdA die letzten Spalten. Wir interpretieren $\bR^n = \bR^k \times \bR^{n-k}$ und definieren $\pi_1 : \bR^n \to \bR^{n-k}$ und $\pi_2 : \bR^n \to \bR^k$ als die dazugehörigen kanonischen Projektionen. Sei $\varphi$ folgende Funktion:
		\begin{align*}
		 \varphi : M &\to \bR^{n-k} \times \bR^k\\
		 X &\to (\pi_1(X), F(X))
		\end{align*}
		Es gilt $F \in C^r$ und $\pi_1 \in C^r$, also auch $\varphi \in C^r$. Gemäß des Satzes der inversen Funktion existiert also eine Umgebung $\varphi \in C^r$, auf der $\varphi$ ein $C^r$ Diffeomorphismus (also $C^r$ und invertierbar).
		\newpar
		Da $\varphi^{-1}$ stetig ist, ist das Urbild $(\varphi^{-1})^{-1}(U') = \varphi(U')$ offen. Es enthält also eine offene Umgebung von $\varphi(X_0) = (\pi_1(X_0), F(X_0))$ der Form $V \times X$, also ist $V$ offen in $\bR^{n-k}$. Wir setzen $U := \varphi^{-1}(V \times W)$ und $h = \varphi \mid_U$. Dann ist $F(U) = W$, und für $X \in U$ gilt $h(X) = (\pi_1(X), F(X))$, also $\pi_2 \circ h = F$.
		\end{proof}
		\noindent Im Fall $k > n$ erhalten wir lokale Injektivität statt lokaler Surjektivität:
		\begin{theorem}
		 \emph{\tbf{Über lokal injektive Abbildungen:}} Sei $k > n$. Sei $M \subseteq \bR^n$ offen, sei $F : M \to \bR^k$ eine $C^r$-Abbildung. Sei $X_0 \in M$ und $F$ in $X_0$ vom Rang $n$ (und damit das Differential $DF_{X_0}$ injektiv). Sei $i$ die kanonische Injektion.
		 \newpar
		 Dann gibt es eine offene Umgebung $U$ von $X_0$ in $M$, eine offene Umgebung $V$ von $0$ in $\bR^{k-n}$, eine offene Umgebung $W$ von $F(X_0)$ in $\bR^k$, und einen $\bC^r$-Diffeomorphismus $h : U \times V \to W$, sodass das folgende Diagramm kommutiert:
		 \FloatBarrier
		 \begin{figure}[h!]
		 \centering
		    \begin{tikzcd}[row sep = huge, column sep = huge]
		    U
		    \arrow[r, "i"]
		    \arrow[dr, "F"]
		    & V \times F(u)
		    \arrow[d, "h"] \\
		    &  F(u)
		    \end{tikzcd}
		\end{figure}
	\end{theorem}
	\FloatBarrier
	\begin{proof}
	 	hi :D
	\end{proof}
\clearpage
[...]
\clearpage
%
%
%
%
%
%
%
\chapter{Diffeomorphismen}
In diesem Kapitel geht es um die lokale Lösbarkeit von nichtlinearen Gleichungen. 
\newpar
Sei $\Omega \in \bR^n$ offen und $f \in \bC^1(\Omega, \bR^m)$. Sei $y \in \bR^m$ gegeben. Uns interessieren nun Lösungen der Gleichung $f(x) = y$. Intuitiv ist dann $m$ die Anzahl der Gleichungen und $n$ die Anzahl der Unbekannten.
\newpar
Angenommen, wir haben bereits eine Lösung $x_0$ der Gleichung $f(x) = y_0$. Uns interessiert nun:
\begin{enumerate}
	\item Hat die Gleichung $f(x) = y$ auch für andere Werte von $y$ nahe an $y_0$ Lösungen? Falls ja, sind diese nahe an $x_0$?
	\item Ist $x_0$ die einzige Lösung von $f(x) = y_0$ in einer Umgebung von $x_0$?
	\item Falls nein, wie sieht die Lösungsmenge $f^{-1}(y_0)$ nahe bei $x_0$ aus?
\end{enumerate}
Falls $f$ affin ist, gilt $f(x) = y \Leftrightarrow A(x - x_0) = y - y_0$, und die Lineare Algebra gibt uns folgende Antworten:
\begin{enumerate}
	\item Es gibt genau dann eine Lösung für alle $y \in \bR^m$, wenn 
	\begin{align*}
		\rang A = m.
	\end{align*}
	\item Es gibt höchstens eine Lösung $x \in \bR^n$, wenn 
	\begin{align*}
		\ker A = \{0\}.
	\end{align*} Dies ist äquivalent zu 
	\begin{align*}
		\rang A = n.
	\end{align*}
	\item $f^{-1}\{y_0\}$ ist ein affiner Unterraum des $\bR^n$ mit Dimension $n - \rang A$.
\end{enumerate}
Da das Differential $Df(x_0)$ einer Abbildung $f \in C^1(\Omega, \bR^m)$ an einem gegebenen Punkt $x_0 \in \Omega$ eine lineare Abbildung ist, hoffen wir nun, einige dieser Erkenntnisse über lineare Funktionen auf die allgemeinere Klasse der differenzierbaren Funktionen übertragen zu können.
\newpar
Wir wollen hierfür die Funktion durch das Differential linear approximieren. Das Restglied für eine solche Approximation mit Abstand $\xi \in \bR^n$ ist dann genau die Differenz zwischen dem Tatsächlichen Wert und dem approximierten Wert, also:
\begin{align*}
	R_f(\xi) = f(x_0 + \xi) - (f(x_0) + Df(x_0)\xi)
\end{align*}
Für unsere Gleichung gilt nun:
\begin{align*}
	f(x) = y \Leftrightarrow Df(x_0) \cdot (x - x_0) + R_f(\xi) \cdot (x - x_0) = y - y_0
\end{align*}
Es wurde also einfach ein Restglied zur Gleichung für affine Funktionen hinzugefügt. Es hilft, im Kopf zu behalten, dass der affine Fall genau der Fall ist, in dem die Approximation exakt und somit das Restglied $0$ ist. 
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
\chapter{Implizite Funktionen}
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
\chapter{Gewöhnliche Differentialgleichungen}
\section{Anfangswertprobleme}
\subsection{Natürliches Wachstum}
Wir sprechen von \tbf{natürlichem Wachstum} wenn die Wachstums- oder Zerfallgeschwindigkeit proportional zum Wert der Funktion ist, also:
\begin{align*}
	x(t_0) = x_0, \qquad x' = \alpha x
\end{align*}
Die Lösung ist
\begin{align*}
	x(t) &= x_0 e^{\alpha(t - t_0)}
\end{align*}	
was oft vereinfacht geschrieben wird als:
\begin{align*}
	x(t) &= x_0 e^{\alpha(t - t_0)}\\
	&= \left(\frac{x_0}{e^{\alpha t_0}}\right) e^{\alpha t}\\
	&:= ce^{\alpha t}
\end{align*}
Ntürliches Wachstum tritt z.B. beim radioaktiven Zerfall oder in der Zinsrechnung auf.
\subsection{Logistisches Wachstum}
Beim Logistischen Wachstum wird eine zusätzliche "Sterberate" hinzugefügt:
\begin{align*}
	x(t_0) = x_0, \qquad x' = \alpha x - \beta x^2
\end{align*}
Die Lösung hier ist bereits deutlich komplizierter:
\begin{align*}
	x(t) = \frac{1}{\frac{\beta}{\alpha} + \left( \frac{1}{x_0} - \frac{\beta}{\alpha}\right) e^{-\alpha(t - t_0)}}
\end{align*}
Durch den Faktor $e^{-\alpha(t - t_0)}$ konvergiert die Lösung für $t \to \infty$ gegen $\frac{\alpha}{\beta}$.
\subsection{Lotka-Volterra-Modell}
Ein bekanntest Modell für Systeme von Raub- und Beutetieren ist das Modell von Lotka-Volterra. Wir betrachten eine Population $x(t)$ an Beutetieren und $y(t)$ von Raubtieren, sodass bei einer zu großen Raubtierpopulation die Wachstumsrate der Beutetierpopulation sinkt und bei einer zu kleinen Beutetierpopulation die Raubtierpopulation sinkt:
\begin{align*}
	x(t_0) &= x_0, \qquad x' = (\alpha - \beta y)x\\
	y(t_0) &= y_0, \qquad y' = (-\gamma + \delta x)y
\end{align*}
Eine besonders simple Lösung ist $x_0 = \frac{\delta}{\gamma}$, $y_0 = \frac{\alpha}{\beta}$ - in diesem Fall bleiben beide Populationen konstant.
\newpar
Im allgemeinen sind die Lösungen dieses Modells sind periodisch, eine allgemeine Lösungsformel lässt sich aber bereits nicht mehr analytisch durch Elementarfunktionen darstellen. Immerhin sind sie ohne größere Probleme sehr genau numerisch approximierbar.
\newpar
Wir wollen nun den Begriff des Anfangswertproblems formalisieren und unsere Lösungsmethoden verallgemeinern.
\begin{definition}
	Sei $G \subset \bR \times \bR^n$ offen und $f : G \to \bR^n$ stetig (in kürzerer Notation: $f \in C^0(G, \bR^n)$
	\newpar
	Eine stetig differenzierbare Funktion $x : I \to \bR^n$ (kurz: $x \in C^1(I, \bR^n)$) ist eine \tbf{Lösung der Differentialgleichung} $x' = f(\cdot, x)$, falls
	\begin{align*}
		\forall t \in I : x'(t) = f(t, x(t))
	\end{align*}
	Gilt außerdem $x(t_0) = x_0$, so ist $x$ eine \tbf{Lösung des dazugehörigen Anfangswertproblems}.
\end{definition}
\begin{definition}
	Falls die Funktion $f$ zeitunabhängig ist (also unabhängig von ihrer ersten Komponente) nennen wir die zugehörige Differentialgleichung \tbf{autonom}.
\end{definition}
\newpar
Die drei zentralen Fragen sind nun:
\begin{enumerate}
	\item Existert eine Lösung des Anfangswertproblems?
	\item Falls eine Lösung existiert, ist sie eindeutig?
	\item Wie hängt die Lösung von $x_0$ und $f$ ab?
\end{enumerate}
Die dritte Frage sprengt leider den Rahmen einer Grundlagenvorlesung Analysis. Die ersten beiden Fragen können wir jedoch bald befriedigend beantworten.
\newpar
Es stellt sich zum Beispiel heraus, dass selbst bei simplen Anfangswertproblemen die Stetigkeit von $f$ nicht ausreicht, um die Eindeutigkeit der Lösungsmenge zu gewährleisten:
\begin{example}
	Sei $f(t,x) = 2\sqrt{\abs{x}}$. Dann hat das Anfangsproblem
	\begin{align*}
		x(0) &= 0\\
		x' &= f(\cdot, x)
	\end{align*}
	unendlich viele Lösungen in $\bC^1(\bR, \bR)$, nämlich:
	\begin{align*}
		x_{\alpha, \beta}(t) = 
		\begin{cases}
			-(t - \alpha)^2 & t < \alpha\\
			0 & t \in [\alpha, \beta]\\
			(t - \beta)^2 & t > \beta\\
		\end{cases}
	\end{align*}
	für beliebige $\alpha \in \bR^-, \beta \in \bR^+$.
\end{example}
\begin{theorem}
	Hiii!!! 'w'
\end{theorem}
\begin{lemma}
	Sei $f \in \bC^0(G, \bR^n)$ und $(t_0, x_0) \in G$. 
	\newpar
	Dann sind die folgenden Aussagen quivalent:
	\begin{enumerate}
		\item $x \in \bC^1(I, \bR^n)$ ist eine Lösung des Anfangswertproblems
		\begin{align*}
			x(t_0) &= x_0,\\ \forall t \in I : x'(t) &= f(t,x(t)),
		\end{align*}
		\item $x \in \bC^0(I, \bR^n)$ erfüllt die Gleichung
		\begin{align*}
			\forall t \in I : x(t) = x_0 + \int_{t_0}^t f(s, x(s)) ds.
		\end{align*}
	\end{enumerate} 
\end{lemma}
\noindent 
Das folgende Beispiel zeigt, dass wir im Allgemeinen nur eine zeitlich lokale Lösung erwarten können:
\begin{example}
	Das Anfangswertproblem 
	\begin{align*}
		x(0) &= 1,\\
		x' &= x^2 
	\end{align*}
	Hat auf $(-\infty, 1)$ die Lösung $x(t) = \frac{1}{1-t}$. Diese Lösung hat jedoch bei $t = 1$ eine Singularität und ist somit nicht fortsetzbar.
\end{example}
\begin{theorem}
	\emph{\tbf{Kurzzeitexistenzsatz von Picard-Lindelöf:}} \\\noindent Sei $f \in \bC^0(G, \bR^n)$ mit $D_x f \in \bC^0(G, \bR^{n \times n})$. Sei $(t_0, x_0) \in G$.
	\newpar
	Dann existiert ein $\delta > 0$, sodass das Anfangswertproblem
	\begin{align*}
		x(t_0) &= x_0,\\
		\forall t \in [t_0-\delta, t_0 + \delta] : x'(t) &= f(t, x(t))
	\end{align*}
	eine eindeutige Lösung besitzt.
\end{theorem}
\begin{proof}
	Banachscher Fixpunktsatz :)
\end{proof}
Gewöhnliche Differentialgleichungen, auf Englisch \textit{ordinary differential equations} (\textit{ODEs}) beschreiben zeitabhängige Prozesse. Sie sind nützlich für die Modellierung zahlreicher Prozesse in verschiedenen Gebieten der Wissenschaft.
\section{Motivation}
Wir wollen die Fischpopulation in einem See modellieren. Wir bezeichnen die Anzahl an Fischen zum Zeitpunkt $t$ mit $y(t)$. Wie viele Fische dürfen die Menschen am See fangen, ohne dass die Fischpopulation ausstirbt?
\newpar
Wir führen folgende Größen ein:
\begin{itemize}
	\item Die Geburtenrate $G(t)$. Wir nehmen an, dass diese proportional zur Größe der Fischpopulation ist, also
	\[G(t) = b y(t).\]
	\item Die natürliche Todesrate $T(t)$. Auch hier gehen wir von Proportionalität zur Population aus:
	\[T(t) = m y(t).\]
	\item Die Fischfangrate $H(t)$.
\end{itemize}
Wir erhalten nun die Gleichung:
\[y'(t) = (b-m)y(t) - H(t)\]
Wir nehmen außerdem an, dass $(b-m) := a > 0$. Diese Größe kann durch Beobachtungen gemessen werden, $H(t)$ ist kontrollierbar. Zu einem gegebenen Anfangszeitpunkt $t_0$, an dem die Fischpopulation $y(t_0) = y_0$ beträgt, können die Menschen nun berechnen, wie viele Fische sie fangen dürfen.
\newpar
Wir betrachten als erstes die einfachstmögliche Situation, in der die Fischfangrate $H(t)$ zeitunabhängig konstant bleibt, also $H(t) = H \in \bR$. Wir erhalten so unser erstes Modell:
\begin{nalign}
	\label{eq:simplefishmodel}
	y' &= ay - H\\
	y(t_0) &= y_0\\
\end{nalign}
Da die Ableitung proportional zur Funktion selbst ist eine Exponentialgleichung eine naheliegende Lösung. Eine rigorose Herleitung dieser Intuition folgt später. Mit diesem Wissen können wir jedoch bereits eine "how would you come up with that"-Herleitung durchführen: 
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

\section{Existenztheorie}
\begin{definition}
	Für $f : \bR^{n+1} \to \bR$ nennen wir eine Gleichung der Form
	\begin{align*}
		y^{(n)}(t) = f(t, y(t), y'(t), \hdots, y^{(n-1)}(t))
	\end{align*}
eine \textit{explizite Differntialgleichung n-ter Ordnung}. Ist zusätzlich
\[y^{(i)}(t_0) = y_{i-1}\]
für $(t_0, y_0, y_1, \hdots y_{n-1}) \in \bR^{n+1}$ gegeben, spricht man von einem \textit{Anfangswertproblem.}
\end{definition}
\begin{definition}
	Sei $I$ ein Intervall. Eine Funktion $y : I \to \bR$ heißt \textit{Lösung} von (2.1) im Intervall $I$, falls $y$ in $I$ $n$-mal differenzierbar ist und
	\[y^{(n)}(t) = f(t, y(t), y'(t), \hdots, y^{(n-1)}(t))\]
	für alle $t \in I$ erfüllt ist.
\end{definition}
Wir erlauben hier jede Art von Intervall, egal ob offen, halboffen, oder geschlossen.
\begin{definition}
	Sei $F : \omega \subseteq \bR^{n+1} \to \bR^n$. Wir nennen das Gleichungssystem
	\[Y'(t) = F(t, Y(t))\]
	ein \textit{System von Differentialgleichungen 1. Ordnung}. Für $F = (f_1, \hdots, f_n)$ und $Y = (y_1, \hdots, y_n)$ lässt sich das System komponentenweise schreiben als:
	\begin{align*}
		y_1'(t) &= f_1(t, y_1(t), \hdots, y_n(t))\\
		&\hspace{6pt}\vdots\\
		y_n'(t) &= f_n(t, y_1(t), \hdots, y_n(t))\\
	\end{align*}
	Ergänzt man das System durch die Bedingung $Y(t_0) = Y_0$ erhalten wir komponentenweise:
	\begin{align*}
		y_1(t_0) &= y_1^0\\
		&\hspace{6pt}\vdots\\
		y_n(t_0) &= y_n^0\\
	\end{align*}
	Für ein $(t_0, y_1^0, \hdots, y_n^0) \in \Omega$ und sprechen wieder von einem \textit{Anfangswertproblem}.
\end{definition}
\begin{lemma}
 Erfülle $F$ die Vorraussetzung $(S)$, sei außerdem $y_i (a,b) \to \bR^n$ eine Lösung des Gleichungssystems $Y'(t) = F(t,Y(t))$. Weiter existiere der Grenzwert $\lim_{t \to^+ b} Y(t) := y_1$ und es gelte $(b,y_1) \in \Omega$. Dann existiert $\delta > 0$, sodass man die Lösung $y$ zu einer Lösung auf dem Intervall $(a, b+\delta]$ fortsetzen kann.
\end{lemma}
\begin{definition}
 Seien $A,B \in \bR^{n+1}$. Wir definieren zwischen den beiden Mengen folgendermaßen eine Abstandsfunktion: \begin{align*}
  \text{dist}(A,B) := \inf_{x \in A, y \in B} \norm{X - Y}                                                                                                   
 \end{align*}
\clearpage
[big gap here oops]
\clearpage
\begin{lemma}
	Seien $I,J$ offene Intervalle, sei $f : J \times I \to \bR$ durch $f(t,y) = h(t)g(y)$ gegeben, wobei $g : I \to \bR$, $g \neq 0$, $h : J \to \bR$ stetig sind. Falls $\varphi : (\alpha, \beta) \subseteq J \to I$ eine Lösung von (3.1) ist, existiert $c \in \bR : \forall t \in (\alpha, \beta)$
	\[\varphi(t) = G^{-1}(H(t) + c)\]
\end{lemma}
\begin{theorem}
	Erfülle $f$ die Vorraussetzung des letzten Lemmas. Dann existiert $\forall (t_0, y_0) \in J \times I$ eine eindeutige maximale Lösung $y : J_0 \to I$ von (3.1) mit $y(t_0) = y_0$. Diese Lösung ist von der Form
	\[y(t) = G^{-1}(H(t)),\]
	wobei \[G(y) = \int_{y_0}^y \frac{1}{g(x)} dx, y \in I,\] \[H(t) = \int_{t_0}^{t}h(s) ds, t \in J\] ist. 
\end{theorem}
\end{definition}
\begin{example}
	Sei $y'(t) = 2t(1 + y^2)$ mit Anfangsbedingung $y(t_0) = y_0$, wobei $(t_0, y_0 \in \bR^2)$.
	Dann gilt:
	\[
		g(y) = 1 + y^2, \quad h(t) = 2t
	\]
	\begin{align*}
		G(y) &= \int_{y_0}^y \frac{1}{1+x^2} dx \\
			 &= \arctan y - \arctan y_0\\
			 &:= \arctan y - c_0
	\end{align*}
	\begin{align*}
		H(t) &= \int_{t_0}^t 2s\ ds\\
			 &= t^2 - t_0^2
	\end{align*}
	\begin{align*}
		\text{Bild}(G) = \left(-\frac{\pi}{2} - c_0, \frac{\pi}{2} - c_0\right), \quad c_0 \in \left(-\frac{\pi}{2},\frac{\pi}{2}\right)
	\end{align*}
	\begin{enumerate}
		\item $-t_0^2 > -\frac{\pi}{2} - c_0$
		\[\alpha := \sqrt{\frac{\pi}{2} - c_0 + t_0^2}\]
		\[H^{-1}(\text{Bild}(G)) = (-\alpha, \alpha)\]
		\[y(t) = \tan(t^2 - t_0^2 + \arctan(y_0))\]
		\item $-t_0^2 \leq -\frac{\pi}{2} - c_0$
		\[\alpha = \sqrt{-\frac{\pi}{2} - c_0 + t_0^2}\]
		\[\beta := \sqrt{\frac{\pi}{2} - c_0 + t_0^2}\]
		\[H^{-1}(\text{Bild}(G)) = (-\beta, -\alpha) \cup (\alpha, \beta)\]
		OBdA $t_0 \in (\alpha, \beta)$, dann
		\[y(t) = \tan(t^2 - t_0^2 - \arctan(y_0))\]
	\end{enumerate}
\end{example}
\clearpage
\section{Lineare Gleichungen}
Angenommen, wir haben eine Funktion $f(t, y)$ der Form
\[f(t,y) = h(t)y + p(t)\]
Es gilt:
\[h, p : I = (a,b) \to \bR\]
Wobei nach Annahme $h, p$ stetig sind und $f : I \times \bR \to \bR$ die Vorraussetzung (S) erfüllt.
\newpar
Wenn $p(t) = 0$ nennen wir die Differentialgleichung $y' = f(t,y)$ \textbf{homogen}, ansonsten nennen wir sie \textbf{inhomogen}.
\newpar
\[y' = h(t)y + p(t) \Leftrightarrow y'(t) - h(t)y(t) = p(t)\]
Wir suchen nun das Urbild von $p \in C^0(I)$ bezüglich
\[L : C^1(I) \to C^0(U) : y \mapsto y' - hy\]
\[(L(y))(t) := y'(t) - h(t)y(t)\]
Es gilt:
\[L(\alpha y + \beta z) = \alpha L(y) + \beta(L(z))\]
Also ist $L$ ein linearer Operator!
\newpar
[...]
\clearpage
\begin{lemma}
	Sei $I = (a,b)$ und für $f : I \times \bR \to \bR$ gelte
	\[f(t,y) = h(t)y + p(t)\]
	Wobei $p, h$ auf $I$ stetig sind. Seien Lösungen $y_1, y_2$ der inhomogenen Gleichung und $y_0$ Lösung der homogenen Gleichung. Dann gilt:
	\begin{enumerate}
		\item[(i)] $y_1 - y_2$ ist Lösung der homogenen Gleichung
		\item[(ii)] $y_1 + y_0$ ist Lösung der inhomogenen Gleichung
	\end{enumerate}
\end{lemma}
\begin{lemma}
	Sei $y_2$ eine Lösung der inhomogenen Gleichung und $y_0$ eine Lösung der homogenen Gleichung. So existiert eine Lösung $y_1$ der inhomogenen Gleichung, sodass
	\[y_2 = y_0 + y_1\]
\end{lemma}
	\noindent\textbf{Variation der Konstanten:} 
	\[y(t) = c(t) e^{H(t)}\]
	\[y'(t) = c'(t) e^{H(t)} + c(t)e^{H(t)}h(t)\]
	Damit $y$ eine Lösung von (3.1) ist muss gelten:
	\[y'(t) = p(t) + h(t)y(t)\]
	Also:
	\[c'(t) = p(t)e^{-H(t)}\]
	Also ist $c$ eine Stammfunktion von $pe^{-H}$.
\begin{theorem}
	Sei $I = (a,b)$, für $f : I \times \bR \to \bR$ gelte
	\[f(t,y) = h(t)y + p(t)\]
	$p,h$ stetig. Dann existert für alle $(t_0, y_0) \in I \times \bR$ eine eindeutige, maximale Lösung
	\[y : I \to \bR\]
	von (3.1) mit $y(t_0) = y_0$. Diese Lösung hat folgende Form:
	\[y(t) = e^{[H(t)]}\left(y_0 + \int_{t_0}^t p(s) e^{-H(s)} ds\right)\]
	Wobei
	\[H(t) = \int_{t_0}^t h(s) ds\]
\end{theorem}
\begin{proof}
	\begin{align*}
		y(t_0) = e^{H(t_0)} (y_0 + 0) = y_0
	\end{align*}
	Rechnungen liefern, dass $y : I \to \bR$ maximal ist. Seien $y_1, y_2$ eine maximale Lösung mit $y_i(t_0) = y_0$. $\overline{y} := y_1 - y_2$ ist eine Lösung der homogenen Gleichung mit $y(t_0) = 0$, also $\overline{y}(t) = 0$, also $y_1 = y_2$.
\end{proof}
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
\clearpage
\chapter{Systeme Linearer Differentalgleichungen}
Wir suchen nach Lösungen von Gleichungssystemen der Form:
\[Y'(t) = \tbf{A}(t) Y(t) + \tbf{B}(t)\]
Wobei $\tbf{A}, \tbf{B}$ Matrizen sind.
\newpar
Sei $I = (a,b)$ und sei $F(t,Y) := \tbA(t) Y + \tbB(t)$. $F$ ist bezüglich $Y$ lokal Lipschitzstetig, also existiert eine eindeutige maximale Lösung mit $Y(t_0) = Y_0$.
\begin{lemma}
	\tbf{Lemma von Gronwall:}\\
	Sei $J$ ein Intervall, $t_0 \in J$, $\alpha, \beta \in [0, \infty)$. Ferner sei $x : J \to [0, \infty)$ stetig und erfülle
	\[x(t) \leq \alpha + \beta \abs{\int_{t_0}^t x(s) ds}\]
	Für $t \in J$. Dann gilt
	\[x(t) \leq \alpha e^{\beta \abs{t - t_0}}\]
\end{lemma}
\begin{proof}
	Sei $t \geq t_0$, $t \in J$. Sei
	\[h(s) := \beta e^{\beta(t_0 - s)}\int_{t_0}^s x(\tau) d\tau\]
	mit $s \in [t_0, t]$. Sei
	\begin{align*}
		h'(s) &= \beta e^{\beta(t_0 - s)} (-1)\beta \int_{t_0}^s x(\tau) d\tau + \beta e^{\beta(t_0 - s)} x(s)\\
			  &= - \beta h(s) + \beta e^{\beta(t_0 - s)} x(s)\\
			  &\leq - \beta h(s) + \beta e^{\beta(t_0 - s)} \left(\alpha + \beta \abs{\int_{t_0}^s x(\tau) d\tau}\right)\\
			  &= - \beta h(s) + \alpha \beta e^{\beta(t_0 - s)} + \beta h(s)\\
			  &= \alpha \beta e^{\beta(t_0 - s)}
	\end{align*}
	\begin{align*}
		\int_{t_0}^t h'(s) ds = h(t) - h(t_0) = h(t) = \beta e^{\beta(t_0 - s)}\int_{t_0}^s x(\tau) d\tau
	\end{align*}
	\begin{align*}
		\int_{t_0}^t \frac{d}{ds}(-\alpha e^{B(t_0 - s)}) ds &= -\alpha e^{\beta(t_0 - t)} + \alpha\\
		\implies \beta e^{\beta(t_0 - s)}\int_{t_0}^t x(\tau) &\leq \alpha -\alpha e^{\beta(t_0 - t)}
	\end{align*}
	\begin{align*}
		\beta \int_{t_0}^t x(s) ds &\leq \alpha e^{\beta(t - t_0)} - \alpha\\
		\implies \alpha + \beta \int_{t_0}^t x(s) ds &\leq \alpha e^{\beta(t - t_0)}\\
		\implies x(t) &\leq \alpha e^{\beta(t - t_0)}
	\end{align*}
\end{proof}
\begin{theorem}
	Seien $\tbA, \tbB$ stetig Funktionen auf $I = (a,b)$. Dann ist jede maximale Lösung des dazugehörigen Differentialsystems auf ganz $(a,b)$ definiert.
\end{theorem}
\begin{proof}
	Sei eine maximale Lösung gegeben durch:
	\begin{align*}
		Y : (\alpha, \beta) \to \bR^n
	\end{align*}
	Wobei $Y(t_0) = Y_0, t_0 \in (\alpha, \beta)$. Da $Y$ eine maximale Lösung ist existiert der Limes
	\[\lim_{t \to^+ \beta} Y(t)\] 
	nicht. Sei $(\alpha, \beta) \subsetneq (a,b)$, OBdA $\beta < b$. Sei für $n \in \bN$:
	\[K_n := \{(t,Y) \in \bR^{n+1} \mid t \in [t_0, \beta], \norm{Y} \leq n\}\]
	Da diese Menge kompakt ist und $Y$ eine maximale Lösung ist, ist
	\[G^+ = \{(t,z) \in \overline{\text{graph}(Y)} \mid t \geq t_0\}\]
	keine kompakte Teilmenge.
	\begin{align*}
		\exists \tau_n \in [t_0, \beta) : \norm{Y(\tau_n)} = n\\
		\implies \lim_{n \to \infty} \norm{Y(\tau_n)} = \infty
	\end{align*}
	\begin{align*}
		n(T) &:= \norm{Y(t)} t \in (\alpha, \beta)\\
		\delta &:= \max_{t \in [t_0, \beta]} \norm{\tbA(t)}_{\bR^{n \times m}} < \infty\\
		\gamma &:= \max_{t \in [t_0, \beta]} \norm{\tbB(t)}_{\bR^{n}} < \infty\\
	\end{align*}
	Da $Y$ eine Lösung ist, ist:
	\begin{align*}
		Y(t) = Y(t_0) + \int_{t_0}^t \tbA(s)Y(s) + \tbB(s) ds t \in [t_0, \beta)
	\end{align*}
\end{proof}
[...]
\clearpage
\begin{definition}
	Wir nennen die Matrix $\tbY$, welche das System linearer Differentialgleichungen beschreibt, die \textbf{Fundamentalmatrix} des Systems.
\end{definition}
\begin{lemma}
	Es gilt $\tbY' = \tbA \tbY$.
\end{lemma}
\begin{definition}
	Wir definieren $\tbZ(t) = \tbY(t) \tbY^{-1}(t_0)$.
\end{definition}
\begin{definition}
	Sei $I = (a,b), A : I \to \bR^{n \times n}$ stetig. Sei $\tbY$ eine Fundamentalmatrix eines homogenen Systems linearer Differentialgleichungen. Wir nennen
	\[W(t) := \det{\tbY(t)}\]
	die \tbf{Wronski-Determinante}.
\end{definition}
\begin{theorem}
	Sei $I = (a,b), \tbA : I \to \bR^{n \times n}$ stetig. Sei $\tbY$ eine Fundamentalmatrix eines homogenen Systems linearer Differentialgleichungen. Dann gilt
	\[W(t) = W(t_0) e^{\int_{t_0}^t \tr(\tbA(s)) ds}\]
	für $t \in I$, wobei die Spur $\tr(\tbA)$ einer quadratischen Matrix als die Summe der Diagonaleinträge definiert ist.
\end{theorem}
\begin{proof}
	Es gilt $\tr(A) \in \bR$, $W(t) \in \bR$. Wir betrachten also eine skalare Gleichung. Gemäß Satz (3.8?) aus Kapitel 12 gilt diese Formel genau dann, wenn
	\[W'(t) = \tr(\tbA(t))\]
	Wir benötigen also eine Formel für die Ableitung der Determinante. Für $\tbB = (b_{ij})$ gilt
	\[\det \tbB = \sum_{\sigma \in S_n} \text{sgn}(\sigma) b_{1\sigma(1)} \cdot \hdots \cdot b_{n\sigma(n)}\]
	Somit gilt:
	\[(\det \tbB)' = \sum_{i=1}^n \sum_{\sigma \in S_n} \text{sgn}(\sigma) b_{1\sigma(1)} \cdot \hdots \cdot b_{i \sigma(i)}' \cdot \hdots \cdot b_{n\sigma(n)}\]
	(insert black magic here)
	\newpar
	Es folgt:
	\[W(t) = \det \tbY(t) = \det \tbZ(t) \det \tbY(t_1) = \det \tbZ(t) W(t_1)\]
	und somit:
	\[W'(t) = (\det \tbZ(t))' W(t_1)\]
	Mit der Formel der Ableitung der Determinante gilt:
	\begin{align*}
		(\det \tbZ(t_1))' &= \sum_{i = 1}^n \det (Z_1(t_1), \hdots, Z_i'(t_1), \hdots, Z_n(t_1))\\
						  &= \sum_{i = 1}^n \det (E_1(t_1), \hdots, \tbA(t_1)E_i, \hdots, E_n(t_1))\\
						  &= \sum_{i = 1}^n a_{ii}(t_1)\\
						  &= \tr \tbA(t_1)
	\end{align*}
	Es gilt folglich:
	\[W'(t) = \tr \tbA(t_1)W(t_1)\]
\end{proof}
\begin{corollary}
	Die Wronski-Determinante einer Fundamentalmatrix ist überall ungleich Null.
\end{corollary}
\section{Systeme mit Konstantem A}
Wir betrachten Systeme der Form:
\[Y'(t) = \tbA Y(t)\]
Wir betrachten dabei die lineare Abbildung:
\[A : \bR^n \to \bR^n : Y \mapsto \tbA Y\]
Also $\tbA = M_{E}^{E}(A)$. Aus der Linearen Algebra ist bekannt, dass:
\[M^{B}_B(A) = M_B^E(id) M_E^E(A) M_E^B(id)\]
Wobei $M_E^B(id) := \tbB$ und $M_B^E := \tbB^{-1}$. Also:
\[M_B^B(A) = \tbB^{-1} \tbA \tbB := \tbD\]
\[Z(t) := \tbB^{-1}Y(T) \Leftrightarrow \tbB Z(t) = Y(t)\]
Falls $Y$ eine Lösung des Systems mit Konstante ist, gilt:
\[Z'(t) = \tbB^{-1}Y'(t) = \tbB^{-1}\tbA Y(t) = \tbB^{-1}\tbA\tbB Z(t) = \tbD Z(t)\]
\begin{theorem}
	Wenn $\tbA$ symmetrisch ist, können wir die Matrix diagonalisieren und erhalten eine besonders simple Lösung der Form:
	\[\tbY = \tbB \tbZ = (B_1 e^{\lambda_1 t}, \hdots, B_n e^{\lambda_n t})\]
\end{theorem}
\chapter{Maßtheorie}
Unser nächstes Großes Ziel ist eine Verallgemeinerung des Integrationsbegriffs. Wir arbeiten hin zum sogenannten \tbf{Lebesque-Integral}, welches uns Funktionen integrieren lässt, die bisher nicht integrierbar waren.
\newpar
Die erste Vorraussetzung ist ein allgemeiner Volumenbegriff. Dieser wird uns gegeben durch \tbf{Maße}, welche die intuitiven Begriffe von Längen, Volumen etc. formalisieren und generalisieren. 
\begin{itemize}
	\item Eindimensionales Maß: Länge eines Intervalls.
	\item Zweidimensionales Maß: Flächeninhalt eines Rechtecks.
	\item Dreidimensionales Maß: Volumen eines Quaders.
	\item etc.
\end{itemize}
Wie misst man nun beliebige Mengen? Gibt es für jede Menge ein sinnvolles "Volumen"?
\newpar
	Intuitiv sollte ein Maß auf $\bR^n$ eine Funktion
	\begin{align*}
		m : \cP(\bR^n) \to \bR_{\geq 0}
	\end{align*}
	sein, welche folgende Eigenschaften hat:
	\begin{enumerate}
		\item Es ist \tbf{bewegungsinvariant} - das Maß ist konstant unter orthogonalen Abbildungen.
		\item Das Maß ist \tbf{zählbar additiv}:
		\begin{align*}
			m \left(\bigcup_{i} A_i \right)= \sum_{i} m(A_i) \quad A_i \cap A_j = \infty \quad i \neq j
		\end{align*}
		\item Das Maß des Einheitswürfels ist auf $1$ \tbf{normiert}:
		\begin{align*}
			m([0,1]^n) = 1
		\end{align*}
	\end{enumerate}
Erlauben wir bei Bedingung $2$ nur endliche Vereinigungen, führt der Maßbegriff zum \tbf{Inhaltsproblem}, welches wiederum in Dimension $ \geq 3$ oder höher zum \tbf{Banach-Tarski-Paradox} führt und somit nicht lösbar ist.
\newpar
Erlauben wir jedoch auch unendliche Vereinigungen, erhalten wir das \tbf{Maßproblem}, dessen Unlösbarkeit in Dimension $\geq 1$ durch Lebesque gezeigt wurde.
\newpar
Es ist also leider nicht möglich, einen sinnvollen Maßbegriff in unserer idealisierten Form zu erhalten.
\newpar
Unser Ansatz ist wird letztendlich sein, nur Mengen zu messen, welche im Grenzwert als zählbare Vereinigung von Rechtecken / Quadern / etc. (endliche Vereinigung von Intervallen) dargestellt werden können. Glücklicherweise sind die einzigen Gegenbeispiele jedoch pathologische Mengen, die uns sowieso nicht allzu sehr interessiert haben.
\begin{theorem}
	Jede offene Menge ist als zählbare Vereinigung geschlossenerer Quader darstellbar.
\end{theorem}
\section{Mengensysteme}
\subsection{Mengenringe und Mengenalgebren}
\begin{definition}
	Sei $X$ eine Menge. Ein Mengensystem $\cR \subseteq \cP(X)$ heißt \tbf{Mengenring}, falls:
	\begin{enumerate}
		\item $\emptyset \in \cR$
		\item $\forall A,B \in \cR : A \symdiff B \in \cR$
		\item $\forall A,B \in \cR : A \cap B \in \cR$
	\end{enumerate}
\end{definition}
\noindent Mengenringe bilden einen kommutativen Ring im Sinne der Algebra, in dem $\vartriangle$ der Addition entspricht, $\cap$ der Multiplikation, und $\emptyset$ das Nullelement $0_{\cR}$. Falls $X \in \cR$, so ist es das Einselement $X = 1_{\cR}$.
\begin{proposition}
	Äquivalent kann ein Mengenring definiert werden als ein Mengensystem $\cR \subseteq \cP(X)$, welches folgende Bedingungen erfüllt:
	\begin{enumerate}
		\item $\emptyset \in \cR$
		\item $\forall A,B \in \cR : A \setminus B \in \cR$
		\item $\forall A,B \in \cR : A \cup B \in \cR$
	\end{enumerate}
\end{proposition}
\begin{definition}
	Eine \tbf{Mengenalgebra} ist ein Mengenring, welcher die gesamte Menge $X$ enthält.
\end{definition}
\begin{proposition}
	Das System aller endlichen Teilmengen einer Menge $X$ bildet einen Mengenring.
\end{proposition}
\begin{proposition}
	Das System aller höchstens abzählbaren endlichen Teilmengen einer Menge $X$ bildet einen Mengenring.
\end{proposition}
\begin{proposition}
	Sei $H$ die Menge der halboffenen Intervalle $[a,b)$. So bildet das System aller Mengen $A \subseteq \bR$, die sich als endliche Vereinigung solcher Intervalle darstellen lassen, einen Mengenring $\cH$.
\end{proposition}
\begin{proposition}
	Sei $A \subseteq X$. So ist $\{\emptyset, A\}$ ein Mengenring, welcher genau dann eine Mengenalgebra ist, wenn $A = X$.
\end{proposition}
\subsection{$\sigma$-Algebren}
\begin{definition}
	Sei $X$ eine Menge. Ein Mengensystem $\cA \subseteq \cP(X)$ heißt \tbf{$\sigma$-Algebra}, falls folgendes gilt:
	\begin{enumerate}
		\item $X \in \cA$
		\item $A \in \cA \implies X \setminus A \in \cA$
		\item $\forall i \in \bN : A_i \in \cA \implies \bigcup_{i \in \bN} A_i \in \cA_i$
	\end{enumerate}
	Das Paar $(X, \cA)$ heißt \tbf{messbarer Raum}.
\end{definition}
\begin{theorem}
	Es gilt außerdem:
	\begin{enumerate}
		\item $\forall i \in \bN : A_i \in \cA \implies \bigcap_{i \in \bN} A_i \in \cA$
		\item $\emptyset \in \cA$
		\item $\forall A, B \in \cA : A \setminus B \in \cA$
	\end{enumerate}
\end{theorem}
\begin{proof}
	\begin{align*}
		\bigcap_{i \in \bN} A_i = X \setminus \left(\bigcup_{i \in \bN} (X \setminus A_i)\right)
	\end{align*}
	\begin{align*}
		\emptyset = X \setminus X
	\end{align*}
	\begin{align*}
		A \setminus B = A \cap (X \setminus B)
	\end{align*}
\end{proof}
\noindent Die Potenzmenge $\cP(X)$ selbst ist bereits eine $\sigma$-Algebra. Ebenso ist die Menge $\{\emptyset, X\}$ bereits eine $\sigma$-Algebra. Später werden wir zeigen, dass die Menge der \tbf{messbaren Mengen} eine $\sigma$-Algebra bilden und dass die offenen Mengen ein Teilsystem der messbaren Mengen bilden.
\begin{theorem}
	Jeder zählbar unendliche Durchschnitt von $\sigma$-Algebren ist wieder eine $\sigma$-Algebra.
\end{theorem}
\begin{proof}
	Proof by trying every necessary condition and realizing it works.
\end{proof}
\begin{definition}
	Für ein Mengensystem $\cE\subseteq \cP(X)$ heißt
	\begin{align*}
		\sigma(\cE_i) = \bigcap \left\{\cA \mid \cA \text{ ist $\sigma$-Algebra und } \cE \subseteq \cA \right\}
	\end{align*}
	die von $\cE$ \tbf{erzeugte} $\sigma$-Algebra.
\end{definition}
\noindent $\sigma(\cE)$ ist in jeder Sigma-Algebra, welche $\cE$ enthält, enthalten, also ist $\sigma(\cE)$ die kleinste $\sigma$-Algebra, welche $\cE$ enthält.
\newpar
Einige Beispiele für wichtige $\sigma$-Algebren:
\begin{enumerate}
	\item Ist $E \subseteq X$ und $\cE = \{E\}\}$, so gilt $\sigma(\cE) = \{\emptyset, E, X \setminus E, X\}$
	\item Sei $(X, \cO)$ ein topologischer Raum, also $\cO$ das System der offenen Mengen. Die von $\cO$ erzeugte $\sigma$-Algebra heißt \tbf{Borel-$\sigma$-Algebra} $\cB(\cO)$, und ihre Elemente heißen \tbf{Borelmengen}. Im Fall des $\bR^n$ mit der kanonischen Topologie schreiben wir auch $\cB^n$.
	\item Sei $X$ eine beliebige nichtleere Menge, $\cC$ eine $\sigma$-Algebra auf einer Menge $Y$ und $f : X \to Y$ eine Abbildung. So ist
	\begin{align*}
		f^{-1}(\cC) := \{B \subseteq X : f(B) \in \cC\}
	\end{align*}
	eine $\sigma$-Algebra.
	\item[3.1] Sei $X \subseteq Y$ und sei $\bC$ eine $\sigma$-Algebra auf $Y$. So nennen wir die durch die Identitätsabbildung $\id : X \to Y, x \to x$ induzierte $\sigma$-Algebra
	\begin{align*}
		\cC \mid_{X} := \id^{-1}(\cC) = \{\id^{-1}(C) \mid C \in \cC\} = \{X \cup A \mid A \in \cC\}
	\end{align*}
	auch die \tbf{Spur-$\sigma$-Algebra auf $X$} oder die \tbf{von $\cC$ auf $X$ induzierte $\sigma$-Algebra.}
\end{enumerate}
\begin{proposition}
	Es ist konsistent mit ZF (Also der Standardaxiomatik der Mengenlehre, ausgenommen das Auswahlaxiom), dass jede Menge $M \in \cP(\bR)$ eine Borelmenge ist.
\end{proposition}
Somit sind Existenzbeweise von Mengen, welche nicht Borel sind, in der Regel nichtkonstruktive Beweise, welche auf Feinheiten der Mengenlehre aufbauen. Das berühmteste Beispiel sind die sogenannten Vitalimengen, welche auch nach unseren späteren Verfeinerungen des Maßbegriffs noch Probleme bleiben werden.
\begin{definition}
	Eine \tbf{Vitalimenge} ist eine Teilmenge $V \subset [0,1]$, sodass für jede reelle Zahl $r$ genau eine Zahl $v \in V$ enthalten ist, sodass $v - r \in \bQ$.
\end{definition}
\begin{proposition}
	Wird das Auswahlaxiom angenommen, existieren Vitalimengen.
\end{proposition}
\begin{proofsketch}
	Die Rationalen Zahlen $\bQ$ bilden eine normale Untergruppe der reellen Zahlen $\bR$. Somit können wir die Quotientengruppe $\bR / \bQ$ bilden.
	\newpar
	$\bR / \bQ$ ist überabzählbar. Die Elemente von $\bR / \bQ$ sind disjunkte Mengen reeller Zahlen, welche die Form $\{r + \bQ \mid r \in \bR\}$ haben. Da $\bQ$ dicht in $\bR$ ist, ist auch jede Äquivalenzklasse dicht in $\bR$.
	\newpar
	Durch das Auswahlaxiom können wir nun aus jeder Äquivalenzklasse ein Element wählen, welches in $[0,1]$ liegt. Wir erhalten eine Vitalimenge.
\end{proofsketch}
\begin{proposition}
	Vitalimengen sind nicht Borel.
\end{proposition}
\noindent Ein Beweis folgt deutlich später in \ref{theorem:vitalinonmeasurable}.
\newpar\newpar
Nun fürs Erste zurück zu $\sigma$-Algebren.
\begin{theorem}
	Sei $X$ eine Menge und seien $\cE_i \subseteq \cP(X)$ Mengensysteme. So gilt:
	\begin{align*}
		\sigma\left(\bigcup_{i \in I} \cE_i \right) = \sigma\left(\bigcup_{i \in I} \sigma(\cE_i)\right)
	\end{align*}
	\begin{proof}
		Es gilt $\cE_i \subseteq \sigma(\cE_i)$, also auch $\sigma\left(\bigcup_{i \in I} \cE_i \right) \subseteq \sigma\left(\bigcup_{i \in I} \sigma(\cE_i)\right)$.
		\newpar
		Umgekehrt gilt (TODO)
	\end{proof}
\end{theorem}
\begin{theorem}
	Jede $\sigma$-Algebra ist entweder endlich oder überabzählbar.
\end{theorem}
\begin{proof}
	Wir definieren:
	\begin{align*}
		\at(x) := \bigcap \{A \in \cA : x \in A\}
	\end{align*}
	\begin{lemma}
		Für jedes $x,y \in X$ gilt
		\begin{align*}
			\at(x) \cap \at(y) \neq \emptyset \implies \at(x) = \at(y)
		\end{align*}
	\end{lemma}
	\begin{proof}
		Angenommen, $\at(x) \neq \at(y)$. Dann existiert ein Element $A_x \in \cA$, in dem $x$ enthalten ist, aber nicht $y$. Dann ist $X \setminus A_x \in \at(y)$ und disjunkt von $A_x$. Dann gilt $\at(y) = \at(y) \cap X \setminus A_x$. Außerdem ist 
		\begin{align*}
			\at(x) = \bigcap \{A \in \cA : x \in A\} = \bigcap \{A \in \cA : x \in A\} \cap A_x = \at(x) \cap A_x.
		\end{align*} Es folgt: 
		\begin{align*}
			\at(x) \cap \at(y) = \at(x) \cap A_x \cap X \setminus A_x \cap \at(y) = \emptyset
		\end{align*}
	\end{proof}
	\begin{lemma}
		Falls $\cA$ abzählbar ist, gilt für jedes $x \in X$ $\at(x) \in \cA$, und für jedes $A \in \cA$ $A = \bigcup_{x \in A} \at(x)$
	\end{lemma}
	\begin{proof}
		Die erste Bedingung folgt daraus, dass die $\sigma$-Algebra unter abzählbaren Schnitten abgeschlossen ist. Es gilt $A \subseteq \bigcup_{x \in A} \at(x)$, da in jedem $\at(x)$ zumindest eine Menge enthalten ist, die $x$ enthält. Es gilt $\forall x : \at(x) \subseteq A$, da $x \in A$ und $\at(X)$ als Schnitt aller solcher Teilmengen definiert ist, somit gilt auch $\bigcup_{x \in A} \at(x) \subseteq A$.
	\end{proof}
	\noindent
	Wir wollen nun diese Lemmas zum Widerspruch führen. Angenommen, $\cA$ ist nicht überabzählbar. Sei $B \subseteq \cA$ die Menge der Atome.
	\begin{enumerate}
		\item Angenommen, $B$ ist endlich. Dann besteht $\cA$ nach unserem zweiten Lemma höchstens aus jeder möglichen Kombination aus Atomen, wovon es endlich viele gibt, also ist auch $\cA$ endlich.
		\item Angenommen, $B$ ist abzählbar. Dann können wir $B = \{B_i\}_{i \in \bN}$ schreiben. Definiere nun $B = \{\bigcup_{i \in I} B_i : I \subseteq \bN\}$. Diese Menge ist in Bijektion mit $\cP(\bN)$.
	\end{enumerate}
\end{proof}
\section{Maße}
\begin{definition}
	Sei $\cA \subseteq \cP(X)$ eine $\sigma$-Algebra. Eine nichtnegative Funktion $\mu : \cA \to [0, \infty]$ heißt \tbf{Maß}, falls:
	\begin{enumerate}
		\item $\mu(\emptyset) = 0$
		\item Für beliebige paarweise disjunkte $A_i \in \cA_i, i \in \bN$ gilt:
		\begin{align*}
			\mu\left(\bigcup_{i \in \bN} A_i\right) = \sum_{i \in \bN} \mu(A_i)
		\end{align*}
	\end{enumerate}
	Das Tripel $(X, \cA, \mu)$ heißt dann \tbf{Maßraum}.
\end{definition}
\begin{definition}
	Sei $(X, \cA, \mu)$ ein Maßraum. $\mu$ heißt \tbf{endlich}, falls $\mu(X) < \infty$, und \tbf{$\sigma$-endlich}, falls es eine Folge $(X_i) \subseteq \cA$ mit $\mu(X_i) < \infty$ gibt, sodass $X = \bigcup_{i \in \bN} X_i$.
\end{definition}
\begin{definition}
	Sei $(X, \cA, \mu)$ ein Maßraum. Ist $\mu(X) = 1$, so wird $\mu$ \tbf{Wahrscheinlichkeitsmaß} genannt.
\end{definition}
\begin{definition}
	Sei $X$ beliebig, $\cA = \cP(X)$, $x \in X$ beliebig. Das \tbf{Diracmaß} ist das Maß:
	\begin{align*}
		\delta_x(A) = \begin{cases}
			0 & x \notin A\\
			1 & x \in A\\
		\end{cases}
	\end{align*}
\end{definition}
\begin{definition}
	Auf einer beliebigen Menge $X$ definieren wir das \tbf{Zählmaß} $\text{card}(A) : \cP(X) \to [0, \infty]$ durch:
	\begin{align*}
		\text{card}(A) = 
		\begin{cases}
			\abs{A} & \text{$A$ endlich}\\
			\infty & \text{$A$ unendlich}
		\end{cases}
	\end{align*}
\end{definition}
\begin{definition}
	\tbf{\ul{Einschränkungen von Maßen:}} Sei $(X, A, \mu)$ ein Maßraum, $M \in \cA$ und $A|_M \subseteq \cP(M)$ die von $\cA$ auf $M$ induzierte $\sigma$-Algebra. Wir können ein Maß $\mu|_M$ auf $\cA|_M$ definieren, da es für alle $B \in \cA|_M$ ein $A \in \cA$ mit $B = A \cap M$ gibt. Wir setzen also:
	\begin{align*}
		\mu|_M(B) = \mu(A \cap M)
	\end{align*}
\end{definition}
\begin{definition}
	Sei $\cA \subseteq \cP(X)$ eine $\sigma$-Algebra. Das \tbf{triviale Maß} ist gegeben durch:
	\begin{align*}
		\forall A \in \cA : \mu(A) = 0
	\end{align*}
\end{definition}
\begin{theorem}
	\theoremname{Stetigkeitseigenschaften:} Sei $(X, \cA, \mu)$ ein Maßraum. Dann gelten für $A_i \subseteq \cA, i \in \bN$ folgende Aussagen:
	\begin{enumerate}
		\item Ist $A_i$ monoton wachsend, also $A_1 \subseteq A_2 \subseteq \hdots$, so folgt
		\begin{align*}
			\mu\left(\bigcup_{i \in \bN} A_i\right) = \lim_{i \to \infty} \mu(A_i)
		\end{align*}
		\item Ist $\mu(A_1) <\infty$ und $A_i$ monoton fallend, also $A_1 \supseteq A_2 \supseteq \hdots$, dann folgt:
		\begin{align*}
			\mu\left(\bigcap_{i \in \bN} A_i\right) = \lim_{i \to \infty} \mu(A_i)
		\end{align*}
		\item $\mu$ ist \tbf{$\sigma$-Subadditiv}:
		\begin{align*}
			\mu\left(\bigcup_{i \in \bN} A_i\right) \leq \sum_{i \in \bN} \mu(A_i)
		\end{align*}
	\end{enumerate}
\end{theorem}
\begin{proof}
	\phantom{}
\begin{enumerate}
	\item Wir definieren $\widetilde A_1 := A_1$ und $\widetilde A_k := A_j \setminus A_{k-1}$. So sind die $\widetilde A_k$ paarweise disjunkt. Es gilt:
	\begin{align*}
		\mu\left(\bigcup A_i \right) &= \mu\left(\bigcup \widetilde A_i\right)\\
		 &= \sum_{i \in \bN} \mu(\widetilde A_i)\\
		 &= \lim_{n \to \infty} \sum_{i = 1}^n \mu(\widetilde A_i)\\
		 &= \lim_{n \to \infty} \mu\left(\bigcup_{i = 1}^n \widetilde A_i\right)\\
		 &= \lim_{n \to \infty} \mu(A_n)
	\end{align*}
	\item Wir definieren $\widetilde A_k' := A_1 \setminus A_k$. Es gilt:
	\begin{align*}
		\mu(A_1) &= \mu(A_1 \cap A_k) + \mu(A_1 \setminus A_k)\\
				 &= \mu(A_k) + \mu(A_k')
	\end{align*}
	Es folgt
	\begin{align*}
	\mu(A_1) - \mu(A_k) = \mu(A_k')
	\end{align*}
	Also auch:
	\begin{align*}
		\mu(A_1) - \lim_{k \to \infty} \mu(A_k) &= \lim_{k \to \infty} \mu(A_k')\\
		&= \mu\left(\bigcup_{k \in \bN} A_k'\right)\\
		&= \mu\left(A_1 \setminus \bigcap_{k \in \bN} A_k\right)\\
		&= \mu\left(A_1\right) - \mu\left(\bigcap_{k \in \bN} A_k\right)
	\end{align*}
	\item
\end{enumerate}
\end{proof}
\begin{proposition}
	Das Zählmaß führt zu Gegenbeispielen zu $2.$ bei unendlichem $\mu(A_1)$.
\end{proposition}
\begin{definition}
	Sei $(X, \cA, \mu)$ ein Maßraum. Jede Menge $A \in \cA$ mit $\mu(A) = 0$ heißt \tbf{Nullmenge}. Wir bezeichnen das System aller Nullmengen eines Maßes mit $\cN(\mu)$.
	$\mu$ heißt \tbf{vollständig}, wenn jede Teilmenge einer Nullmenge ebenfalls in der $\sigma$-Algebra enthalten ist und ebenfalls Maß $0$ hat.
\end{definition}
\begin{proposition}
	Das triviale Maß ist auf jeder $\sigma$-Algebra, welche nicht die Potenzmenge ist, nicht vollständig.
\end{proposition}
\begin{definition}
	Sei $(X, \cA, \mu)$ ein Maßraum und $\cT_\mu$ die Mengen aller Teilmengen von Nullmengen in $\mu$. Wir definieren den \tbf{Abschluss} von $\cA$ als:
	\begin{align*}
		\overline{\cA_\mu} := \{A \cup N : A \in \cA, N \in \cT_\mu\}
	\end{align*}
	$\mu$ ist offensichtlich genau dann vollständig, wenn $\cT_\mu \subseteq \cA$. Wir definieren für $A \in \cA$ und $N \in \cT_\mu$ nun den Abschluss des Maßes als:
	\begin{align*}
		\overline{\mu}(A \cup N) := \mu(A)
	\end{align*}
\end{definition}
\begin{theorem}
	\theoremname{Vervollständigung:} Sei $(X, \cA, \mu)$ ein Maßraum. Dann ist $\overline{\cA_\mu}$ eine $\sigma$-Algebra und $\overline{\mu}$ ein vollständiges Maß, welches auf $\cA$ mit $\mu$ übereinstimmt.
\end{theorem}
\begin{proof}
	\phantom{}
	\begin{enumerate}
		\item $\cT_\mu$ ist unter abzählbaren Vereinigungen abgeschlossen, ebenso $\cA$. Also ist auch $\overline{\cA_\mu}$ unter abzählbaren Vereinigungen abgeschlossen.
		\newpar
		Sei $E \in \overline{\cA_\mu}$. Dann existieren ein $A \in \cA$, $N \in \cT_\mu$ und ein $B \in \cN(\mu)$, sodass $E = A \cup N$.
		\newpar
		Es gilt $B \setminus N \in \cT_\mu$. Nun gilt:
		\begin{align*}
			X \setminus E = (X \setminus (A \cup B)) \cup (B \setminus N)
		\end{align*}
		Da $(X \setminus (A \cup B)) \in \cA$ und $B \setminus N \in \cT_\mu$ gilt also $X \setminus E \in \overline{\cA_\mu}$. Also ist $\overline{\cA_\mu}$ eine $\sigma$-Algebra. \\\hfill\qed
		\item coming soon :)
	\end{enumerate}
\end{proof}
\begin{theorem}
	Sei $(X, \cA, \mu)$ ein Maßraum und sei $(X, \ol{\cA_\mu}, \ol{\mu})$ dessen Vervollständigung. Sei $(X, \cB, \nu)$ ein weiterer vollständiger Maßraum mit $\cA \subseteq \cB$ und $\forall A \in \cA: \mu(A) = \nu(A)$. Dann ist $\ol{\cA_\mu} \subseteq \cB$ und $\forall A \in \ol{\cA_\mu} : \nu(A) = \ol{\mu}(A)$.
\end{theorem}
\begin{proof}
	Aus $\cA \subseteq \cB$ und $\mu = \nu$ auf $\cA$ folgt direkt $\cN(\mu) \subseteq \cN(\nu)$, also auch $\cT_\mu \subseteq \cT_\nu$. Da $\nu$ vollständig ist, ist $\cT_\mu \subseteq \cT_\nu \subseteq \cB$, also auch $\ol{\cA_\mu} \subseteq \cB$.
	\newpar
	Da $\ol{\mu}$ auf $\ol{\cA_\mu}$ vollständig durch $\mu$ auf $\cA$ bestimmt ist, und $\mu = \nu$ auf $\cA$, folgt außerdem $\ol{\mu} = \nu$ auf $\ol{\cA_\mu}$.
\end{proof}
\section{Messbare Funktionen}
\begin{definition}
	Seien $(X, \cA)$ und $(Y, \cC)$ messbare Räume. Eine Abbildung $f : X \to Y$ heißt $\cA-\cC$-Messbar, falls
	\begin{align*}
		f^{-1}(\cC) \subseteq \cA,
	\end{align*} 
	also
	\begin{align*}
		\forall c \in \cC : f^{-1}(c) \in \cA.
	\end{align*}
\end{definition}
\begin{proposition}
	\phantom{}
	\begin{enumerate}
		\item Konstante Abbildungen sind messbar.
		\item Sei $\bR$ mit der Borel-$\sigma$-Algebra versehen. Dann ist für jeden Messbaren Raum $(X, \cA)$ und jede Menge $E \in \cA$ die Indikatorfunktion $\chi_E$ messbar.
		\item Die Komposition messbarer Funktionen ist messbar.
	\end{enumerate}
\end{proposition}
\begin{proposition}
	Das Finden nicht Borel-messbarer Funktionen ist ähnlich schwierig wie das Finden von Mengen, die nicht Borel sind. Alle praxisrelevanten Funktionen $\bR^n \to \bR^k$ sind Borel-messbar.
\end{proposition}
\begin{lemma}
	Seien $(X, \cA)$, $(Y, \cC)$ messbare Räume. Sei $f : X \to Y$ eine Abbildung. Für beliebige Systeme $\cE \subseteq \cC$ gilt:
	\begin{align*}
		f^{-1}(\sigma(\cE)) = \sigma({f^{-1}(\cE)})
	\end{align*}
	Die Urbildbildung kommutiert also mit der Erzeugung von $\sigma$-Algebren.
\end{lemma}
\begin{proof}
	\phantom{}
	\begin{description}
		\item[$\supseteq$ :] $f^{-1}(\sigma(\cE))$ ist wieder eine $\sigma$-Algebra. Es gilt außerdem $f^{-1}(\cE) \subseteq f^{-1}(\sigma(\cE))$. Da die erzeugte $\sigma$-Algebra die kleinstmögliche ist gilt also $\sigma(f^{-1}(\cE)) \subseteq f^{-1}(\sigma(\cE))$.
		\item[$\subseteq$ :] 
		\begin{align*}
			\cF := \{F \subseteq Y \mid f^{-1}(F) \in \sigma(f^{-1}(\cE))\}
		\end{align*}
		ist wieder eine $\sigma$-Algebra.
		Es gilt $\cE \subseteq \cF$, also $\sigma(\cE) \subseteq \cF$, also $f^{-1}(\sigma(\cE)) \subseteq \sigma(f^{-1}(\cE))$.
	\end{description}
\end{proof}
\begin{corollary}
	Seien $(X, \cA)$, $(Y, \cC)$ messbare Räume und sei $C = \sigma(\cE)$. Jede Abbildung $f : X \to Y$ mit $f^{-1}(\cE) \subseteq \cA$ ist $\cA$ - $\cC$-messbar.
\end{corollary}
\begin{proof}
	\begin{align*}
		f^{-1}(\cC) = f^{-1}(\sigma(\cE)) )  = \sigma(f^{-1}(\cE)) \subseteq \sigma(\cA) \subseteq \cA
	\end{align*}
\end{proof}
\begin{corollary}
	Stetige Funktionen $f : \bR^n \to \bR^k$ sind $\cB^n$ - $\cB^k$-messbar (Borel-messbar).
\end{corollary}
\begin{corollary}
	Sei $X \neq \emptyset$, $(Y, \cC)$ ein messbarer Raum und $f : X \to Y$. Sei $f^{-1}(\cC)$ eine $\sigma$-Algebra. Dann ist $f$ $f^{-1}(\cC) - \cC$-messbar. $f^{-1}(\cC)$ ist außerdem die kleinste $\sigma$-Algebra, die $f$ messbar macht.y
\end{corollary}
\begin{corollary}
	Analog für Familien $f_i$.
\end{corollary}
\begin{definition}
	Wir definieren $0 \cdot \pm \infty = 0$.
\end{definition}
\noindent Die Multiplikation ist damit in den vier Punkten $(0, \pm \infty)$ und $(\pm \infty, 0)$ unstetig. Diese Erweiterung wird sich aber später für die Integration als sinnvoll erweisen - die Fläche der Nullfunktion über das unendliche Intervall $\bR$ soll schließlich $0$ sein.
\begin{definition}
	Sei $(X, \cA)$ ein messbarer Raum und $D \in \cA$. eine Funktion $f : D \to \ol{\bR}$ heißt \tbf{numerische Funktion}.
\end{definition}
\begin{lemma}
	Sei $(X, \cA)$ ein messbarer Raum, $D \in \cA$ und $f : D \to \ol{\bR}$. Dann ist äquivalent:
	\begin{enumerate}
		\item $f$ ist $\cA$-messbar
		\item Für jede offene Menge $U \subseteq \bR$ ist $f^{-1}(U) \in \cA$, $f^{-1}(\infty) \in A$ und $f^{-1}(- \infty) \in A$.
		\item $\forall s \in \bR : \{f(x) \leq s\} \in A$
		\item $\forall s \in \bR : \{f(x) < s\} \in A$
		\item $\forall s \in \bR : \{f(x) \geq s\} \in A$
		\item $\forall s \in \bR : \{f(x) > s\} \in A$
	\end{enumerate}
\end{lemma}
\begin{proof}
	1. und 2. sind durch unsere Korrolare äquivalent. Aus 2. folgt 6., da $\{f > s\} = f^{-1}(s, \infty)  \cup f^{-1}(\infty)$. 3.-6. sind äquivalent, da
	\begin{align*}
		\{f(x) \leq s\} &= \bigcap_{k \in \bN} \{f(x) \leq s + \frac{1}{k}\}\\
		\{f(x) > s\} &= D \setminus \{f(x) \leq s\}\\
 	\end{align*}
 	etc. Betrachte nun $f^{-1}((a,b)) = \{f(x) > a\} \cap \{f(x) < b\}\} \in \cA$. Wir behaupten nun, dass jede offene Menge in $\ol{\bR}$ durch abzählbar viele Intervalle generiert ist. Dadurch folgt dann aus 3.-6. auch 2.
\end{proof}
\begin{proposition}
	Es reicht auch, die gegebenen Eigenschaften für $\bQ$ zu fordern.
\end{proposition}
\begin{lemma}
	Sei $(X, \cA)$ ein messbarer Raum, $D \in \cA$, $f,g : D \to \ol{\bR}$ $\cA$-messbar. Dann sind die Mengen $\{f < g\}$ und $\{f \leq g\}$ messbar.
\end{lemma}
\begin{proof}
	\begin{align*}
	 	\{f < g\} &= \bigcup_{q \in \bQ} (\{f < q\} \cap \{g > q\})\\
	 	\{f \leq g\} &= D \setminus \{g < f\}
	\end{align*}
\end{proof}
\begin{definition}
	Wir definieren in den folgenden Sätzen die Grenzwerte von Funktionenfolgen \tbf{punktweise}:
	\begin{align*}
		(\liminf_{k \to \infty} f_k)(x) = \liminf_{k \to \infty} f_k(x)
	\end{align*}
\end{definition}
\begin{theorem}
	Folgende Funktionen von messbaren $f_k$ sind messbar:
	\begin{enumerate}
		\item $\inf f_k$
		\item $\sup f_k$
		\item $\liminf f_k$
		\item $\limsup f_k$
	\end{enumerate}
\end{theorem}
\begin{proof}
	Sei $s \in \bR$. Dann gilt:
	\begin{align*}
		\{(\inf f_k) \geq s\} &= \bigcap_{k \in \bN} \{f_k \geq s\}\\
		\{(\sup f_k) \leq s\} &= \bigcap_{k \in \bN} \{f_k \leq s\}\\
	\end{align*}
	Also sind $\inf f_k$ und $\sup f_k$ messbar.
	\newpar
	Es gilt außerdem:
	\begin{align*}
		\liminf f_k &= \sup_{k \in \bN}(\inf_{l \geq k} f_l)\\
		\limsup f_k &= \inf_{k \in \bN}(\sup_{l \geq k} f_l)\\
	\end{align*}
	Also sind $\liminf f_k$ und $\limsup f_k$ ebenfalls messbar.
\end{proof}
\begin{definition}
	Wir definieren die Positiv- und Negativanteile einer Funktion als:
	\begin{align*}
		f^+ := \max(f, 0) &\geq 0\\
		f^- := \max(-f, 0) &\geq 0\\
	\end{align*}
	Es gilt also $f = f^+ - f^-$ und $\abs{f} = f^+ + f^-$
\end{definition}
\begin{theorem}
	Sei $(X, \cA)$ ein messbarer Raum, $D \in \cA$, $f,g : D \to \ol{\bR}$ $\cA$-messbar, $\alpha \in \bR$. Dann sind auch folgende Funktionen auf ihren Definitionsbereichen messbar:
	\begin{enumerate}
		\item $f + g$
		\item $\alpha f$
		\item $f^+$
		\item $f^-$
		\item $\max(f,g)$
		\item $\min(f,g)$
		\item $\abs{f}$
		\item $fg$
		\item $\frac{f}{g}$
	\end{enumerate}
\end{theorem}
\noindent Mit "auf ihren Definitionsbereichen messbar" werden Definitonslücken Ausgeschlossen, z.B. $(f + g)(x)$ mit $f(x) = \infty$ und $g(x) = -\infty$
\begin{proof}
	Seien $f,g : X \to \bR$. Dann gilt:
	\begin{align*}
		\{f + g < t\} = \bigcup_{r,s \in \bQ, r + s < t} \{f < r\} \cap \{g < s\}
	\end{align*}
	Also sind $f + g$ und $-f$ $\cA$-messbar. Es gilt außerdem:
	\begin{align*}
		\{ \alpha f > t\} = \{f > \frac{t}{\alpha}\}
	\end{align*}
	Also ist auch $\alpha f$ messbar.
	\newpar
	Sei nun $\varphi \in C^0(\bR)$. Dann ist $\varphi \circ f$ $\cA$-messbar:
	\begin{align*}
		(\varphi \circ f)^{-1}(U) = f^{1}(\phi^{-1}(U)) \in \cA
	\end{align*}
	Daraus folgt nun die Messbarkeit von $f^{\pm}$:
	\begin{align*}
		\varphi(s) = \max(\pm s, 0)
	\end{align*}
	Für $\abs{f}$ gilt:
	\begin{align*}
		\abs{f} = f^+ + f^-
	\end{align*}
	Für $\max$ und $\min$ gelten folgende Formeln:
	\begin{align*}
		\max(f,g) &= \frac{1}{2}(f + g + \abs{f - g})\\
		\min(f,g) &= \frac{1}{2}(f + g - \abs{f - g})
	\end{align*}
	Es gilt $f^2 = \varphi \circ f$ mit $\phi(s) = s^2$, daraus folgt die Messbarkeit von $f^2$, also auch von:
	\begin{align*}
		fg = \frac{1}{4}((f + g)^2 - (f - g)^2)
	\end{align*}
	Schließlich ist auch $\frac{1}{g}$ messbar, da
	\begin{align*}
		\left\{\frac{1}{g} < s\right\} =
		\begin{cases}
			\frac{1}{s} < g < 0 & s < 0\\
			\{g < 0\} & s = 0\\
			\{g < 0\} \cup \{g > \frac{1}{s}\} & s > 0\\
		\end{cases}
	\end{align*}
	Für $g : X \to \ol{\bR}$ definieren wir nun:
	\begin{align*}
		f_k(x) := 
		\begin{cases}
			k & f(x) \geq k\\
			f(x) & -k < f(x) < k\\
			-k & f(x) \leq -k\\
		\end{cases}
	\end{align*}
	Diese $f_k$ sind messbar (?). Ersetzen wir nun die Funktionen $f$ und $g$ in den gewünschten Formeln durch $f_k$ und $g_k$, kovergieren die entstehenden Funktionenfolgen punktweise gegen die gewünschten Funktionen in den erweiterten reellen Zahlen. Also gilt der Satz nicht nur für $f,g : X \to \bR$, sondern auch für $f,g : X \to \ol{\bR}$.
\end{proof}
\begin{definition}
	Eine Aussage $A[x]$ ist \tbf{wahr für $\mu$-fast alle $x$}, wenn
	\begin{align*}
		\{x \in M \mid A[x]  \text{ ist falsch}\} \subseteq N \in \cN(\mu)
	\end{align*}
\end{definition}
\begin{definition}
	Sei $(X, \cA, \mu)$ ein Maßraum. Eine auf $D \in \cA$ definierte numerische Funktion $f : D \to \ol{\bR}$ heißt $\mu$-messbar auf $X$, wenn $\mu(X \setminus D) = 0$ und $f$ $\cA|_D$-messbar ist.
\end{definition}
\begin{theorem}
	Die Relation "$f = g$ $\mu$-fast überall" ist eine Äquivalenzrelation
\end{theorem}
\begin{theorem}
	Sei $D \in \cA$ und $f : D \to \ol{\bR}$ $\mu$-messbar. Dann gibt es eine $\cA$-messbare Funktion $g : X \to \ol{\bR}$ mit $f = g$ auf $D$.
\end{theorem}
\begin{corollary}
	Unsere Sätze über $\cA$-messbare Funktionen gelten auch für $\mu$-messbare Funktionen.
\end{corollary}
\begin{lemma}
	Sei $(X, \cA, \mu)$ ein vollständiger Maßraum und sei $f$ $\mu$-messbar auf $X$. Dann ist jede Funktion $\tilde{f}$ mit $f = \tilde{f}$ $\mu$-fast überall auch $\mu$-messbar.
\end{lemma}
\begin{proof}
	Wir haben $f : D \to \ol{\bR}$, $D \in \cA$, $\mu(X \setminus D) = 0$.
	\newpar
	$\tilde{F} : \tilde{D} \to \ol{\bR} \implies \exists N \in \cN(\mu) : X \setminus N \subseteq D \cap \tilde{D}$ und $\forall X \in X \setminus N : f(x) = \tilde{f}(x)$. Es folgt, dass $X - \tilde{D} \in N$. Da $\mu$ vollständig ist, folgt $\tilde{D} \in \cA$.
	\newpar
	Es gilt:
	\begin{align*}
		\{x \in \tilde{D} : \tilde{f}(x) < s\} &= \{x \in \tilde{D} \cap N \mid \tilde{f}(x) < s\} \cup \{x \in \tilde{D} \cap (X \setminus N) : \tilde{f}(x) < s\}\\
		&= \{x \in \tilde{D} \cap N \mid \tilde{f}(x) < s\} \cup \{x \in X \setminus N : \tilde{f}(x) < s\}\\
		&= \{x \in \tilde{D} \cap N \mid \tilde{f}(x) < s\}\\ &\cup (\{x \in D : \tilde{f}(x) < s\} \setminus \{x \in D \cap N : \tilde{f}(x) < s\})\\
		&= \{x \in \tilde{D} \cap N \mid \tilde{f}(x) < s\}\\ &\cup (\{x \in D : \tilde{f}(x) < s\} \setminus (\{x \in D : \tilde{f}(x) < s\} \cap N))
	\end{align*}
	Also ist $\tilde{f}$ $\mu$-messbar.
\end{proof}
\begin{theorem}
	Sei $(X, \cA, \mu)$ ein vollständiger Maßraum. Seien Funktionen $f_k, k \in \bN$ $\mu$-messbar. Falls $f_k$ punktweise $\mu$-fast-überall gegen $f$ konvergiert, so ist $f$ $\mu$-messbar.
\end{theorem}
\begin{theorem}
	\theoremname{Satz von Severini-Egorov:} Sei $(X, \cA, \mu)$ ein Maßraum, $D \in \cA$ eine Menge mit $\mu(D) < \infty$, und seien $f_k, f$ messbare, $\mu$-fast-überall endliche Funktionen auf $D$, sodass die $f_k$ fast überall gegen $f$ konvegieren. Dann existiert für alle $\epsilon \in \bR^+$ eine Menge $B \in \cA$ mit $B \subseteq D$ und
	\begin{enumerate}
		\item $\mu(D \setminus B) <  \epsilon$
		\item $f_k$ konvergiert auf $B$ gleichmäßig gegen $f$.
	\end{enumerate}
\end{theorem}
\section{Äußere Maße}
\begin{definition}
	Sei $X$ eine Menge. Wir nennen eine Funktion $\mu : \cP(X) \to \ol{\bR}_{\geq 0}$ ein \tbf{äußeres Maß auf $X$}, falls
	\begin{align*}
		A \subseteq \bigcup_{i \in \bN} A_i \implies \mu(A) \leq \sum_{i \in \bN} \mu(A_i).
	\end{align*}
\end{definition}
\noindent 
Alle bisher eingeführten Begrifflichkeiten zu Maßen und ihren Eigenschaften sind analog für äußere Maße definiert. Insbesondere ist ein äußeres Maß immer monoton und $\sigma$-subadditiv.
\begin{definition}
	Sei $\mu$ ein äußeres Maß auf $X$. Die Menge $A \subseteq X$ heißt $\mu$-messbar, falls für alle $S \subseteq X$:
	\begin{align*}
		\mu(S) \geq \mu(S \cap A) + \mu(S \setminus A)
	\end{align*}
	Das System aller $\mu$-messbaren Mengen wird mit $\cM(\mu)$ bezeichnet.
\end{definition}
\begin{example}
	Jedes Maß auf $\cP(X)$ ist ein äußeres Maß. Beispiele sind z.B. das Diracmaß oder das Zählmaß.
\end{example}
\begin{theorem}
	Sei $Q$ ein System von Teilmengen einer Menge $X$, welches die leere Menge enthält. Sei $\lambda : Q \to [0, \infty]$ eine Mengenfunktion, sodass $\lambda(\emptyset) = 0$. Sei außerdem $\mu : \cP(X) \to [0,\infty]$ für beliebige $E \subseteq X$, sodass:
	\begin{align*}
		\mu(E) = \inf \left\{\sum_{i = 1}^\infty \mu(P_i) \mid P_i \in Q, E \subseteq \bigcup_{i \in \bN} P_i \right\}
	\end{align*}
	Dann ist $\mu$ ein äußeres Maß.
\end{theorem}
\begin{theorem}
	Seien $X, Y$ Mengen und $f : X \to Y$. Für ein gegebenes äußeres Maß $\mu : \cP(X) \to [0,\infty]$ erhält man durch die Vorschrift
	\begin{align*}
		f(\mu) : \cP(Y) &\to [0,\infty]\\
		B &\mapsto \mu(f^{-1}(B))
	\end{align*}
	ein äußeres Maß auf $Y$, genannt das \tbf{Bildmaß von $\mu$ unter $f$}.
\end{theorem}
\noindent Ist $f^{-1}(B)$ $\mu$-messbar, so ist $B$ $f(\mu)$-messbar.
\begin{theorem}
	Sei $\mu : \cP(X) \to [0, \infty]$ ein äußeres Maß auf $X$. Für $M \subseteq X$ erhält man durch
	\begin{align*}
		\mu_{LM} : \cP(X) &\to [0, \infty]\\
				        A & \mapsto \mu(M \cap A)\\
	\end{align*}
	Ein äußeres Maß auf $X$, welches wir die Einschrnkung von $\mu$ auf $M$ nennen. Ist $A$ $\mu$-messbar, so ist $A$ auch $\mu_{LM}$-messbar.
\end{theorem}
\begin{theorem}
	Sei $\mu$ ein äußeres Maß auf einer Menge $X$. Dann gilt:
	\begin{enumerate}
		\item Jede $\mu$-Nullmenge $N$ ist $\mu$-messbar
		\item Für jede Familie $N_k$ von Nullmengen ist auch $N := \bigcup_{k \in \bN} N_k$ $\mu$-messbar.
	\end{enumerate} 
\end{theorem}
\begin{example}
	Wir können auf jeder Menge $X$ durch
	\begin{align*}
		\beta(A) = 
		\begin{cases}
			0 & A = \emptyset\\
			1 & \text{sonst}
		\end{cases}
	\end{align*}
	ein äußeres Maß definieren. Dann sind nur $\emptyset$ und $X$ $\beta$-messbar.
\end{example}
\begin{lemma}
	Seien $A_i \in \cM(\mu)$, $i = 1, \hdots, k$ paarweise disjunkt. Dann gilt für alle $S \subseteq X$
	\begin{align*}
		\mu\left(S \cap \bigcup_{i = 1}^k A_i\right) = \sum_{i = 1}^k \mu (S \cap A_i)
	\end{align*}
\end{lemma}
\begin{theorem}
	Sei $\mu : \cP(X) \to \barR_{\geq 0}$ ein äußeres Maß. Dann ist das System $\cM(\mu)$ eine $\sigma$-Algebra und $\mu$ ist ein vollständiges Maß auf $\cM(\mu)$.
\end{theorem}
\begin{proof}
	Zu zeigen ist:
	\begin{description}
		\item[1. \ul{Endliche Durchschnitte und Vereinigungen sind messbar:}]
		Es gilt $X \in \cM$, denn für jede Menge $S \subseteq X$ ist
		\begin{align*}
			\mu(S \cap X) + \mu (S \setminus X) = \mu(S) + \mu(\emptyset) = \mu(S)
		\end{align*}
		Mit $A \in \cM$ folgt auch $X \setminus A \in \cM$, denn für $S \subseteq X$ gilt
		\begin{align*}
			\mu(S \cap (X \setminus A)) + \mu(S \setminus (X \setminus A)) = \mu(S \setminus A) + \mu (S \cap A) = \mu(S)
		\end{align*}
		Als nächstes zeigen wir, dass $A \cap B \in \cM$ für $A, B \in \cM$. Für alle $S \subseteq X$ gilt
		\begin{align*}
			\mu(S) &= \mu(S \cap A) + \mu(S \setminus A)\\
			\mu(S \cap A) &= \mu(S \cap A \cap B) + \mu((S \cap A) \setminus B)
		\end{align*}
		Durch Wahl von $S \setminus A \cap B$ als Teilmenge und Messbarkeit von $A$ erhält man:
		\begin{align*}
			\mu(S \setminus (A \cap B)) &= \mu((S \setminus (A \cap B)) \cap A) + \mu((S \setminus (A \cap B)) \setminus A)\\
			&= \mu((S \cap A) \setminus B) + \mu(S \setminus A)
		\end{align*}
		Aus diesen drei Identitäten folgt sofort:
		\begin{align*}
			\mu(S) = \mu(S \cap (A \cap B)) + \mu(S \setminus (A \cap B))
		\end{align*}
		Es gilt also:
		\begin{align*}
			A \cup B = X \setminus ((X \setminus A) \cap (X \setminus B)) \in \cM
		\end{align*}
		und
		\begin{align*}
			A \setminus B = A \cap (X \setminus B) \in \cM
		\end{align*}
		Also ist $\cM$ unter endlichen Vereinigungen und Durchscnitten abgeschlossen.
		\item[2. $\mu$ ist $\sigma$-additiv auf $\cM$]
		Left as an exercise :)
		\item[3. $\cM$ ist abgeschlossen unter zählbaren Vereinigungen]
		Left as an exercise :)
	\end{description}
\end{proof}
\begin{corollary}
	Sei $\mu$ ein äußeres Maß. Seien $A_i$ $\mu$-messbar. Dann gilt:
	\begin{enumerate}
		\item Ist $A_1 \subseteq A_2 \subseteq \hdots$, so gilt 
		\begin{align*}
			\displaystyle \mu\left(\bigcup_{i = 1}^\infty A_i\right) = \lim_{i \to \infty} \mu(A_i)
		\end{align*}
		\item Ist $A_1 \supseteq A_2 \supseteq \hdots$, so gilt
		\begin{align*}
			\displaystyle \mu\left(\bigcap_{i = 1}^\infty A_i\right) = \lim_{i \to \infty} \mu(A_i)
		\end{align*}
	\end{enumerate}
\end{corollary}
\section{Der Fortsetzungssatz von Carathéodory}
\begin{definition}
	Ein Mengensystem $A \subseteq \cP(X)$ heißt $\cup$-stabil, falls 
	\begin{align*}
		\forall A, B \in \cA : A \cup B \in \cA.
	\end{align*}
	analog heißt $\cA$ $\cap$-stabil, falls
	\begin{align*}
		\forall A, B \in \cA : A \cap B \in \cA.
	\end{align*}
	Per Induktion folgt direkt, dass auch Ergebnisse endlicher Wiederholungen der Operationen in $\cA$ enthalten sein müssen.
\end{definition}
%
\begin{definition}
	Sei $\cR \subseteq \cP(X)$ ein Mengenring. Eine Funktion $\lambda : \cR \to \barR_{\geq 0}$ heißt \tbf{Prämaß} auf $\cR$, wenn:
	\begin{enumerate}
		\item $\lambda(\emptyset) = 0$
		\item Für paarweise disjunkte Mengen $A_i \in \cR$ mit $\displaystyle \bigcup_{i = 1}^\infty A_i \in \cR$ gilt $\sigma$-Additivität, also:
		\begin{align*}
			\lambda\left(\bigcup_{i = 1}^\infty A_i \right) = \sum_{i = 1}^\infty \lambda(A_i)
		\end{align*}
	\end{enumerate}
\end{definition}
\begin{definition}
	Sei $\lambda$ ein Prämaß auf dem Ring $\cR \subseteq \cP(X)$. Ein äußeres Maß $\mu$ auf $\cP(X)$, bzw. ein Maß $\mu$ auf $\cA \subseteq \cP(X)$, heißt Fortsetzung von $\lambda$, falls
	\begin{enumerate}
		\item $\mu|_{\cR} = \lambda$
		\item $\cR \subseteq \cM(\mu)$ (bzw. $\cR \subseteq \cA$)
	\end{enumerate}
\end{definition}
\begin{theorem}
	\theoremname{Carathéodory-Fortsetzung:} Sei $\lambda : \cR \to \barR_{\geq 0}$ ein Prämaß auf dem Ring $\cR$. Sei $\mu : \cP(X) \to \barR_{\geq 0}$ das äußere Maß
	\begin{align*}
		\mu(E) := \inf \left\{\sum_{i = 1}^\infty \mu(A_i) \mid A_i \in \cR, E \subseteq \bigcup_{i = 1}^\infty A_i\right\}
	\end{align*}
	Dann ist $\mu$ eine Fortsetzung von $\lambda$, welches wir als das \tbf{von $\lambda$ induzierte äußere Maß} oder als die \tbf{Carathéodory-Fortsetzung von $\lambda$} bezeichnen.
	\begin{proof}
		\phantom{}
		\begin{description}
			\item[\ul{1: $\forall A \in \cR : \mu(A) = \lambda(A)$.}]
			Es gilt $\mu(A) \leq \lambda(A)$, da wir $A_1 = A$ und $A_i = \emptyset$ für $i \geq 2$ wählen können.
			\newpar
			Für $\lambda(A) \leq \mu(A)$ reicht zu zeigen, dass:
			\begin{align*}
				A \subseteq \bigcup_{i = 1}^\infty A_i \wedge A_i \in \cR \implies \lambda(A) \leq \sum_{i = 1}^\infty \lambda(A_i).
			\end{align*}
			Wir betrachten hierfür die disjunkten Mengen
			\begin{align*}
				B_i = \left(A_i \setminus \bigcup_{j = 1}^{i -1} A_j\right) \cap A \in \cR.
			\end{align*}
			Für diese gilt:
			\begin{align*}
				\lambda(A) = \lambda\left(\bigcup_{i = 1}^\infty B_i\right) = \sum_{i = 1}^\infty \lambda(B_i) \leq \sum_{i = 1}^\infty \lambda(A_i).
			\end{align*}
			\item[\ul{2: Jedes $A \in \cR$ ist $\mu$-messbar.}] Sei $A \in \cR$ und $S \subseteq X$ beliebig mit $\mu(S) < \infty$. Zu $\epsilon \in \bR^+$ wähle $A_i \in \cR$, sodass
			\begin{align*}
				S \subseteq \bigcup_{i = 1}^\infty A_i
			\end{align*}
			und
			\begin{align*}
				\sum_{i = 1}^\infty \lambda(A_i) \leq \mu(S) + \epsilon
			\end{align*}
			So gilt
			\begin{align*}
				S \cap A \subseteq \bigcup_{i = 1}^\infty (A_i \cap A)
			\end{align*}
			sowie 
			\begin{align*}
				S \setminus A \subseteq \bigcup_{i = 1}^\infty (A_i \setminus A).
			\end{align*}
			Aus der Definition von $\mu$ folgt
			\begin{align*}
				\mu(S \cap A) + \mu(S \setminus A) &\leq \sum_{i = 1}^\infty \lambda(A_i \cap A) + \sum_{i = 1}^\infty \lambda(A_i \setminus A)\\
				&= \sum_{i = 1}^\infty \lambda(A_i)\\
				&\leq \mu(S) + \epsilon
			\end{align*}
			Für $\epsilon \to 0$ folgt, dass $A$ $\mu$-messbar ist.
		\end{description}
	\end{proof}
\end{theorem}
\noindent Die Carathéodory-Fortsetzung $\mu$ ist ein vollständiges Maß auf der $\sigma$-Algebra der Messbaren Mengen $\cM(\mu)$, die die durch den Ring $\cR$ generierte $\sigma$-Algebra $\sigma(\cR)$ enthält.
\newpar
Wir wollen als nächstes Zeigen, dass die Carathéodory-Fortsetzung eindeutig ist.
\begin{lemma}
	\theoremname{Maximalität der Carathéodory-Fortsetzung:} Sei $\mu$ die Carathéodory-Fortsetzung des Prämaßes $\lambda : \cR \to \barR_{\geq 0}$ auf dem Ring $\cR$ über $X$. Sei $\tilde\mu$ ein Maß auf $\sigma(\cR)$ mit $\tilde\mu = \lambda$ auf $\cR$. Dann gilt \begin{align*}
		\forall E \in \sigma(\cR) : \tilde\mu(E) \leq \mu(E)
	\end{align*}
\end{lemma}
\begin{proof}
	Da Maße $\sigma$-subadditiv sind, gilt für alle $E \in \sigma(\cR)$ die Implikation
	\begin{align*}
		E \subseteq \bigcup_{i = 1}^\infty P_i \wedge P_i \in \cR \implies \tilde\mu(E) \leq \sum_{i = 1}^\infty \tilde\mu(P_i) = \sum_{i = 1}^\infty \lambda(P_i)
	\end{align*}
	Die Bildung des Infimums über alle solchen Überdeckungen liefert die Carathéodory-Fortsetzung.
\end{proof}

\begin{theorem}
	\theoremname{Hopf-Fortsetzung:} Sei $\lambda : \cR \to \barR_{\geq 0}$ ein Prämaß auf dem Mengenring $\cR \subseteq \cP(x)$. Dann gibt es ein Maß $\mu$ auf $\sigma(\cR)$ mt $\mu = \lambda$ auf $\cR$. Diese Fortsetzung ist eindeutig, falls $\lambda$ $\sigma$-endlich ist.
\end{theorem}
\begin{proof}
	Die Existenz von $\mu$ folgt aus der Carathéodory-Fortsetzung und daraus, dass jedes äußere Maß ein Maß bildet.
	\newpar
	Sei $\tilde\mu$ ein Maß auf $\sigma(\cR)$, sodass $\tilde\mu = \lambda$ auf $\cR$. Sei $A_i \in \cR$ und $\bigcup A_i = A \in \sigma(\cR)$.
	\newpar
	Dann ist
	\begin{align*}
		\tilde\mu(A) = \lim_{n \to \infty} \tilde\mu(\bigcup A_i) = \lim_{n \to \infty} \mu(\bigcup A_i) = \mu(A)
	\end{align*}
	Sei $E \in \sigma(\cR)$ mit $\mu(E) < \infty$. Sei $\epsilon \in \bR_{> 0}$. Dann existiert eine Überdeckung $A = \bigcup A_i \supseteq E$, sodass $\mu(A) \leq \mu(E) + \epsilon$. Es folgt $\mu(A \setminus E) < \epsilon$, also
	\begin{align*}
		\mu(E) + \epsilon &\geq \mu(A) = \mu(A \cap E) + \mu(A \setminus E) =  \mu(E) + \mu(A \setminus E)\\
		\implies \epsilon &\geq \mu(A \setminus E)\\
		\mu(E) &\leq \mu(A) = \tilde\mu(A) = \tilde\mu(E) + \tilde\mu(A \setminus E)\\
		&\leq \tilde\mu(E) + \mu(A \setminus E) \leq \tilde\mu(E) + \epsilon
	\end{align*}
	Für $\epsilon \to 0$ folgt $\tilde\mu(E) \leq \mu(E)$.
	\newpar
	Sei $\lambda$ $\sigma$-endlich. Dann existieren paarweise disjunkte $X_n \in \cR$, die endliches $\lambda$ haben, somit auch endliches $\mu$. Sei $X = \bigcup X_n$ und $E \in \cR$. Dann gilt:
	\begin{align*}
		\mu(E) = \sum \mu(E \cap X_n) = \sum \tilde\mu(E \cap X_n) = \tilde\mu(E).
	\end{align*}
\end{proof}
\begin{definition}
	Ein Maß $\mu$ heißt \tbf{regulär}, falls:
	\begin{align*}
		\forall M \subseteq X : \exists D \supseteq M, D \in \cM(\mu) : \mu(M) = \mu(D)
	\end{align*}
\end{definition}
\begin{theorem}
	Die Carathéodory-Fortsetzung ist regulär.
\end{theorem}
\begin{theorem}
	Sei $\mu$ die Carathéodory-Fortsetzung des Prämaßes $\mu : \cR \to \barR_{\geq 0}$ auf dem Mengenring $\cR$ über $X$. Dann gibt es zu jeder Menge $D \subseteq X$ eine Menge $E \in \sigma(\cR)$ mit $E \supseteq D$ und $\mu(D) = \mu(E)$. Insbesondere ist $\mu$ ein äußeres Maß.
\end{theorem}
\begin{theorem}
	\theoremname{Eindeutigkeit der Maßfortsetzung:} Sei $\lambda$ ein $\sigma$-endliches Prämaß auf einem Mengenring $\cR$ über $X$, und sei $\mu : \cP(X) \to \barR_{\geq 0}$ die Carathéodory-Fortsetzung von $\lambda$. Dann ist $\mu|_{\cM(\mu)}$ die Vervollständigung vom Maß $\mu|_{\sigma(\cR)}$ und $\cM(\mu)$ ist die vervollständigte $\sigma$-Algebra $\overline{\sigma(\cR)}_{\mu|_{\sigma(\cR)}}$ von $\sigma(\cR)$ gemäß $\mu|_{\sigma(\cR)}$. Insbesondere gibt es genau eine Fortsetzung von $\lambda : \cR \to \barR_{\geq 0}$ zu einem vollständigen Maß auf $\cM(\mu)$.
\end{theorem}
\begin{corollary}
	\theoremname{Charakterisierung von $\cM(\mu)$:}
	Sei $\lambda : \cR \to \barR_{\geq 0}$ ein $\sigma$-endliches Prämaß auf dem Mengenring $\cR \subseteq \cP(X)$ mit Charathéodory-Fortsetzung $\mu$. Eine Menge $D \subset X$ ist genau dann $\mu$-messbar, wenn eine der folgenden Bedingungen gilt:
	\begin{enumerate}
		\item Es gibt ein $E \in \sigma(\cR)$ mit $E \supset D$ und $\mu(E \setminus D) = 0$.
		\item Es gibt ein $C \in \sigma(\cR)$ mit $C \subset D$ und $\mu(D \setminus C) = 0$ 
	\end{enumerate}
\end{corollary}
\noindent Sei $\mu$ ein Äußeres Maß. Wir wissen, dass wir $\mu$ auf seine messbaren Mengen einschränken, um ein vollständiges Maß $\lambda$ zu erhalten. Umgekehrt können wir mit einem Maß $\lambda$ auf $\cA$ anfangen und durch Carathéodory eine Fortsetzung $\lambda^C$ erhalten, welche ein reguläres äußeres Maß ist.
\begin{theorem}
	Die durch Einschränkung bzw. Fortsetzung gegebenen Abbildungen zwischen den $\sigma$-endlichen, regulären Abbildungen zwischen den $\sigma$-endlichen regulären äußeren Maßen und den $\sigma$-endlichen vollständigen Maßen auf $X$ sind zueinander invers und somit insbesondere bijektiv.
\end{theorem}
\begin{proof}
	\begin{enumerate}
		\item Sei $\lambda$ ein $\sigma$-endliches vollständiges Maß auf $\cA$. Da $\cA = \sigma(\cA)$ folgt $\lambda = \lambda^C|_{\cA}$. Da $\lambda$ vollständig ist folgt $\cA \ol{\cA_{\lambda}} = \cM(\lambda^C)$.
		\item Sei $\mu$ ein $\sigma$-endliches reuläres äußeres Maß. Wir zeigen $\mu = \lambda^C$ für $\lambda = \mu|_{\cM(\mu)}$. Es gilt $\cM(\mu) \subset \cM(\mu)$ nach vorherigen Sätzen. $\mu$ ist regulär nach Vorraussetzung und $\lambda^C$ ist regulär nach einem der vorherigen Sätze. Weiter stimmen beide äußere Maße auf $\cM(\mu) = \cM(\lambda^C)$ überein, sind also gleich.
	\end{enumerate}
\end{proof}
\section{Mengensysteme und Mengenfunktionen}
Wie konstruiert man aus einfachen Mengenfunktionen Prämaße?
\begin{definition}
	Ein Mengensystem $\cQ \subset \cP(X)$ heißt \tbf{Halbring} über $X$, falls:
	\begin{enumerate}
		\item $\emptyset \in \cQ$
		\item $P, Q \in \cQ \implies P \cap Q \in \cQ$
		\item $P, Q \in \cQ \implies P \setminus Q = \bigcup P_i$ mit endlich vielen paarweise disjunkten $P_i \in \cQ$.
	\end{enumerate}
\end{definition}
\begin{example}
	Sei $X$ eine beliebige Menge. Dann ist $\cQ := \{\emptyset\} \cup \{\{a\} \mid a \in X\}$ ein Halbring.
\end{example}
\begin{example}
	Eine Menge $I \subset \cR$ heißt \tbf{Intervall}, wenn es $a,b \in \cR$ mit $a \leq b$ gibt, sodass:
	\begin{align*}
		(a,b) \subset I \subset [a,b]
	\end{align*}
	Wir bezeichnen das System aller Intervalle mit $\cI$.
	Ein achsenparalleler \tbf{Quader} in $\bR^n$ ist ein kartesisches Produkt von Intervallen. Das System aller Quader in $\bR^n$ wird mit $\cQ^n$ bezeichnet.
\end{example}
\noindent Wir wollen im folgenden Zeigen, dass das System der Quader des $\bR^n$ einen Halbring bildet.
\begin{theorem}
	Das System $\cI$ der Intervalle in $\cR$ ist ein Halbring.
\end{theorem}
\begin{theorem}
	Seien $\cQ_i$ Halbringe über $X_i$. Dann ist das System der Produktmengen
	\begin{align*}
		\cQ = \{P_1 \times \hdots \times P_n \mid P_i \in \cQ_i\}
	\end{align*}
	ein Halbring über $X_1 \times \hdots \times X_n$.
\end{theorem}
\begin{corollary}
	Das System $\cQ^n$ der Quader in $\bR^n$ ist ein Halbring.
\end{corollary}
\begin{theorem}
	Sei $\cQ$ ein Halbring und $F$ das System aller endlichen Vereinigungen
	\begin{align*}
		F = \bigcup_{i = 1}^k P_i
	\end{align*}
	von Mengen $P_i \in \cQ$. Dann ist $F$ der durch $\cQ$ generierte Mengenring.
\end{theorem}
\begin{corollary}
	Sei $\cQ$ ein Halbring über $X$ und $\cF$ der von $\cQ$ erzeugte Ring. Dann ist $\sigma(\cQ) = \sigma(\cF)$
\end{corollary}
\begin{theorem}
	Sei $\cQ$ ein Halbring über $X$ und $\cF$ der von $\cQ$ erzeugte Ring. So  gibt es zu jedem $F \in \cF$ paarweise disjunkte Mengen $P_1, \hdots, P_k \in \cQ$, sodass
	\begin{align*}
		F = \bigcup_{i = 1}^k P_i.
	\end{align*}
\end{theorem}
\begin{definition}
	Sei $\cQ \in \cP(X)$ ein Halbring. Eine Funltion $\lambda : \cQ \to [0, \infty]$ heißt \tbf{Inhalt} auf $\cQ$, wenn:
	\begin{enumerate}
		\item $\lambda(\emptyset) = 0$
		\item Für paarwise disjunkte $A_i \in \cQ$ mit $\bigcup A_i \in \cQ$ gilt
		\begin{align*}
			\lambda\qty(\bigcup A_i) = \sum^n \lambda(A_i) 
		\end{align*}
	\end{enumerate}
	Ein Inhalt $\lambda$ definiert ein Prämaß auf $\cQ$, wenn $\lambda$ $\sigma$-additiv ist, also die Additivität auch für abzählbar unendliche Vereinigungen gilt.
\end{definition}
\begin{theorem}
	\theoremname{Fortsetzung auf den erzeugten Ring:} Sei $\lambda$ ein Inhalt auf einem Halbring $\cQ$. Sei $\cF$ der von $\cQ$ erzeugte Ring. Dann gibt es genau einen Inhalt $\bar\lambda$ auf $\cQ$, sodass $\forall Q \in \cQ : \lambda(Q) = \bar\lambda(Q)$
\end{theorem}
\begin{corollary}
	Ein Inhalt auf einem Halbring $\cQ$ über $X$ ist monoton und subadditiv.
\end{corollary}
\begin{example}
	Sei $\cQ^n$ der Halbring der Quader im $\bR^n$. Sei $Q = I_1 \times \hdots \times I_n \in \cQ$, sodass jedes $I_j$ die Grenzen $a_j$ und $b_j$ hat. Wir definieren das \tbf{elementargeometrische Volumen} als
	\begin{align*}
		\vol^n(Q) := \prod_{j = 1}^n (b_j - a_j)
	\end{align*}
\end{example}
\begin{theorem}
	Das elementargeometrische Volumen induziert einen Inhalt auf dem Quaderhalbring $\cQ^n$.
\end{theorem}
\begin{theorem}
	Sei $\lambda$ ein Prämaß auf dem Halbring $\cQ$ über $X$ und $\bar\lambda$ die eindeutige Erweiterung auf den von $\cQ$ erzeugten Ring $\cR$. So ist $\bar\lambda$ ein Prämaß auf $\cR$.
\end{theorem}
\begin{theorem}
	\theoremname{Caratheodory-Fortsetzung auf Halbringen:} Sei $\lambda$ ein Prämaß auf dem Halbring $\cQ$ über $X$. Sei $\mu$ das äußere Maß
	\begin{align*}
		\mu(E) = \inf \qty{\sum_{i = 1}^\infty \lambda(A_i) \mid A_i \in \cQ, E \subseteq \bigcup_{i \in \bN} A_i}
	\end{align*}
	So ist $\mu$ ein äußeres Maß. Wie im Fall für Ringe bezeichnen wir $\mu$ als die Carathéodory-Fortsetzung von $\lambda$.
\end{theorem}
\begin{theorem}
	Für einen Inhalt $\lambda$ auf einem Ring $\cR$ und Mengen $A_i \in \cR$ betrachten wir folgende Aussagen:
	\begin{enumerate}
		\item $\lambda$ ist ein Prämaß auf $\cR$
		\item Falls $A_i \subseteq A_{i+1}$ für alle $i$ und $\bigcup A_i \in \cR$ ist äquivalent:
		\begin{align*}
			\lambda\lr(\bigcup A_i) = \lim_{i \to \infty} \lambda(A_i)			
		\end{align*}
		\item Falls $A_i \supseteq A_{i+1}$ für alle $i$, mit $\lambda(A_1) < \infty$ und $\bigcap A_i \in \cR$ gilt
		\begin{align*}
			\lambda\lr(\bigcap A_i) = \lim_{i \to \infty} \lambda(A_i)
		\end{align*}
		\item Falls $A_i \supseteq A_{i+1}$ für alle $i$, mit $\lambda(A_1) < \infty$ und $\bigcap A_i = \emptyset$ gilt
		\begin{align*}
			\lim_{i \to \infty} \lambda(A_i) = 0
		\end{align*}
	\end{enumerate}
	Es gilt:
	\begin{itemize}
		\item Aussagen (i) und (ii) sind äquivalent.
		\item Aus Aussagen (i) und (ii) folgen Aussagen (iii) und (iv).
		\item Ist $\lambda$ endlich, so sind alle Aussagen äquivalent.
	\end{itemize}
\end{theorem}
\section{Dynkin-Systeme, monotone Klassen und Produkträume}
\begin{definition}
	Ein Mengensystem $\cD$ mit Grundmenge $X$ heißt \tbf{Dynkin-System}, falls:
	\begin{enumerate}
		\item $X \in \cD$
		\item $\forall A, B \in \cD, A \subseteq B : B \setminus A \in \cD$
		\item Sind $A_i \in \cD$ paarweise disjunkt, so ist $\bigcup_{i \in \bN} A_i \in \cD$.
	\end{enumerate}
\end{definition}
\begin{example}
	Jede $\sigma$-Algebra ist ein Dynkin-System.
\end{example}
\begin{example}
	Sei $X$ eine Menge mit gerader Kardinalität. Dann ist die Menge mit Teilmengen mit gerader Kardinalität ein Dynkin-System.
\end{example}
\begin{theorem}
	Ein Dynkin-System ist genau dann eine $\sigma$-Algebra, wenn es $\cap$-stabil ist.
\end{theorem}
\begin{proof}
	Zu zeigen ist nur, dass jedes $\cap$-stabile Dynkin-System $\cD$ eine $\sigma$-Algebra ist.
	\newpar
	Sei also $A,B \in \cD$ und $\cD$ $\cap$-stabil. Dann gilt
	\begin{align*}
		A \cup  B = A \cup (B \setminus (A \cap B)) \in \cD
	\end{align*}
	Da letztere Vereinigung eine disjunkte Vereinigung von in $\cD$ enthaltenen Mengen ist.
	\newpar
	Seien $A_i \in \cD$, $\hat A_0 := \emptyset$, $\hat A_i := \bigcup_{j = 1}^i A_j$. So sind
	$B_i := \hat A_i \setminus \hat A_{i + 1}$ paarweise disjunkt, also $\bigcup A_i \in \cD$.
 \end{proof}
\begin{theorem}
	Für jedes $\cap$-stabile Mengensystem $\cE$ über einer Menge $X$ gilt:
	\begin{align*}
		\cD(\cE) = \sigma(\cE)
	\end{align*}
\end{theorem}
\begin{proof}
	Da $\sigma(\cE)$ ein Dynkin-System ist, gilt $\cD(\cE) \subseteq \sigma(\cE)$. Für $\sigma(\cE) \subseteq \cD(\cE)$ reicht es zu zeigen, dass $\cD(\cE)$ eine $\sigma$-Algebra ist.
	\newpar
	Sei $D \in \cD(\cE)$. Wir definieren:
	\begin{align*}
		\cD_D := \{Q \subseteq X \mid Q \cap D \in \cD(\cE)\}
	\end{align*}
	Wir wollen zeigen, dass $\cD_D$ ein Dynkin-System ist. Es gilt:
	\begin{enumerate}
		\item $X \in \cD_D$
		\item Für $E,F \in \cD_D$, $E \subseteq F$ gilt: 
		\begin{align*}
			(F \setminus E) \cap D &= (F \cap D) \setminus (E \cap D) \in \cD(\cE)\\ 
								   &\implies F \setminus E \in \cD_D
		\end{align*}
		\item Für paarweise disjunkte $D_i \in \cD_D$ gilt analog:
		\begin{align*}
			\lr(\bigcup D_i) \cap D &= \bigcup(D_i \cap D) \in \cD(\cE)\\
			&\implies \bigcup D_i \in \cD_D	
		\end{align*}
	\end{enumerate}
	Es bleibt zu zeigen, dass für jedes $E \in \cE$ $\cD(\cE) \subset \cD_E$, und zu folgern, dass für $\forall D \in \cD(\cE) : \cD(\cE)\subset \cD_D$. Dies ist den Lesenden überlassen :)
\end{proof}
\begin{definition}
	Ein Mengensystem $\cM \subseteq \cP(X)$ heißt \tbf{monotone Klasse}, falls:
	\begin{enumerate}
		\item Aus $A_i \in \cM$ mit $A_i \subseteq A_{i + 1}$ folgt $\bigcup A_i \in \cM$
		\item Aus $A_i \in \cM$ mit $A_i \supseteq A_{i + 1}$ folgt $\bigcap A_i \in \cM$
	\end{enumerate}
\end{definition}
\begin{corollary}
	Jede $\sigma$-Algebra ist eine monotone Klasse. 
\end{corollary}
\begin{theorem}
	Jede monotone Klasse, die eine Mengenalgebra ist, ist eine $\sigma$-Algebra. Insbesondere ist für jede Mengenalgebra $\cR$ $\cM(\cR) = \sigma(\cR)$.
\end{theorem}
\begin{definition}
	Seien $(X_i, \cA_i)_{i \in I}$ messbare Räume. Die von den Projektionen $(\pi_i)_{i \in I}$ induzierte $\sigma$-Algebra $\cA$ heißt \tbf{Produkt-$\sigma$-Algebra} auf $\prod_{i \in \cI} X_i$.
	\newpar
	Wir schreiben $\cA := \bigotimes_{i \in I} \cA_i$. Der dazugehörige messbare Raum heißt das Produkt der messbaren Räume.
\end{definition}
\begin{lemma}
	Seien $(X_i, \cA_i)$, $i \in I$, messbare Rume, und sei $J \subset I$ eine nichtleere Teilmenge von $I$. So ist die Projektion
	\begin{align*}
		\pi_J = \pi_J^I : \prod_{i \in I} X_i \to \prod_{j \in J} x_j 
	\end{align*}
	$\bigotimes_{i \in I} \cA_i$ - $\bigotimes_{j \in J} \cA_j$-messbar.
\end{lemma}
\begin{lemma}
	Seien $(X_i, \cA_i)_{i \in I}$ und $(Y, \cC)$ messbare Räume, und sei $g : Y \to \prod_{i \in I} X_i$ eine Abbildung. Dann ist $g$ genau dann $\cC-\bigotimes_{i \in I} \cA_i$-messbar, wenn alle Projektionen $\pi_i \circ g$ $\cC-\cA_i$-messbar sind.
\end{lemma}

\begin{definition}
	Sei $M \subset \displaystyle \prod_{i \in I} X_i$ und sei für ein beliebiges $j$ $a_j \in X_j$. Der \tbf{Schnitt von $M$ durch $a_j$} ist die Menge:
	\begin{align*}
		M^{a_j} := \lr{(x_i)_{i \in I \setminus \{j\}} \in \prod_{i \in I \setminus \{j\}} X_i : x_j := a_j \implies (x_i)_{i \in I} \in M}
	\end{align*}
\end{definition}

\begin{corollary}
	Seien $(X_i, \cA_i)_{i \in I}$ messbare Räume, sei $M \in \displaystyle \bigotimes_{i \in I} \cA_i$, und sei $a_j \in X_j$ für ein $j \in I$. Dann ist der Schnitt $M^{a_j}$ ein Element von $\displaystyle \bigotimes_{i \in I \setminus \{j\}} \cA_i$.
\end{corollary}

\begin{theorem}
	Seien $(X_i, \cA_i)_{i \in I}$ messbare Räume, sodass jedes $\cA$ die erzeugte $\sigma$-Algebra eines Mengensystems $\cE_i$ ist. Dann gilt
	\begin{align*}
		\bigotimes_{i \in I} \cA_i = \sigma\lr(\bigcup_{i \in I} \pi_i^{-1}(\cE_i))
	\end{align*}
\end{theorem}
\begin{proof}
	Es gilt:
	\begin{align*}
		\bigotimes_{i \in I} \cA_i 
		&= \sigma \lr(\bigcup_{i \in I} \pi_i^{-1}(\cA_i))\\
		&= \sigma \lr(\bigcup_{i \in I} \pi_i^{-1}(\sigma(\cE_i)))\\
		&= \sigma \lr(\bigcup_{i \in I} \sigma(\pi_i^{-1}(\cE_i)))\\
		&= \sigma \lr(\bigcup_{i \in I} \pi_i^{-1}(\cE_i))
	\end{align*}
\end{proof}
\begin{corollary}
	Sei $(X_i, \cA_i)_{i = 1, \hdots, n}$ eine endliche Menge messbarer Räume, wobei $\cA_i$ durch $\cE_i$ generiert sind und sodass für alle $i = 1, \hdots, n$ eine Folge $(E_i^k)_{k \in \bN} \subseteq \cE_i$, sodass
	\begin{align*}
		\bigcup_{k \in \bN} E_i^k = X_i
	\end{align*}
	Dann erzeugt das System
	\begin{align*}
		Q_0 := \lr{\prod_{i = 1}^n A_i : A_i \in \cE_i}
	\end{align*}
	die Produkt-$\sigma$-Algebra $\displaystyle \bigotimes_{i = 1}^n \cA_i$.
\end{corollary}
\begin{example}
	Die Borel-$\sigma$-Algebra $\cB^n$ ist das Produkt der Borel-Sigma-Algebra $\cB$ auf $\bR$. Wir wählen also als $\cE_i$ die Intervalle, also Mengen $M$ mit $(a,b) \subseteq M \subseteq [a,b]$. Dann ist $Q_0$ die Menge der Quader. Wir werden später Zeigen, dass $\cB^n = \sigma(Q^n)$ und $\cB = \sigma(I)$.
	\newpar
	Es gilt $\bR = \displaystyle \bigcup_{k = 1}^\infty (-k, k)$, also ist
	\begin{align*}
		\cB^n = \sigma(Q^n) = \bigotimes_{i = 1}^n \cB^1.
	\end{align*}
\end{example}
\begin{definition}
	Sei $I$ eine Indexmenge. So defieren wir
	\begin{align*}
		P_0(I) := \lr{J \subseteq I : (J \neq \emptyset) \wedge (\abs{J} < \infty)}
	\end{align*}
	Dann ist 
	\begin{align*}
		\cQ := \bigcup_{J \in P_0(I)}\lr{\prod_{j \in J} \cA_j \times \prod_{i \notin J} X_i : A_i \in \cA_i, j \in J}
	\end{align*}
	die Menge der \tbf{messbaren Quader} und
	\begin{align*}
		\cZ := \bigcup_{J \in P_0(I)}\lr{\cA_J \times \prod_{i \notin J} X_i : A_J \in \bigotimes_{j \in J} \cA_j} = \bigcup_{J \in P_0(I)} \pi_j^{-1}(A_j)
	\end{align*}
	die Menge der \tbf{messbaren Zylinder}.
\end{definition}
\begin{theorem}
	Sei $(X_i, \cA_i)\iinI$ eine Familie messbarer Räume. Dann erzeugen $\cQ$ und $\cI$ die Produkt-Sigma-Algebra $\displaystyle \bigotimes\iinI \cA_i$, d.h.
	\begin{align*}
		\bigotimes_{i \in I} \cA_i := \sigma(\cQ) = \sigma(\cZ)
	\end{align*}
\end{theorem}
\section{Das $n$-dimensionale Lebesquemaß $\lambda^n$}
\begin{lemma}
	Der elementargeometrische Inhalt $\vol^n : \cQ^n \to \barR_{\geq 0}$ ist ein Prämaß auf dem Halbring $\cQ^n \subset P(\bR^n)$.
\end{lemma}
\begin{definition}
	Das $n$-dimensionale äußere Lebesquemaß ist die Carathéodory-Fortsetzung des elementargeometrischen Inhalts, also:
	\begin{align*}
		\lambda^n(E) := \inf\lr{\sum_{k = 1}^\infty \vol^n(Q_k) : Q_k \in \cQ^n, E \subset \bigcup_{i = 1}^\infty \cQ_k}
	\end{align*}
	Das $n$-dimensionale Lebesquemaß ist dann die Einschränkung von $\lambda^n$ auf die $\sigma$-Algebra $\cM(\lambda^n)$ der messbaren Mengen. Wir bezeichnen dieses Maß ebenfalls mit $\lambda^n$.
\end{definition}
\begin{corollary}
\begin{enumerate}
	\item Das äußere Maß $\lambda^n$ ist regulär.
	\item Das Maß $\lambda^n$ ist vollständig.
\end{enumerate}
\end{corollary}
\begin{proof}
	Gemäß der Vorüberlegungen zur Carathéodory-Fortsetzung aus dem letzten Kapitel.
\end{proof}
\begin{lemma}
	\theoremname{Approximation durch Gitterfiguren:}
	Betrachte für $k \in \bN_0$ die Würfelfamilie
	\begin{align*}
		\cW_k := \{Q_{k,m} := 2^{-k}(m + [0,1]^n) \mid m \in \bZ^n\}
	\end{align*}
	und definiere für $E \subseteq \bR^n$ die Approximationen von unten und oben:
	\begin{align*}
		\cF_k(E) := &\bigcup \lr{Q \in \cW_k \mid Q \subseteq E}\\
		\cF^k(E) := &\bigcup \lr{Q \in \cW_k \mid Q \cap E \neq \emptyset}
	\end{align*}
	So gilt:
	\begin{enumerate}
		\item $F_k(E)$ und $F^k(E)$ sind abzählbare Vereinigungen abzählbar vieler kompakter Quader mit paarweise disjunktem Inneren
		\item \begin{align*}
			F_1(E) &\subseteq F_2(E) \subseteq \hdots \subseteq E\\
			F^1(E) &\supseteq F^2(E) \supseteq \hdots \supseteq E
		\end{align*}
		\item \begin{align*}
			F_k(E) &\supseteq \{x \in \bR^n \mid d(x, \bR^n \setminus E) > 2^{-k}\sqrt{n}\}\\
			F^k(E) &\subseteq \{x \in \bR^n \mid d(x, E) \leq 2^{-k}\sqrt{n}\}
		\end{align*}
		\item \begin{align*}
			\textnormal{int}(E) &\subseteq \bigcup_{k = 1}^\infty F_k(E) \subseteq E\\
			\bar E &\supseteq \bigcap_{k = 1}^\infty F^k(E) \supseteq E
		\end{align*}
	\end{enumerate}
\end{lemma}
\begin{lemma}
	Die Borelmengen $\cB^n$ sind die vom Halbring der Quader $\cQ^n$, dem Ring $\cF^n$ der Figuren, und dem vom System $\cC^n$ der abgeschlossenen Mengen erzeugte $\sigma$-Algebra, also:
	\begin{align*}
		\cB^n = \sigma(\cQ^n) = \sigma(\cF^n) = \sigma(\cC^n)
	\end{align*}
\end{lemma}
\begin{corollary}
	Für das äußere Lebesquemaß $\lambda^n$ gilt folgendes:
	\begin{enumerate}
		\item Alle Borelmengen sind $\lambda^n$-messbar.
		\item Zu jeder Teilmenge $E \subseteq \bR^n$ existiert eine Obermenge $B \subseteq E$ mit $\lambda^n(E) = \lambda^n(B)$ 
		\item $\lambda^n(K) < \infty$ für alle beschränkten Mengen $K \subseteq \bR^n$ (also insbesondere für kompakte Mengen).
	\end{enumerate}
\end{corollary}
\begin{lemma}
	Für ein beliebiges $E \subseteq \bR^n$ gilt
	\begin{align*}
		\lambda^n(E) = \inf\lr{\lambda^n(U) \mid U \textnormal{ offen}, U \supseteq E}.
	\end{align*}
	Ist $E$ zusätzlich $\lambda^n$-messbar, gilt außerdem
	\begin{align*}
		\lambda^n(E) = \sup\lr{\lambda^n(K) \mid K \textnormal{ kompakt}, K \subseteq E}.
	\end{align*}	
\end{lemma}
\begin{theorem}
	Eine Menge $D \subseteq \bR^n$ ist genau dann $\lambda^n$-messbar, wenn eine der folgenden Bedingungen gilt:
	\begin{enumerate}
		\item Es existiert eine Borelmenge $E \in \cB^n$ mit $E \supseteq D$ und $\lambda^n(E \setminus D) = 0$.
		\item Es existiert eine Borelmenge $C \in \cB^n$ mit $C \subseteq D$ und $\lambda^n(D \setminus C) = 0$.
	\end{enumerate}
	Wir können hier insbesondere $E = \bigcap_{i \in \bN} U_i$ mit $U_i$ offen oder $C = \bigcup_{i \in \bN} A_i$ mit $A_i$ abgeschlossen wählen.
\end{theorem}
\begin{theorem}
	\theoremname{Lusin}: Sei $A \subseteq \bR^n$ eine offene Menge mit $\lambda^n(A) < \infty$. Sei $f : A \to \bR$ auf $A$ $\lambda^n$-messbar. Dann existiert für alle $\epsilon \in \bR_{\geq 0}$ eine kompakte Teilmenge $K$, sodass $\lambda^n(A \setminus K) < \epsilon$ und sodass $f$ auf $K$ stetig ist.
\end{theorem}
\begin{theorem}
	Ein äußeres Maß $\mu$ auf $\bR^n$ heißt \tbf{Borelmaß}, falls folgendes gilt:
	\begin{enumerate}
		\item Alle Borelmengen sind $\mu$-messbar
		\item Für jede kompakte Menge $K$ gilt $\mu(K) < \infty$
	\end{enumerate}
\end{theorem}
\begin{example}\phantom{}
	\begin{enumerate}
		\item $\lambda^n$ ist ein Borelmaß.
		\item Für beliebiges $E \subseteq \bR^n$ ist $\lambda^n |_E$ ein Borelmaß.
	\end{enumerate}
\end{example}
\begin{definition}
	Ein äußeres Maß $\mu$ auf $\bR^n$ heißt \tbf{translationsinvariant}, falls
	\begin{align*}
		\forall \vv \in \bR^n, E \subseteq \bR^n :\\ \mu(E + \vv) = \mu(E)
	\end{align*}
\end{definition}
\begin{example}
	Da der Elementarinhalt $\vol^n$ translationsinvariant ist folgt auch direkt die Translationsinvarianz von $\lambda^n$.
\end{example}
\begin{lemma}
	Ist $\mu$ ein translationsinvariantes äußeres Maß, so ist jede Hyperebene 
	\begin{align*}
		H := \lr{x \in \bR^n \mid \exists i \in 1, \hdots, n : x_i = c \in \bR}
	\end{align*}
	eine $\mu$-Nullmenge.
\end{lemma}
\begin{theorem}
	Sei $\mu$ ein translationsinvariantes Borelmaß auf $\bR^n$. Sei $E$ $\lambda^n$-messbar. Dann gilt
	\begin{align*}
		\mu(E) = \mu([0,1]^n) \cdot \lambda^n(E) := \theta \cdot \lambda^n(E)
	\end{align*}
\end{theorem}
\begin{lemma}
	Sei $U \subseteq \bR^n$ offen. Sei $f : U \to \bR^n$ lipschitzstetig mit Lipschitzkonstante $\Lambda$ bezüglich $\norm{\cdot}_\infty$. Dann gilt für alle $E \subseteq U$: 
	\begin{align*}
		\lambda^n(f(E)) \leq \Lambda^n \lambda^n(E) 
	\end{align*}
\end{lemma}
\begin{theorem}
	Sei $U \subseteq \bR^n$ offen und $f \in C^1(U, \bR^n)$. Dann gilt:
	\begin{enumerate}
		\item Ist $N \subseteq U$ eine $\lambda^n$-Nullmenge, so ist $f(N)$ ebenfalls eine $\lambda^n$-Nullmenge.
		\item Ist $E \subseteq U$ $\lambda^n$-messbar, so ist auch $f(E)$ $\lambda^n$-messbar.
	\end{enumerate}
\end{theorem}
\begin{theorem}
	\theoremname{Invarianz von $\lambda^n$ unter orthogonalen Transformationen:}
	Sei $S \in O(n)$. Dann gilt für alle $E \subset \bR^n$:
	\begin{align*}
		\lambda^n(S(E)) = \lambda^n(E)
	\end{align*}
\end{theorem}
\begin{corollary}
	\theoremname{Bewegungsinvarianz von $\lambda^n$:}
	Sei $S \in O(n)$ und $a \in \bR^n$. Dann gilt für alle $E \subset \bR^n$:
	\begin{align*}
		\lambda^n(S(E) + a) = \lambda^n(E)
	\end{align*}
\end{corollary}
\begin{lemma}
	\theoremname{Polarzerlegung:} Zu jedem $S \in \GL_n(\bR)$ gibt es eine Diagonalmatrix $\Lambda$ mit positiven Einträgen $\lambda_i$ und Orthogonale Matrizen $T_1, T_2 \in O(n)$, sodass
	\begin{align*}
		S = T_1 \Lambda T_2
	\end{align*}
\end{lemma}
\begin{theorem}
	Für eine beliebige Lineare Abbildung $S \in \bRnn$ gilt
	\begin{align*}
		\lambda^n(S(E)) = \abs{\det S} \lambda^n(E)
	\end{align*}
\end{theorem}
\begin{example}
	Seien $\lambda_1, \hdots, \lambda_n > 0$. So definiert die Menge
	\begin{align*}
		E := \{x \in \bR^n \mid \sum_{i = 1}^n (\frac{x_i}{\lambda_i})^2 < 1\}
	\end{align*}
	einen Ellipsoid mit Halbachsen $\lambda_i$. Dieser ist das Bild eines offenen Balls unter einer Diagonalmatrix $\Lambda$. Also gilt
	\begin{align*}
		\lambda^n(E) = \lambda^n(\Lambda(B_1(0))) ) \prod_{i = 1}^n \lambda_i \cdot \lambda^n (B_1(0))
	\end{align*}
\end{example}
\begin{theorem}
	\label{theorem:vitalinonmeasurable}
	Jede Vitalimenge $V$ ist nicht $\lambda^1$-messbar, und somit insbesondere nicht Borel.
\end{theorem}
\begin{proof}
	Sei $q_k$ eine Abzählung von $[0,1] \cap \bQ$. Wir wissen $\forall q \in \bQ : \lambda^1(V) = \lambda^1(V + q)$. Wir wissen außerdem
	\begin{align*}
		[0,1] \subseteq \bigcup_{k \in \bN} q_k + V \subseteq [-1,2],
	\end{align*}
	also gilt insbesondere
	\begin{align*}
		1 \leq \lambda^1(\bigcup_{k \in \bN} q_k + V) \leq 3.
	\end{align*}
	Nun gilt:
	\begin{align*}
		\sum_{k = 1}^\infty \lambda^1(V) &= \sum_{k = 1}^\infty \lambda^1(V + q_k)\\
			 							 &= \lambda^1 (\bigcup_{k = 1}^\infty(S + q_k))\\
			 							 &\in [1,3]
	\end{align*}
	Was ein Widerspruch sowohl zu $\lambda^1(V) = 0$ also auch zu $\lambda^1(V) = \epsilon > 0$ ist.
\end{proof}
\chapter{Integrationstheorie}
\section{Das Lebesqueintegral}
Im gesamten folgende Kapitel nehmen wir $(X, \cA, \mu)$ als beliebigen Maßraum. Ist $\mu$ ein äußeres Maß, ersetzen wir $\cA$ durch $\cM(\mu)$.
\newpar
Wir nehmen außerdem $f : D \to \barR$ mit $D \subset X$ entwededer als $\cA$-messbare Funktion an, also
\begin{align*}
	D \in \cA, \forall s \in \bR : \{f > s\} \in \cA,
\end{align*}
oder als $\mu$-messbare Funktion, also
\begin{align*}
	f : \tilde D \to \barR, \tilde D \in \cA, \mu(D \setminus \tilde D) = 0,
\end{align*}
und $f|_{\tilde D}$ ist $\cA|_{\tilde D}$ messbar.
\newpar
Wir erinnern uns, dass die einfachsten messbaren Funktionen die Indikatorfunktionen $\chi_E$ von Mengen $E \in \cA$ sind.
\begin{definition}
	Sei $(Y, \cC)$ ein messbarer Raum. So nennen wir eine Funktion $f : Y \to \bR$ eine \tbf{Treppenfunktion}, wenn sie als endliche Linearkombination von Indikatorfunktionen von Mengen $A_i \in \cA$ darstellbar ist, also:
	\begin{align*}
		f(x) = \sum_{i = 1}^n \alpha_i \cdot (\chi_{A_i}(x))
	\end{align*}
	Insbesondere hat eine Treppenfunktion nur endlich viele mögliche Werte.
\end{definition}
\begin{proposition}
	Die Treppenfunktionen bilden einen $\bR$-Vektorraum.
\end{proposition}
\begin{theorem}
	Sei $(Y, \cC)$ ein messbarer Raum. Für jede nichtnegative $\cC$-messbare Funktion $f : Y \to [0, \infty]$ existiert eine monoton wachsende Folge $f_n$ nichtnegativer Treppenfunktionen, welche punktweise gegen $f$ konvergiert.
\end{theorem}
\begin{proof}
	Sei $m \in \bN$, $k = 1, \hdots, m2^m$. Wir definieren
	\begin{align*}
		F_{m,k} := \{x \in Y \mid \frac{k-1}{2^m} \leq f(x) < \frac{k}{2^m}\}
	\end{align*}
	Da $f$ messbar ist, sind auch diese Mengen $F_{m,k}$ messbar. Wir definieren nun
	\begin{align*}
		f_m(x) =
		\begin{cases}
			\frac{k-1}{2^m} & x \in F_{m,k}\\
			m & x \in Y \setminus \bigcup_{k} F_{m,k}
		\end{cases}
	\end{align*}
	Offensichtlich ist die Folge $f_m$ monoton wachsend. Da die Differenz zum Funktionswert immer kleiner wird, konvergiert die Folge außerdem gegen $f$.
\end{proof}
\begin{definition}
	\theoremname{Lebesqueintegral von Charakteristischen Funktionen:}
	Das Lebesqueintegral einer Charakeristischen Funktion einer Menge $E \in \cA$ kann nun sehr intuitiv definiert werden durch:
	\begin{align*}
		\int_X \chi_A d\mu = \mu(A)
	\end{align*}
\end{definition}
\begin{lemma}
	Seien $A_1, \hdots, A_m, B_1, \hdots, B_m \in \cA$ paarweise disjunkt und seien $\alpha_i$, $\beta_j$ nichtnegative Zahlen. Dann gilt:
	\begin{align*}
		\sum_{i = 1}^n \alpha_i \chi_{A_i} &\leq \sum_{j = 1}^n \beta_j \chi_{B_j}\\
		\implies \sum_{i = 1}^n \alpha_i \mu(A_i) &\leq \sum_{j = 1}^n \beta_j \mu(B_j)
	\end{align*}
\end{lemma}
\begin{proof}
	Sei $\alpha_0 = \beta_0 = 0$, $A_0 = X \setminus \bigcup_{i = 1}^m A_i$, $B_0 = X \setminus \bigcup_{j = 1}^n B_j$ mit $A_i \cap B_j = \emptyset$ oder $\alpha_i \leq \beta_j$. Dann gilt:
	\begin{align*}
		\sum_{i = 0}^m \alpha_i \mu(A_i) 
		&= \sum_{i = 0}^m \sum_{j = 0}^n \alpha_i \mu(A_j \cap B_j)\\ 
		&\leq \sum_{i = 0}^m \sum_{j = 0}^n \beta_j \mu(A_j \cap B_j)\\
		&= \sum_{j = 0}^n \beta_j \mu(\cap B_j) 
	\end{align*}
\end{proof}
\begin{anmerkung}
	Wir können jede Treppenfunktion
	\begin{align*}
		f = \sum_{j = 1}^m \beta_j \chi_{B_j}
	\end{align*}
	in eine Darstellung mit paarweise disjunkten $B_j$ bringen, indem wir den Funktionswert auf einem Schnitt $B_i \cap B_j$ als $\beta_i + \beta_j$ definieren. 
\end{anmerkung}
\begin{definition}
	\theoremname{Lebesqueintegral von Treppenfunktionen:}
	Sei $D \in \cA$ und $s$ eine nichtnegative Treppenfunktion mit einer Darstellung
	\begin{align*}
		s = \sum_{j = 1}^n \beta_j \chi_{B_j}
	\end{align*}
	mit paarweise disjunkten $B_j \in \cA$ und $\beta_j \in \bR_{\geq 0}$.
	\newpar
	So definieren wir das Lebesqueintegral von $s$ als:
	\begin{align*}
		\int_D s\ d\mu = \sum_{j = 1}^n \beta_j \mu(B_j)
	\end{align*}
\end{definition}
\begin{definition}
	\theoremname{Lebesqueintegral messbarer Funktionen:}
	Für nichtnegative $\cA$-messbare numerischer Funktionen auf $D \in \cA$ setzen wir:
	\begin{align*}
		\int_D f\ d\mu &:= \sup \lr{\int_D s\ d\mu}
	\end{align*}
	Wobei jedes $s$ eine Treppenfunktion ist, sodass $\forall x \in D : 0 \leq s(x) \leq f(x)$.
	Für beliebige $\cA$-messbare Funktionen $f$ auf $D \in \cA$ definieren wir das Lebesqueintegral durch
	\begin{align*}
		\int_D f\ d_\mu := \int_D f^+\ d\mu - \int_D f^{-}\ d\mu,
	\end{align*}
	solange wenigstens eines der Intergral auf der rechten Seite endlich ist.
\end{definition}
\begin{anmerkung}
	Für Treppenfunktion stimmen die Integraldefinitionen gemäß unseres Lemmas überein.
\end{anmerkung}
\begin{proposition}
	Sei $f$ $\cA$-messbar auf einer Nullmenge $N \in \cA$. Dann ist
	\begin{align*}
		\int_N f\ d\mu = 0
	\end{align*}
\end{proposition}
\begin{proposition}
	Sei $f : X \to \barR$ und $M \in \cA$. Dann gilt
	\begin{align*}
		\int_M f\ d\mu = \int_X f \chi_M\ d\mu
	\end{align*}
	und
	\begin{align*}
		\int_M f\ d\mu = \int_M f\ d\mu|_M
	\end{align*}
\end{proposition}
\begin{proof}
	\begin{enumerate}
	\item
	Sei $f \geq 0$ und $0 \leq s \leq f$ auf $M$. Dann folgt $0 \leq s\chi_M \leq f\chi_M$. Sei nun
	\begin{align*}
		s = \sum \alpha_i \chi_{A_i}.
	\end{align*}
	Dann ist
	\begin{align*}
		s\chi_M = \sum \alpha_i \chi_{A_i \cap M}.
	\end{align*}
	Also gilt
	\begin{align*}
		\sup_{0 \leq s \leq f} \leq \sup_{0 \leq s \leq f_{\chi_M}},
	\end{align*}
	also
	\begin{align*}
		\int_M f\ d\mu \leq \int_X f\chi_M\ d\mu.
	\end{align*}
	Wir wissen außerdem $x \in X \setminus M \implies \forall i : x \notin A_i$, also
	\begin{align*}
		s = \sum \alpha_i \chi_{A_i \cap M},
	\end{align*}
	also
	\begin{align*}
		\int_X s\ d\mu = \int_M s\ d\mu \implies \int_X f(X_M)\ d\mu \leq \int_M f\ d\mu.
	\end{align*}
	\item
	\begin{align*}
		\int_M s\ d\mu &= \sum \alpha_i \mu(A_i)\\
		&= \sum \alpha_i \mu(A_i \cap M)\\
		&= \sum \alpha_i \mu|_M(A_i)\\
		&= \int_M s\ d\mu|_M
	\end{align*}
\end{enumerate}
\end{proof}
Es reicht also, uns auf Integrale über ganz $X$ zu beschränken.
\begin{lemma}\theoremname{Monotonie des Lebesqueintegrals:}
	Für nichtnegative $\cA$-messbare Funktionen $f,g$ folgt aus $0 \leq f \leq g$
	\begin{align*}
		0 \leq \int_X f\ d\mu \leq \int_X g\ d\mu
	\end{align*}
\end{lemma}
\begin{proof}
	Die Menge der Treppenfunktionen unter $f$ ist eine Teilmenge der Treppenfunktionen unter $g$.
\end{proof}
\begin{theorem}
	\theoremname{Über monotone Konvergenz:}
	Seien $f_n$ nichtnegative $\cA$-messbare Funktionen auf $X$, sodass $f_n \uparrow f$, dann gilt
	\begin{align*}
		\lim_{n \to \infty} \int_x f_n\ d\mu = \int_X f\ d\mu
	\end{align*}
\end{theorem}
\begin{lemma}
	Seien $f_1, f_2$ nichtnegative $\cA$-messbare Funktionen auf $X$. Dann gilt
	\begin{align*}
		\int_X (f_1 + f_2) \dmu = \int_X f_1 \dmu + \int_X f_2 \dmu
	\end{align*}
\end{lemma}
\begin{anmerkung}
	Sei $f$ nur $\mu$-messbar, also auf einer Menge $D$ definiert, sodass $\mu(X \setminus D) = 0$. So setzten wir
	\begin{align*}
		\int_X f \dmu = \int_D f \dmu
	\end{align*}
	(solange das Integral auf der rechten Seite tatsächlich definiert ist).
\end{anmerkung}
\begin{lemma}
	Seien $f_1, f_2$ nichtnegative $\mu$-messbare Funktionen auf $X$. Dann gilt ebenfalls
	\begin{align*}
		\int_X (f_1 + f_2) \dmu = \int_X f_1 \dmu + \int_X f_2 \dmu
	\end{align*}
\end{lemma}
\begin{lemma}
	Für nichtnegative $\mu$-messbare Funktionen $f,g$ folgt aus $0 \leq f \leq g$ $\mu$-fast-überall, dass
	\begin{align*}
		0 \leq \int_X f \dmu \leq \int_X g \dmu
	\end{align*}
\end{lemma}
\begin{definition}
	Die Menge aller $\mu$-messbaren Funktionen auf $X$, deren Lebesque-Integral definiert ist, wird mit
	\begin{align*}
		\cL^*(\mu) = \cL^*
	\end{align*}
	bezeichnet. Weiter definieren wir
	\begin{align*}
		\cL^1 := \lr{f \in \cL*(\mu) \mid \int_X f \dmu \in \bR}
	\end{align*}
	und nennen eine Funktion $f$ \tbf{integrierbar}, falls $f \in \cL^1$.
\end{definition}
\begin{lemma}
	Sei $g \in \cL^*(\mu)$ und $f$ eine $\mu$-messbare Funktion mit $f = g$ $\mu$-fast überall. Dann gilt $f \in \cL^*(\mu)$ und
	\begin{align*}
		\int_X f \dmu = \int_X g \dmu
	\end{align*}
	Ist $\mu$ vollständig, so gilt die Behauptung auch für $f$ nicht $\mu$-messbar.
\end{lemma}
\begin{lemma}
	\theoremname{(Chebyshevsche Ungleichung:)} Sei $f \geq 0$ $\mu$-messbar auf $X$ und $\int_X f \dmu < \infty$. Dann gilt:
	\begin{align*}
		\mu(\{f \geq s\}) = 
		\begin{cases}
			\displaystyle \frac{1}{s} \int_X f \dmu & s \in (0, \infty)\\
			0 & s = \infty
		\end{cases}
	\end{align*}
\end{lemma}
\begin{corollary}
	\phantom{}
	\begin{enumerate}
		\item Ist $\int_X f \dmu < \infty$, so folgt $f(X) < \infty$ für $\mu$-fast alle $x \in X$.
		\item Ist $f \geq 0$ und $\int_X f \dmu = 0$, so gilt $f(x) = 0$ $\mu$-fast überall.
	\end{enumerate}
\end{corollary}
\begin{corollary}
	Seien $f, g \in \cL^1$.
	\begin{enumerate}
		\item Falls $\forall A \in \cA : \int_A f \dmu = 0$ ist, dann gilt $f = 0$ $\mu$-fast überall.
		\item Gilt für alle $A \in \cA$ die Ungleichung $\int_X f \dmu \leq \int_A g \dmu$, so ist $f \leq g$ $\mu$-fast überall.
	\end{enumerate}
\end{corollary}
\begin{theorem}
	Seien $f, g \in \cL^1(\mu)$. Dann gilt:
	\begin{enumerate}
		\item Für alle $\alpha, \beta \in \bR$ ist auch $\alpha f + \beta g \in \cL^1(\mu)$ und es gilt:
		\begin{align*}
			\int_X (\alpha f + \beta g) \dmu = \alpha \int_Xf \dmu + \beta \int_X g \dmu
		\end{align*}
		\item $\abs{f} \in \cL^1(\mu)$ und
		\begin{align*}
			\abs{\int_x f \dmu} \leq \int_X \abs{f} \dmu
		\end{align*}
		\item $\max(f,g) \in \cL^1(\mu)$, $\min(f,g) \in \cL^1(\mu)$.
	\end{enumerate}
	Ist $f$ nur $\mu$-messbar, aber $g \in \cL^1(\mu)$ mit $\abs{f} \leq g$ $\mu$-fast überall, so gilt
	\begin{enumerate}
		\item[(iv)] $f \in \cL^1(\mu)$ und
		\begin{align*}
			\int_X f \dmu \leq \int_X \abs{f} \dmu \leq \int_X g \dmu
		\end{align*}
	\end{enumerate}
\end{theorem}

%
%
%
%
%
%
%
%
%
%
\appendix
\chapter{Wörterbuch Analysis III}
\section*{A}
\begin{description}
	\item[\tit{Algebra:}] Sei $X$ eine beliebige Menge. Eine Menge $\cA \subset \cP(X)$ heißt \tit{Mengenalgebra} oder einfach \tit{Algebra}, falls $\cA$ ein Mengenring ist und $X$ enthält. Somit ist $\cA$ eine Mengenalgebra, falls:
	\begin{enumerate}
		\item $\emptyset \in \cA$,
		\item $A, B \in \cA \implies A \setminus B \in \cA$ ($\cA$ ist \tit{$\setminus$-stabil}),
		\item $A, B \in \cA \implies A \cap B \in \cA$ ($\cA$ ist \tit{$\cap$-stabil}),
		\item $X \in \cA$.
	\end{enumerate}
	\item[\tit{äußeres Maß:}] Sei $X$ eine beliebige Menge. Ein \tit{äußeres Maß} ist eine Funktion $\mu : \cP(X) \to \barR_{\geq 0}$ mit folgenden Eigenschaften:
	\begin{enumerate}
		\item $\mu(\emptyset) = 0$
		\item $\displaystyle A \subset \bigcup_{i = 1}^\infty A_i \implies \mu(A) \leq \sum_{i = 1}^\infty \mu(A_i)$ ($\sigma$-subadditivität)
	\end{enumerate} 
	Jedes äußere Maß definiert ein vollständiges Maß auf der $\sigma$-Algebra seiner messbaren Mengen.
\end{description}
\section*{C}
\begin{description}
	\item[\tit{Carathéodory-Fortsetzung}] Sei $\lambda : \cR \to \barR_{\geq 0}$ ein Prämaß. So ist die Funktion $\mu : \cP(X) \to \barR_{\geq 0}$ mit
	\begin{align*}
		\mu(E) = \inf\lr{\sum_{i = 1}^\infty \lambda(A_i) \mid A_i \in \cR, E \subset \bigcup_{i = 1}^\infty A_i}
	\end{align*}
	ein äußeres Maß auf $X$, welches wir die \tit{Carathéodory-Fortsetzung von $\lambda$} nennen. Per Definition ordnet $\mu$ jeder Menge $E$ den Wert der gemäß $\lambda$ kleinstmöglichen Überdeckung mit Mengen aus $\cR$ zu (bzw. die größte untere Schranke, falls es kein Minimum gibt).
\end{description}
\section*{D}
\begin{description}
	\item[\tit{Dynkin-System}:]
	Sei $X$ eine beliebige Menge. Eine Menge $\cA \subset \cP(X)$ heißt \tit{Dynkin-System}, falls:
	\begin{enumerate}
		\item $X \in \cD$,
		\item $A, B \in \cD, A \subset B \implies B \setminus A \in \cD$,
		\item $(A_i)_{i \in \bN} \subset \cA$ paarweise disjunkt $\implies \bigcup_{i = 1}^\infty A_i \in \cD$.
	\end{enumerate}
	Die Definition entspricht der Definition einer $\sigma$-Algebra, aber mit eingeschränkten Stabilitätseigenschaften. Ein Dynkin-System ist genau dann eine $\sigma$-Algebra, wenn es $\cap$-stabil ist.
\end{description}
\section*{E}
\begin{description}
	\item[\tit{endliche Additivität}:]  Sei $X$ eine beliebige Menge und $\cM \subset \cP(X)$ ein Mengensystem auf $X$. Eine Abbildung $f : M \to \barR_{\geq 0}$ heißt \tit{endlich additiv}, wenn für paarweise disjunkte Mengen $A_1, \hdots, A_n \in \cM$ mit $\bigcup_{i = 1}^n A_i \in \cM$ gilt, dass:
	\begin{align*}
		f\lr(\bigcup_{i = 1}^n A_i) = \sum_{i = 1}^n f(A_i).
	\end{align*}
	Inhalte sind per Definition endlich additiv. Maße und Prämaße sind per Definition $\sigma$-additiv, also insbesondere endlich additiv.
	\item[\tit{endliches Maß}:] Ein Maß (bzw. Prämaß, äußeres Maß, Inhalt) $mu$ auf einem Mengensystem $\cM$ heißt \tbf{endlich}, falls $\forall M \in \cM : \mu(M) < \infty$.
\end{description}
\section*{H}
\begin{description}
	\item[\tit{Halbring:}] Sei $X$ eine beliebige Menge. Eine Menge $\cQ \subset \cP(X)$ heißt \tit{Halbring}, falls:
	\begin{enumerate}
		\item $\emptyset \in \cQ$
		\item $\cQ$ ist \tit{$\cap$-stabil}, also $P,Q \in \cQ \implies P \cap Q \in \cQ$ 
		\item Für $P, Q \in \cQ$ existieren endlich viele paarweise disjunkte Mengen $P_1, \hdots, P_k \in \cQ$, sodass
		\begin{align*}
			P \setminus Q = \bigcup_{i = 1}^k P_i
		\end{align*}
		$\cQ$ erfüllt also eine abgeschwächte Version von \tit{$\setminus$-Stabilität}.
	\end{enumerate}
	Halbringe sind die Mengensysteme, auf denen Inhalte definiert werden können.
	\item[\tit{Hopf-Fortsetzung:}] Sei $\lambda : \cR \to \barR_{\geq 0}$ ein Prämaß auf einem Mengenring $\cR$. So existiert ein Maß $\mu$ auf $\sigma(\cR)$ mit $\mu = \lambda$ auf $\cR$. Falls $\lambda$ $\sigma$-endlich ist, ist diese Fortsetzung eindeutig.
\end{description}
\section*{I}
\begin{description}
	\item[\tit{Inhalt:}] Sei $\cQ$ ein Halbring über einer Menge $\cX$. Eine Funktion $\lambda : \cQ \to \barR_{\geq 0}$ heißt \tit{Inhalt} auf $\cQ$, falls
	\begin{enumerate}
		\item $\lambda(\emptyset) = 0$
		\item $\lambda$ ist \tit{endlich additiv} - Für paarweise disjunkte Mengen $A_1, \hdots, A_n \in \cQ$ mit $\bigcup_{i = 1}^n A_i \in \cQ$ gilt also:
		\begin{align*}
			\lambda\lr(\bigcup_{i = 1}^n A_i) = \sum_{i = 1}^n \lambda(A_i).
		\end{align*}
	\end{enumerate} 
\end{description}
\section*{M}
\begin{description}
	\item[\tit{Maß:}] Sei $\cA$ ein $\sigma$-Algebra auf einer Menge $\cX$. Eine Funktion $\lambda : \cA \to \barR_{\geq 0}$ heißt \tit{Maß} auf $\cA$, falls
	\begin{enumerate}
		\item $\mu(\emptyset) = 0$
		\item $\mu$ ist \tit{$\sigma$-additiv} - Für jede Folge paarweise disjunkten Mengen $(A_i)_{i \in \bN} \subset \cA$ mit $\bigcup_{i = 1}^n A_i \in \cA$ gilt also:
		\begin{align*}
			\mu\lr(\bigcup_{i = 1}^\infty A_i) = \sum_{i = 1}^\infty \mu(A_i).
		\end{align*}
	\end{enumerate} 
	\item[\textit{messbare Funktion:}]
	Wir unterscheiden zwischen \tit{$\cA$-$\cC$-messbaren Funktionen}, welche auf einer gesamten Menge $X$ definiert sein müssen, und \tit{$\mu$-messbaren Funktionen}, welche nur fast überall auf $X$ definiert sein müssen.
	\begin{description}
		\item[\tit{$\cA$-$\cC$-messbar:}] Seien $(X, \cA)$ und $(Y, \cC)$ messbare Räume. Eine Abbildung $f : X \to Y$ heißt \tit{$\cA$-$\cC$-messbar}, falls $f^{-1}(\cC) \subset \cA$, also falls
		\begin{align*}
			\forall C \in \cC : f^{-1}(C) \in \cA
		\end{align*}
		Ist $f : X \to X$ sprechen wir auch einfach von $\cA$-messbaren Funktionen.
		\item[\tit{$\mu$-messbar:}] Sei $(X, \cA, \mu)$ ein Maßraum. Eine auf $D \in \cA$ definierte Funktion $f : D \to \barR$ heißt \tit{$\mu$-messbar} auf $X$, wenn $\mu(X \setminus D) = 0$ und wenn $f$ $\cA|_D$ messbar ist, also messbar auf der Einschränkung von $\cA$ von $X$ auf $D$.
	\end{description}
	\item[\textit{messbare Menge:}] Sei $\mu$ ein äußeres Maß auf einer Menge $X$. So heißt eine Menge $A \subset X$ \tit{messbar}, falls für alle $S \subset X$:
	\begin{align*}
		\mu(S) \geq \mu(S \cap A) + \mu(S \setminus A)
	\end{align*}
	Da per Definition äußerer Maße bereits $\mu(S) \leq \mu(S \cap A) + \mu(S \setminus A)$, ist dies äquivalent zu
	\begin{align*}
		\mu(S) = \mu(S \cap A) + \mu(S \setminus A).
	\end{align*}
\end{description}
\section*{N}
\begin{description}
	\item[\tit{numerische Funktion:}] Sei $(X, \cA)$ ein messbarer Raum und $D \in \cA$. So bezeichnen wir Funktionen $f : D \to \barR$ als \tit{numerische Funktionen}.
\end{description}
\section*{P}
\begin{description}
	\item[\tit{Prämaß:}] Sei $\cR$ ein Mengenring über einer Menge $\cX$. Eine Funktion $\lambda : \cR \to \barR_{\geq 0}$ heißt \tit{Prämaß} auf $\cR$, falls
	\begin{enumerate}
		\item $\lambda(\emptyset) = 0$
		\item $\mu$ ist \tit{$\sigma$-additiv} - Für jede Folge paarweise disjunkten Mengen $(A_i)_{i \in \bN} \subset \cA$ mit $\bigcup_{i = 1}^n A_i \in \cA$ gilt also:
		\begin{align*}
			\lambda\lr(\bigcup_{i = 1}^\infty A_i) = \sum_{i = 1}^\infty \lambda(A_i).
		\end{align*}
	\end{enumerate} 
	Ein Prämaß auf einem Ring $\cR$ kann durch \tit{Carathéodory-Fortsetzung} zu einem äußeren Maß auf $\cP(X)$ fortgesetzt werden. Es kann außerdem durch \tit{Hopf-Fortsetzung} zu einem Maß auf $\sigma(\cR)$ fortgesetzt werden.
\end{description}
\section*{R}
\begin{description}
	\item[\tit{reguläres äußeres Maß:}] Ein äußeres Maß heißt \tit{regulär}, falls für jede Menge $M \in X$ eine messbare Obermenge $D \supset M$ mit $\mu(D) = \mu(M)$ existiert.
	\item[\tit{Ring:}] Sei $X$ eine beliebige Menge. Eine Menge $\cA \subset \cP(X)$ heißt \tit{Mengenring} oder einfach \tit{Ring}, falls:
	\begin{enumerate}
		\item $\emptyset \in \cR$,
		\item $A, B \in \cR \implies A \setminus B \in \cR$ ($\cR$ ist \tit{$\setminus$-stabil}),
		\item $A, B \in \cR \implies A \cap B \in \cR$ ($\cR$ ist \tit{$\cap$-stabil}),
	\end{enumerate}
	Ringe sind die Mengensysteme, auf denen Prämaße definiert werden können.
\end{description}
\section*{S}
\begin{description}
	\item[\tit{$\sigma$-Algebra:}] Sei $X$ eine beliebige Menge. Eine Menge $\cA \subset \cP(X)$ heißt \tit{$\sigma$-Algebra}, falls:
	\begin{enumerate}
		\item $X \in \cA$,
		\item $A \in \cA \implies X \setminus A \in \cA$,
		\item $(A_i)_{i \in \bN} \subset \cA \implies \bigcup_{i = 1}^\infty A_i \in \cA$ ($\cA$ ist nicht nur \tit{$\cup$-stabil}, sondern auch abzählbar unendlich $\cup$-stabil),
	\end{enumerate}
	Aus der Definition folgt, dass $\cA$ auch $\setminus$-stabil und abzählbar unendlich $\cap$-stabil ist.
	$\sigma$-Algebren sind die Mengensysteme, auf denen Maße definiert werden können.
	\newpar
	Ist $\cM \subset \cP(X)$ ein Mengensystem, so notieren wir die kleinste $\sigma$-Algebra, die $\cM$ enthält als $\sigma(\cM)$.
	\item[\tit{$\sigma$-additivität:}]  Sei $X$ eine beliebige Menge und $\cM \subset \cP(X)$ ein Mengensystem auf $X$. Eine Abbildung $f : M \to \barR_{\geq 0}$ heißt \tit{$\sigma$-additiv}, wenn für jede Folge von paarweise disjunkten Teilmengen $A_i \in \cM$ mit $\bigcup_{i = 1}^\infty A_i \in \cM$ gilt, dass:
	\begin{align*}
		f\lr(\bigcup_{i = 1}^\infty A_i) = \sum_{i = 1}^\infty f(A_i).
	\end{align*}
	Maße und Prämaße sind per Definition $\sigma$-additiv.
	\item[\tit{$\sigma$-subadditivität:}] Sei $X$ eine beliebige Menge und $\cM \subset \cP(X)$ ein Mengensystem auf $X$. Eine Abbildung $f : M \to \barR_{\geq 0}$ heißt \tit{$\sigma$-subadditiv}, falls für jede Teilmenge $A \in \cM$ und Folge von Teilmengen $A_i \in \cM$ gilt, dass:
	\begin{align*}
		A \subset \bigcup_{i = 1}^\infty A_i \implies f(A) \leq \sum_{i = 1}^\infty f(A_i).
	\end{align*}
	Äußere Maße sind per Definition $\sigma$-subadditiv. Da $\sigma$-subadditivität aus $\sigma$-additivität folgt sind Maße und Prämaße ebenfalls $\sigma$-additiv. 
	\item[\tit{stabil}:] Ein Mengensystem $\cM$ heißt stabil, falls es unter einer bestimmten Mengenoperation abgeschlossen ist. Insbesondere sind für die Maßtheorie folgende Begriffe relevant:
	\begin{description}
		\item[\tit{$\cap$-stabil:}] $\cM$ heißt $\cap$-stabil, falls für alle $A,B \in \cM$ auch $A \cap B \in \cM$.
		\item[\tit{$\cup$-stabil:}] $\cM$ heißt $\cap$-stabil, falls für alle $A,B \in \cM$ auch $A \cup B \in \cM$.
		\item[\tit{$\setminus$-stabil:}] $\cM$ heißt $\cap$-stabil, falls für alle $A,B \in \cM$ auch $A \setminus B \in \cM$.
	\end{description}
	$\sigma$-Algebren sind $\cap$-stabil, $\cup$-stabil und $\setminus$-stabil. Mengenringe und Mengenalgebren sind $\cap$-stabil und $\setminus$-stabil. Halbringe sind $\cap$-stabil und erfüllen eine abgeschwächte Version von $\setminus$-Stabilität..
\end{description}
\chapter{Sammlung von Reihen und ihren Grenzwerten}
\section{Geometrische Summe}
\begin{align*}
	\sum_{k = 0}^n q^k = \frac{1 - q^{n+1}}{1 - q}
\end{align*}
Also für $|q| < 1$:
\begin{align*}
	\sum_{k = 0}^\infty q^k = \frac{1}{1 - q}
\end{align*}
\section{Standardbeispiel für Teleskopsummen}
\begin{align*}
	\sum_{k = 1}^\infty \frac{1}{k(k+1)} &= \lim_{n \to \infty} \sum_{k = 1}^n\frac{1}{k(k+1)}\\
	&= \lim_{n \to \infty }\sum_{k = 1}^n \left(\frac{1}{k} - \frac{1}{k+1}\right) ^*\\
	&= \lim_{n \to \infty } 1 - \frac{1}{n + 1}\\
	&= 1
\end{align*}
$^*$ Die Umformung der Brüche funktioniert folgendermaßen:
\begin{align*}
	\frac{1}{k(k+1)} = \frac{k+1}{k(k+1)} - \frac{k}{k(k+1)} = \frac{1}{k} - \frac{1}{k+1}
\end{align*}
\section{Wichtige Taylorreihen}
\subsection{Exponentialfunktion}
\begin{align*}
	e^x = \sum_{k = 0}^\infty \frac{x^k}{k!} \quad \left( = \lim_{n \to \infty} \left(1 + \frac{x}{n}\right)^n \right)
\end{align*}
\subsection{Sinus und Kosinus}
\begin{align*}
	\cos(x) &= \sum_{k=0}^\infty \frac{(-1)^k}{(2k)!}x^{2k}\\
	\sin(x) &= \sum_{k=0}^\infty \frac{(-1)^k}{(2k+1)!}x^{2k+1}\\
\end{align*}
Aus diesen Reihen folgt direkt die Eulersche Formel $e^{ix} = \cos(x) + i\sin(x)$:
\begin{align*}
	e^{ix} &= \sum_{k = 0}^\infty \frac{(ix)^k}{k!}\\
	&= \sum_{k = 0}^\infty \frac{(ix)^{2k}}{(2k)!} + \sum_{k = 0}^\infty \frac{(ix)^{2k+1}}{(2k+1)!}\\
	&= \sum_{k = 0}^\infty \frac{i^{2k}}{(2k)!}x^{2k} + \sum_{k = 0}^\infty \frac{i^{2k+1}}{(2k+1)!}x^{2k+1}\\
	&= \sum_{k = 0}^\infty \frac{i^{2k}}{(2k)!}x^{2k} + i \sum_{k = 0}^\infty  \frac{i^{2k}}{(2k+1)!}x^{2k+1}\\
	&= \sum_{k = 0}^\infty \frac{(i^2)^k}{(2k)!}x^{2k} + i \sum_{k = 0}^\infty \frac{(i^2)^k}{(2k+1)!}x^{2k+1}\\
	&= \sum_{k = 0}^\infty \frac{(-1)^k}{(2k)!}x^{2k} + i \sum_{k = 0}^\infty \frac{(-1)^k}{(2k+1)!}x^{2k+1}\\
	&= \cos(x) + i \sin(x)
\end{align*}
\subsection{Logarithmus}
Da $\ln(x)$ eine Singularität am Punkt $x = 0$ hat, Entwickeln wir stattdessen am Punkt $x = 1$ und erhalten:
\begin{align*}
	\ln(1+x) = \sum_{k=1}^\infty (-1)^{k+1} \frac{x^k}{k}
\end{align*}
\chapter{Sammlung von Stammfunktionen}
\section{Inverse Trigonometrie}
\begin{align*}
	\arcsin(x) &= \int \frac{1}{\sqrt{1-x^2}} dx\\
	\arccos(x) &= - \int \frac{1}{\sqrt{1-x^2}} dx\\
	\arctan(x) &= \int \frac{1}{1+x^2} dx\\
\end{align*}
Für die Herleitung sind die Ableitungsformel für Umkehrfunktionen und die Identität 
\begin{align*}
	\sin(x)^2 &+ \cos(x)^2 = 1\\
	\implies \sin(x) = \sqrt{1 - \cos(x)^2}&, \qquad \cos(x) = \sqrt{1 - \sin(x)^2}
\end{align*} nötig.

\section{Hyperbolische Trigonometrie}
\begin{align*}
	\sinh(x) &= \frac{e^x - e^{-x}}{2}\\
	\cosh(x) &= \frac{e^x + e^{-x}}{2}\\
	\tanh(x) &= \frac{\sinh(x)}{\cosh(x)}\\
\end{align*}
\end{document}
